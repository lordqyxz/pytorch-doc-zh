
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/1.4/77/">
      
      
        <link rel="prev" href="../76/">
      
      
        <link rel="next" href="../78/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.17">
    
    
      
        <title>torch张量 - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.26e3688c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link rel="stylesheet" href="../../assets/stylesheets/custom.bea7efe8.min.css">
  <!-- google ads -->
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3565452474788507" crossorigin="anonymous"></script>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8DP4GX97XY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-8DP4GX97XY');
  </script>
  <!-- google webmaster -->
  <meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo" />

  <!-- wwads-cn union -->
  <meta name="wwads-cn-verify" content="03c6b06952c750899bb03d998e631860" />
  <script type="text/javascript" charset="UTF-8" src="https://cdn.wwads.cn/js/makemoney.js" async></script>

  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
            
  => 组织无偿提供 中文版本（免费，秒级响应）
  <a target="_blank" href="https://chat.ibooker.org.cn/chat" style="color: red;">
    <span class="twemoji mastodon">
      <img src="https://data.apachecn.org/img/icon/ROBOT_TXT.svg" alt="ChatGPT - ailake.top">
    </span>
    <strong>ChatGPT - ailake.top</strong>
  </a> 一起来白嫖叭～！

          </div>
          
        </aside>
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              torch张量
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        PyTorch 中文文档 & 教程
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          PyTorch 2.0 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 2.0 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/README.md" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          PyTorch 1.7 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.7 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
          学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
          PyTorch 深度学习：60 分钟的突击
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习：60 分钟的突击
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/02/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/03/" class="md-nav__link">
        张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/04/" class="md-nav__link">
        torch.autograd的简要介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/05/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/06/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
          通过示例学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          通过示例学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/07/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/08/" class="md-nav__link">
        热身：NumPy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/09/" class="md-nav__link">
        PyTorch：张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/10/" class="md-nav__link">
        PyTorch：张量和 Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/11/" class="md-nav__link">
        PyTorch：定义新的 Autograd 函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/12/" class="md-nav__link">
        PyTorch：nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/13/" class="md-nav__link">
        PyTorch：optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/14/" class="md-nav__link">
        PyTorch：自定义nn模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/15/" class="md-nav__link">
        PyTorch：控制流 - 权重共享
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/16/" class="md-nav__link">
        torch.nn到底是什么？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/17/" class="md-nav__link">
        使用 TensorBoard 可视化模型，数据和训练
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
          图片/视频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          图片/视频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/19/" class="md-nav__link">
        torchvision对象检测微调教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/20/" class="md-nav__link">
        计算机视觉的迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/21/" class="md-nav__link">
        对抗示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/22/" class="md-nav__link">
        DCGAN 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
          音频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          音频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/24/" class="md-nav__link">
        音频 I/O 和torchaudio的预处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/25/" class="md-nav__link">
        使用torchaudio的语音命令识别
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/27/" class="md-nav__link">
        使用nn.Transformer和torchtext的序列到序列建模
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/28/" class="md-nav__link">
        从零开始的 NLP：使用字符级 RNN 分类名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/29/" class="md-nav__link">
        从零开始的 NLP：使用字符级 RNN 生成名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/30/" class="md-nav__link">
        从零开始的 NLP：使用序列到序列网络和注意力的翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/31/" class="md-nav__link">
        使用torchtext的文本分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/32/" class="md-nav__link">
        torchtext语言翻译
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
      
      
      
        <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/34/" class="md-nav__link">
        强化学习（DQN）教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/35/" class="md-nav__link">
        训练玩马里奥的 RL 智能体
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
      
      
      
        <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
          在生产中部署 PyTorch 模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_6">
          <span class="md-nav__icon md-icon"></span>
          在生产中部署 PyTorch 模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/37/" class="md-nav__link">
        通过使用 Flask 的 REST API 在 Python 中部署 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/38/" class="md-nav__link">
        TorchScript 简介
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/39/" class="md-nav__link">
        在 C-- 中加载 TorchScript 模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/40/" class="md-nav__link">
        将模型从 PyTorch 导出到 ONNX 并使用 ONNX 运行时运行它（可选）
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
      
      
      
        <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
          前端 API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_7">
          <span class="md-nav__icon md-icon"></span>
          前端 API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/42/" class="md-nav__link">
        PyTorch 中的命名张量简介（原型）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/43/" class="md-nav__link">
        PyTorch 中通道在最后的内存格式（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/44/" class="md-nav__link">
        使用 PyTorch C-- 前端
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/45/" class="md-nav__link">
        自定义 C-- 和 CUDA 扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/46/" class="md-nav__link">
        使用自定义 C-- 运算符扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/47/" class="md-nav__link">
        使用自定义 C-- 类扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/48/" class="md-nav__link">
        TorchScript 中的动态并行性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/49/" class="md-nav__link">
        C-- 前端中的 Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/50/" class="md-nav__link">
        在 C-- 中注册调度运算符
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_8" >
      
      
      
        <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
          模型优化
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_8">
          <span class="md-nav__icon md-icon"></span>
          模型优化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/52/" class="md-nav__link">
        分析您的 PyTorch 模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/53/" class="md-nav__link">
        使用 Ray Tune 的超参数调整
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/54/" class="md-nav__link">
        模型剪裁教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/55/" class="md-nav__link">
        LSTM 单词语言模型上的动态量化（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/56/" class="md-nav__link">
        BERT 上的动态量化（Beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/57/" class="md-nav__link">
        PyTorch 中使用 Eager 模式的静态量化（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/58/" class="md-nav__link">
        计算机视觉的量化迁移学习教程（beta）
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_9" >
      
      
      
        <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
          并行和分布式训练
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_9">
          <span class="md-nav__icon md-icon"></span>
          并行和分布式训练
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/60/" class="md-nav__link">
        PyTorch 分布式概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/61/" class="md-nav__link">
        单机模型并行最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/62/" class="md-nav__link">
        分布式数据并行入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/63/" class="md-nav__link">
        用 PyTorch 编写分布式应用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/64/" class="md-nav__link">
        分布式 RPC 框架入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/65/" class="md-nav__link">
        使用分布式 RPC 框架实现参数服务器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/66/" class="md-nav__link">
        使用 RPC 的分布式管道并行化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/67/" class="md-nav__link">
        使用异步执行实现批量 RPC 处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/68/" class="md-nav__link">
        将分布式DataParallel与分布式 RPC 框架相结合
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          PyTorch 1.4 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.4 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
          入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1_1" id="__nav_4_1_1_label" tabindex="0">
          使用 PyTorch 进行深度学习：60 分钟的闪电战
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1_1">
          <span class="md-nav__icon md-icon"></span>
          使用 PyTorch 进行深度学习：60 分钟的闪电战
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../4/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/tensor_tutorial/" class="md-nav__link">
        什么是PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/autograd_tutorial/" class="md-nav__link">
        Autograd：自动求导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/cifar10_tutorial/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/data_parallel_tutorial/" class="md-nav__link">
        可选：数据并行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../5/" class="md-nav__link">
        编写自定义数据集，数据加载器和转换
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../6/" class="md-nav__link">
        使用 TensorBoard 可视化模型，数据和训练
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
      
      
      
        <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
          图片
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          图片
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../8/" class="md-nav__link">
        TorchVision 对象检测微调教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../9/" class="md-nav__link">
        转移学习的计算机视觉教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../10/" class="md-nav__link">
        空间变压器网络教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../11/" class="md-nav__link">
        使用 PyTorch 进行神经传递
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../12/" class="md-nav__link">
        对抗示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../13/" class="md-nav__link">
        DCGAN 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
      
      
      
        <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
          音频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          音频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../15/" class="md-nav__link">
        torchaudio 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../17/" class="md-nav__link">
        NLP From Scratch: 使用char-RNN对姓氏进行分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../18/" class="md-nav__link">
        NLP From Scratch: 生成名称与字符级RNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../19/" class="md-nav__link">
        NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../20/" class="md-nav__link">
        使用 TorchText 进行文本分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../21/" class="md-nav__link">
        使用 TorchText 进行语言翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../22/" class="md-nav__link">
        使用 nn.Transformer 和 TorchText 进行序列到序列建模
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
      
      
      
        <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
          命名为 Tensor(实验性）
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_5">
          <span class="md-nav__icon md-icon"></span>
          命名为 Tensor(实验性）
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../24/" class="md-nav__link">
        (实验性)PyTorch 中的命名张量简介
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6" >
      
      
      
        <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_6">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../26/" class="md-nav__link">
        强化学习(DQN)教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_7" >
      
      
      
        <label class="md-nav__link" for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
          在生产中部署 PyTorch 模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_7">
          <span class="md-nav__icon md-icon"></span>
          在生产中部署 PyTorch 模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../28/" class="md-nav__link">
        通过带有 Flask 的 REST API 在 Python 中部署 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../29/" class="md-nav__link">
        TorchScript 简介
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../30/" class="md-nav__link">
        在 C --中加载 TorchScript 模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../31/" class="md-nav__link">
        (可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_8" >
      
      
      
        <label class="md-nav__link" for="__nav_4_8" id="__nav_4_8_label" tabindex="0">
          并行和分布式训练
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_8">
          <span class="md-nav__icon md-icon"></span>
          并行和分布式训练
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../33/" class="md-nav__link">
        单机模型并行最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../34/" class="md-nav__link">
        分布式数据并行入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../35/" class="md-nav__link">
        用 PyTorch 编写分布式应用程序
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../36/" class="md-nav__link">
        分布式 RPC 框架入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../37/" class="md-nav__link">
        (高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_9" >
      
      
      
        <label class="md-nav__link" for="__nav_4_9" id="__nav_4_9_label" tabindex="0">
          扩展 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_9">
          <span class="md-nav__icon md-icon"></span>
          扩展 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../39/" class="md-nav__link">
        使用自定义 C --运算符扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../40/" class="md-nav__link">
        使用自定义 C --类扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../41/" class="md-nav__link">
        使用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../42/" class="md-nav__link">
        自定义 C --和 CUDA 扩展
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_10" >
      
      
      
        <label class="md-nav__link" for="__nav_4_10" id="__nav_4_10_label" tabindex="0">
          模型优化
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_10_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_10">
          <span class="md-nav__icon md-icon"></span>
          模型优化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../44/" class="md-nav__link">
        LSTM Word 语言模型上的(实验）动态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../45/" class="md-nav__link">
        (实验性）在 PyTorch 中使用 Eager 模式进行静态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../46/" class="md-nav__link">
        (实验性）计算机视觉教程的量化转移学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../47/" class="md-nav__link">
        (实验）BERT 上的动态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../48/" class="md-nav__link">
        修剪教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_11" >
      
      
      
        <label class="md-nav__link" for="__nav_4_11" id="__nav_4_11_label" tabindex="0">
          PyTorch 用其他语言
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_11_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_11">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 用其他语言
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../50/" class="md-nav__link">
        使用 PyTorch C --前端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_12" >
      
      
      
        <label class="md-nav__link" for="__nav_4_12" id="__nav_4_12_label" tabindex="0">
          PyTorch 基础知识
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_12_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_12">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 基础知识
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../52/" class="md-nav__link">
        通过示例学习 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../53/" class="md-nav__link">
        torch.nn 到底是什么？
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_13" >
      
      
      
        <label class="md-nav__link" for="__nav_4_13" id="__nav_4_13_label" tabindex="0">
          笔记
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_13_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_13">
          <span class="md-nav__icon md-icon"></span>
          笔记
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../56/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../57/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../58/" class="md-nav__link">
        CPU 线程和 TorchScript 推断
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../59/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../60/" class="md-nav__link">
        分布式 Autograd 设计
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../61/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../62/" class="md-nav__link">
        经常问的问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../63/" class="md-nav__link">
        大规模部署的功能
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../64/" class="md-nav__link">
        并行处理最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../65/" class="md-nav__link">
        重现性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../66/" class="md-nav__link">
        远程参考协议
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../67/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../68/" class="md-nav__link">
        Windows 常见问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../69/" class="md-nav__link">
        XLA 设备上的 PyTorch
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_14" >
      
      
      
        <label class="md-nav__link" for="__nav_4_14" id="__nav_4_14_label" tabindex="0">
          语言绑定
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_14_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_14">
          <span class="md-nav__icon md-icon"></span>
          语言绑定
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../71/" class="md-nav__link">
        PyTorch C -- API
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../72/" class="md-nav__link">
        PyTorch Java API
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_15" checked>
      
      
      
        <label class="md-nav__link" for="__nav_4_15" id="__nav_4_15_label" tabindex="0">
          Python API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_15_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4_15">
          <span class="md-nav__icon md-icon"></span>
          Python API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../74/" class="md-nav__link">
        torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../75/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../76/" class="md-nav__link">
        torch功能
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        torch张量
      </a>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../78/" class="md-nav__link">
        张量属性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../79/" class="md-nav__link">
        自动差分包-Torch.Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../80/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../81/" class="md-nav__link">
        分布式通讯包-Torch.Distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../82/" class="md-nav__link">
        概率分布-torch分布
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../83/" class="md-nav__link">
        torch.hub
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../84/" class="md-nav__link">
        torch脚本
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../85/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../86/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../87/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../88/" class="md-nav__link">
        量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../89/" class="md-nav__link">
        分布式 RPC 框架
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../90/" class="md-nav__link">
        torch随机
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../91/" class="md-nav__link">
        torch稀疏
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../92/" class="md-nav__link">
        torch存储
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../93/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../94/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../95/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../96/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../97/" class="md-nav__link">
        torch.utils.dlpack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../98/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../99/" class="md-nav__link">
        torch.utils.tensorboard
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../100/" class="md-nav__link">
        类型信息
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../101/" class="md-nav__link">
        命名张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../102/" class="md-nav__link">
        命名为 Tensors 操作员范围
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../103/" class="md-nav__link">
        糟糕！
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_16" >
      
      
      
        <label class="md-nav__link" for="__nav_4_16" id="__nav_4_16_label" tabindex="0">
          torchvision参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_16_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_16">
          <span class="md-nav__icon md-icon"></span>
          torchvision参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../105/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_17" >
      
      
      
        <label class="md-nav__link" for="__nav_4_17" id="__nav_4_17_label" tabindex="0">
          音频参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_17_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_17">
          <span class="md-nav__icon md-icon"></span>
          音频参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../107/" class="md-nav__link">
        torchaudio
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_18" >
      
      
      
        <label class="md-nav__link" for="__nav_4_18" id="__nav_4_18_label" tabindex="0">
          torchtext参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_18_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_18">
          <span class="md-nav__icon md-icon"></span>
          torchtext参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../109/" class="md-nav__link">
        torchtext
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_19" >
      
      
      
        <label class="md-nav__link" for="__nav_4_19" id="__nav_4_19_label" tabindex="0">
          社区
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_19_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_19">
          <span class="md-nav__icon md-icon"></span>
          社区
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../111/" class="md-nav__link">
        PyTorch 贡献指南
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../112/" class="md-nav__link">
        PyTorch 治理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../113/" class="md-nav__link">
        PyTorch 治理| 感兴趣的人
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          PyTorch 1.0 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.0 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_1" id="__nav_5_2_1_label" tabindex="0">
          入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_1">
          <span class="md-nav__icon md-icon"></span>
          入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_1_1" id="__nav_5_2_1_1_label" tabindex="0">
          PyTorch 深度学习: 60 分钟极速入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习: 60 分钟极速入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deep_learning_60min_blitz/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_tensor_tutorial/" class="md-nav__link">
        什么是 PyTorch？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_autograd_tutorial/" class="md-nav__link">
        Autograd：自动求导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_cifar10_tutorial/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_data_parallel_tutorial/" class="md-nav__link">
        可选：数据并行处理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/data_loading_tutorial/" class="md-nav__link">
        数据加载和处理教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/pytorch_with_examples/" class="md-nav__link">
        用例子学习 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/transfer_learning_tutorial/" class="md-nav__link">
        迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deploy_seq2seq_hybrid_frontend_tutorial/" class="md-nav__link">
        混合前端的 seq2seq 模型部署
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/saving_loading_models/" class="md-nav__link">
        Saving and Loading Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_tutorial/" class="md-nav__link">
        What is torch.nn really?
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_2" id="__nav_5_2_2_label" tabindex="0">
          图像
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_2">
          <span class="md-nav__icon md-icon"></span>
          图像
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/finetuning_torchvision_models_tutorial/" class="md-nav__link">
        Torchvision 模型微调
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/spatial_transformer_tutorial/" class="md-nav__link">
        空间变换器网络教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/neural_style_tutorial/" class="md-nav__link">
        使用 PyTorch 进行图像风格转换
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/fgsm_tutorial/" class="md-nav__link">
        对抗性示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/super_resolution_with_caffe2/" class="md-nav__link">
        使用 ONNX 将模型从 PyTorch 传输到 Caffe2 和移动端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_3" id="__nav_5_2_3_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_3">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/chatbot_tutorial/" class="md-nav__link">
        聊天机器人教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/char_rnn_generation_tutorial/" class="md-nav__link">
        使用字符级别特征的 RNN 网络生成姓氏
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/char_rnn_classification_tutorial/" class="md-nav__link">
        使用字符级别特征的 RNN 网络进行姓氏分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3_4" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_3_4" id="__nav_5_2_3_4_label" tabindex="0">
          Deep Learning for NLP with Pytorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_3_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_3_4">
          <span class="md-nav__icon md-icon"></span>
          Deep Learning for NLP with Pytorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deep_learning_nlp_tutorial/" class="md-nav__link">
        在深度学习和 NLP 中使用 Pytorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_pytorch_tutorial/" class="md-nav__link">
        PyTorch 介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_deep_learning_tutorial/" class="md-nav__link">
        使用 PyTorch 进行深度学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_word_embeddings_tutorial/" class="md-nav__link">
        Word Embeddings: Encoding Lexical Semantics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_sequence_models_tutorial/" class="md-nav__link">
        序列模型和 LSTM 网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_advanced_tutorial/" class="md-nav__link">
        Advanced: Making Dynamic Decisions and the Bi-LSTM CRF
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/seq2seq_translation_tutorial/" class="md-nav__link">
        基于注意力机制的 seq2seq 神经网络翻译
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_4" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_4" id="__nav_5_2_4_label" tabindex="0">
          生成
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_4">
          <span class="md-nav__icon md-icon"></span>
          生成
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dcgan_faces_tutorial/" class="md-nav__link">
        DCGAN Tutorial
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_5" id="__nav_5_2_5_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_5">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/reinforcement_q_learning/" class="md-nav__link">
        Reinforcement Learning (DQN) Tutorial
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_6" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_6" id="__nav_5_2_6_label" tabindex="0">
          扩展 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_6">
          <span class="md-nav__icon md-icon"></span>
          扩展 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/numpy_extensions_tutorial/" class="md-nav__link">
        用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_extension/" class="md-nav__link">
        Custom C-- and CUDA Extensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_script_custom_ops/" class="md-nav__link">
        Extending TorchScript with Custom C-- Operators
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_7" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_7" id="__nav_5_2_7_label" tabindex="0">
          生产性使用
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_7">
          <span class="md-nav__icon md-icon"></span>
          生产性使用
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dist_tuto/" class="md-nav__link">
        Writing Distributed Applications with PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/aws_distributed_training_tutorial/" class="md-nav__link">
        使用 Amazon AWS 进行分布式训练
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/ONNXLive/" class="md-nav__link">
        ONNX 现场演示教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_export/" class="md-nav__link">
        在 C-- 中加载 PYTORCH 模型
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_8" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_8" id="__nav_5_2_8_label" tabindex="0">
          其它语言中的 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_8">
          <span class="md-nav__icon md-icon"></span>
          其它语言中的 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_frontend/" class="md-nav__link">
        使用 PyTorch C-- 前端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_1" id="__nav_5_3_1_label" tabindex="0">
          注解
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_1">
          <span class="md-nav__icon md-icon"></span>
          注解
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_broadcasting/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_cuda/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_extending/" class="md-nav__link">
        Extending PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_faq/" class="md-nav__link">
        Frequently Asked Questions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_multiprocessing/" class="md-nav__link">
        Multiprocessing best practices
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_randomness/" class="md-nav__link">
        Reproducibility
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_serialization/" class="md-nav__link">
        Serialization semantics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_windows/" class="md-nav__link">
        Windows FAQ
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2" id="__nav_5_3_2_label" tabindex="0">
          包参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_2">
          <span class="md-nav__icon md-icon"></span>
          包参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2_1" id="__nav_5_3_2_1_label" tabindex="0">
          torch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_3_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_2_1">
          <span class="md-nav__icon md-icon"></span>
          torch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_tensors/" class="md-nav__link">
        Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_random_sampling/" class="md-nav__link">
        Random sampling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_serialization_parallelism_utilities/" class="md-nav__link">
        Serialization, Parallelism, Utilities
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2_1_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2_1_5" id="__nav_5_3_2_1_5_label" tabindex="0">
          Math operations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_5_3_2_1_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_2_1_5">
          <span class="md-nav__icon md-icon"></span>
          Math operations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_pointwise_ops/" class="md-nav__link">
        Pointwise Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_reduction_ops/" class="md-nav__link">
        Reduction Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_comparison_ops/" class="md-nav__link">
        Comparison Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_spectral_ops/" class="md-nav__link">
        Spectral Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_other_ops/" class="md-nav__link">
        Other Operations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_blas_lapack_ops/" class="md-nav__link">
        BLAS and LAPACK Operations
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/tensors/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/tensor_attributes/" class="md-nav__link">
        Tensor Attributes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/type_info/" class="md-nav__link">
        数据类型信息
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/sparse/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_functional/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_init/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/autograd/" class="md-nav__link">
        Automatic differentiation package - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributed/" class="md-nav__link">
        Distributed communication package - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributions/" class="md-nav__link">
        Probability distributions - torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/jit/" class="md-nav__link">
        Torch Script
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/multiprocessing/" class="md-nav__link">
        多进程包 - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/bottleneck/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/checkpoint/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/docs_cpp_extension/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dlpack/" class="md-nav__link">
        torch.utils.dlpack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/hub/" class="md-nav__link">
        torch.hub
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/onnx/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributed_deprecated/" class="md-nav__link">
        Distributed communication package (deprecated) - torch.distributed.deprecated
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_3" id="__nav_5_3_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/docs_torchvision_ref/" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_transforms/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          PyTorch 0.4 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.4 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" >
      
      
      
        <label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
          笔记
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          笔记
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/1/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/2/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/3/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/4/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/5/" class="md-nav__link">
        常见问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/6/" class="md-nav__link">
        多进程最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/7/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/8/" class="md-nav__link">
        Windows 常见问题
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
      
      
      
        <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
          包参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_2">
          <span class="md-nav__icon md-icon"></span>
          包参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/10/" class="md-nav__link">
        Torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/11/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/12/" class="md-nav__link">
        Tensor Attributes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/13/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/14/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/15/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/16/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/17/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/18/" class="md-nav__link">
        自动差异化包 - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/19/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/20/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/21/" class="md-nav__link">
        torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/22/" class="md-nav__link">
        Multiprocessing 包 - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/23/" class="md-nav__link">
        分布式通讯包 - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/24/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/25/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/26/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/27/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/28/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/29/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/30/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/31/" class="md-nav__link">
        遗留包 - torch.legacy
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
      
      
      
        <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/33/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/34/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/35/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/36/" class="md-nav__link">
        torchvision.transform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/37/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
      
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          PyTorch 0.3 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.3 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1" id="__nav_7_2_1_label" tabindex="0">
          初学者教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1">
          <span class="md-nav__icon md-icon"></span>
          初学者教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_1" id="__nav_7_2_1_1_label" tabindex="0">
          PyTorch 深度学习: 60 分钟极速入门教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习: 60 分钟极速入门教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/deep_learning_60min_blitz/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_tensor_tutorial/" class="md-nav__link">
        PyTorch 是什么？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_autograd_tutorial/" class="md-nav__link">
        自动求导: 自动微分
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_cifar10_tutorial/" class="md-nav__link">
        训练一个分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_data_parallel_tutorial/" class="md-nav__link">
        可选: 数据并行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_2" id="__nav_7_2_1_2_label" tabindex="0">
          PyTorch for former Torch users
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_2">
          <span class="md-nav__icon md-icon"></span>
          PyTorch for former Torch users
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_tutorial/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_tensor_tutorial/" class="md-nav__link">
        Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_autograd_tutorial/" class="md-nav__link">
        Autograd (自动求导)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_nn_tutorial/" class="md-nav__link">
        nn package
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_parallelism_tutorial/" class="md-nav__link">
        Multi-GPU examples
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_3" id="__nav_7_2_1_3_label" tabindex="0">
          跟着例子学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_3">
          <span class="md-nav__icon md-icon"></span>
          跟着例子学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_warm-up-numpy/" class="md-nav__link">
        Warm-up: numpy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-tensors/" class="md-nav__link">
        PyTorch: Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-variables-and-autograd/" class="md-nav__link">
        PyTorch: 变量和autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-defining-new-autograd-functions/" class="md-nav__link">
        PyTorch: 定义新的autograd函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_tensorflow-static-graphs/" class="md-nav__link">
        TensorFlow: 静态图
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-nn/" class="md-nav__link">
        PyTorch: nn包
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-optim/" class="md-nav__link">
        PyTorch: optim包
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-custom-nn-modules/" class="md-nav__link">
        PyTorch: 定制化nn模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-control-flow-weight-sharing/" class="md-nav__link">
        PyTorch: 动态控制流程 - 权重共享
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/transfer_learning_tutorial/" class="md-nav__link">
        迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/data_loading_tutorial/" class="md-nav__link">
        数据加载和处理教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_6" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_6" id="__nav_7_2_1_6_label" tabindex="0">
          针对NLP的Pytorch深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_6">
          <span class="md-nav__icon md-icon"></span>
          针对NLP的Pytorch深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/deep_learning_nlp_tutorial/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_pytorch_tutorial/" class="md-nav__link">
        PyTorch介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_deep_learning_tutorial/" class="md-nav__link">
        PyTorch深度学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_word_embeddings_tutorial/" class="md-nav__link">
        词汇嵌入:编码词汇语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_sequence_models_tutorial/" class="md-nav__link">
        序列模型和 LSTM 网络(长短记忆网络）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_advanced_tutorial/" class="md-nav__link">
        高级教程: 作出动态决策和 Bi-LSTM CRF
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_2" id="__nav_7_2_2_label" tabindex="0">
          中级教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_2">
          <span class="md-nav__icon md-icon"></span>
          中级教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/char_rnn_classification_tutorial/" class="md-nav__link">
        用字符级RNN分类名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/char_rnn_generation_tutorial/" class="md-nav__link">
        基与字符级RNN(Char-RNN）的人名生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/seq2seq_translation_tutorial/" class="md-nav__link">
        用基于注意力机制的seq2seq神经网络进行翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/reinforcement_q_learning/" class="md-nav__link">
        强化学习(DQN）教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/dist_tuto/" class="md-nav__link">
        Writing Distributed Applications with PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/spatial_transformer_tutorial/" class="md-nav__link">
        空间转换网络 (Spatial Transformer Networks) 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_3" id="__nav_7_2_3_label" tabindex="0">
          高级教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_3">
          <span class="md-nav__icon md-icon"></span>
          高级教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/neural_style_tutorial/" class="md-nav__link">
        用 PyTorch 做 神经转换 (Neural Transfer)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/numpy_extensions_tutorial/" class="md-nav__link">
        使用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/super_resolution_with_caffe2/" class="md-nav__link">
        使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/c_extension/" class="md-nav__link">
        为 pytorch 自定义 C 扩展
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3_1" id="__nav_7_3_1_label" tabindex="0">
          介绍
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3_1">
          <span class="md-nav__icon md-icon"></span>
          介绍
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_broadcasting/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_cuda/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_extending/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_multiprocessing/" class="md-nav__link">
        多进程的最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_serialization/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3_2" id="__nav_7_3_2_label" tabindex="0">
          Package 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3_2">
          <span class="md-nav__icon md-icon"></span>
          Package 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/torch/" class="md-nav__link">
        torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/tensors/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/sparse/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/autograd/" class="md-nav__link">
        Automatic differentiation package - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/distributions/" class="md-nav__link">
        Probability distributions - torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/multiprocessing/" class="md-nav__link">
        Multiprocessing package - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/distributed/" class="md-nav__link">
        Distributed communication package - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/legacy/" class="md-nav__link">
        Legacy package - torch.legacy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/ffi/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/onnx/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3_3" id="__nav_7_3_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/torchvision/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/transforms/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
      
      
      
        <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
          PyTorch 0.2 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.2 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2" >
      
      
      
        <label class="md-nav__link" for="__nav_8_2" id="__nav_8_2_label" tabindex="0">
          说明
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_2">
          <span class="md-nav__icon md-icon"></span>
          说明
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/cuda/" class="md-nav__link">
        CUDA语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/extending/" class="md-nav__link">
        扩展PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/multiprocessing/" class="md-nav__link">
        多进程最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/serialization/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_3" >
      
      
      
        <label class="md-nav__link" for="__nav_8_3" id="__nav_8_3_label" tabindex="0">
          PACKAGE参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_3">
          <span class="md-nav__icon md-icon"></span>
          PACKAGE参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch/" class="md-nav__link">
        torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/Tensor/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/Storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/functional/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-autograd/" class="md-nav__link">
        torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/nn_init/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-multiprocessing/" class="md-nav__link">
        torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/legacy/" class="md-nav__link">
        torch.legacy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/ffi/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_4" >
      
      
      
        <label class="md-nav__link" for="__nav_8_4" id="__nav_8_4_label" tabindex="0">
          TORCHVISION参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_4">
          <span class="md-nav__icon md-icon"></span>
          TORCHVISION参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-transform/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/acknowledgement/" class="md-nav__link">
        致谢
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../contrib/" class="md-nav__link">
        贡献者
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about/" class="md-nav__link">
        关于我们
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        中文资源合集
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/1.4/77.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/1.4/77.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<div class="wwads-cn wwads-horizontal" data-id="206" style="max-width:680px"></div>
<h1 id="torch">torch张量</h1>
<blockquote>
<p>原文： <a href="https://pytorch.org/docs/stable/tensors.html">https://pytorch.org/docs/stable/tensors.html</a></p>
</blockquote>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 是包含单个数据类型元素的多维矩阵。</p>
<p>Torch 定义了 9 种 CPU 张量类型和 9 种 GPU 张量类型：</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>dtype</th>
<th>CPU 张量</th>
<th>GPU 张量</th>
</tr>
</thead>
<tbody>
<tr>
<td>32 位浮点</td>
<td><code>torch.float32</code>或<code>torch.float</code></td>
<td><code>torch.FloatTensor</code></td>
<td><code>torch.cuda.FloatTensor</code></td>
</tr>
<tr>
<td>64 位浮点</td>
<td><code>torch.float64</code>或<code>torch.double</code></td>
<td><code>torch.DoubleTensor</code></td>
<td><code>torch.cuda.DoubleTensor</code></td>
</tr>
<tr>
<td>16 位浮点</td>
<td><code>torch.float16</code>或<code>torch.half</code></td>
<td><code>torch.HalfTensor</code></td>
<td><code>torch.cuda.HalfTensor</code></td>
</tr>
<tr>
<td>8 位整数(无符号）</td>
<td><code>torch.uint8</code></td>
<td><code>torch.ByteTensor</code></td>
<td><code>torch.cuda.ByteTensor</code></td>
</tr>
<tr>
<td>8 位整数(有符号）</td>
<td><code>torch.int8</code></td>
<td><code>torch.CharTensor</code></td>
<td><code>torch.cuda.CharTensor</code></td>
</tr>
<tr>
<td>16 位整数(有符号）</td>
<td><code>torch.int16</code>或<code>torch.short</code></td>
<td><code>torch.ShortTensor</code></td>
<td><code>torch.cuda.ShortTensor</code></td>
</tr>
<tr>
<td>32 位整数(有符号）</td>
<td><code>torch.int32</code>或<code>torch.int</code></td>
<td><code>torch.IntTensor</code></td>
<td><code>torch.cuda.IntTensor</code></td>
</tr>
<tr>
<td>64 位整数(有符号）</td>
<td><code>torch.int64</code>或<code>torch.long</code></td>
<td><code>torch.LongTensor</code></td>
<td><code>torch.cuda.LongTensor</code></td>
</tr>
<tr>
<td>布尔型</td>
<td><code>torch.bool</code></td>
<td><a href="#torch.BoolTensor" title="torch.BoolTensor"><code>torch.BoolTensor</code></a></td>
<td><code>torch.cuda.BoolTensor</code></td>
</tr>
</tbody>
</table>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 是默认张量类型(<code>torch.FloatTensor</code>）的别名。</p>
<p>可以使用 <a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> 构造函数从 Python <code>list</code>或序列构造张量：</p>
<pre><code>&gt;&gt;&gt; torch.tensor([[1., -1.], [1., -1.]])
tensor([[ 1.0000, -1.0000],
        [ 1.0000, -1.0000]])
&gt;&gt;&gt; torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))
tensor([[ 1,  2,  3],
        [ 4,  5,  6]])

</code></pre>
<p>警告</p>
<p><a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> 始终复制<code>data</code>。 如果您具有张量<code>data</code>，而只想更改其<code>requires_grad</code>标志，请使用 <a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a> 或 <a href="autograd.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>detach()</code></a> 以避免复制。 如果您有一个 numpy 数组并且想要避免复制，请使用 <a href="torch.html#torch.as_tensor" title="torch.as_tensor"><code>torch.as_tensor()</code></a> 。</p>
<p>可以通过将 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和/或 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 传递给构造函数或张量创建操作来构造特定数据类型的张量：</p>
<pre><code>&gt;&gt;&gt; torch.zeros([2, 4], dtype=torch.int32)
tensor([[ 0,  0,  0,  0],
        [ 0,  0,  0,  0]], dtype=torch.int32)
&gt;&gt;&gt; cuda0 = torch.device('cuda:0')
&gt;&gt;&gt; torch.ones([2, 4], dtype=torch.float64, device=cuda0)
tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],
        [ 1.0000,  1.0000,  1.0000,  1.0000]], dtype=torch.float64, device='cuda:0')

</code></pre>
<p>张量的内容可以使用 Python 的索引和切片符号来访问和修改：</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6]])
&gt;&gt;&gt; print(x[1][2])
tensor(6)
&gt;&gt;&gt; x[0][1] = 8
&gt;&gt;&gt; print(x)
tensor([[ 1,  8,  3],
        [ 4,  5,  6]])

</code></pre>
<p>使用 <a href="#torch.Tensor.item" title="torch.Tensor.item"><code>torch.Tensor.item()</code></a> 从张量中获取包含单个值的 Python 数字：</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([[1]])
&gt;&gt;&gt; x
tensor([[ 1]])
&gt;&gt;&gt; x.item()
1
&gt;&gt;&gt; x = torch.tensor(2.5)
&gt;&gt;&gt; x
tensor(2.5000)
&gt;&gt;&gt; x.item()
2.5

</code></pre>
<p>可以使用<code>requires_grad=True</code>创建一个张量，以便 <a href="autograd.html#module-torch.autograd" title="torch.autograd"><code>torch.autograd</code></a> 对其进行记录操作以进行自动微分。</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)
&gt;&gt;&gt; out = x.pow(2).sum()
&gt;&gt;&gt; out.backward()
&gt;&gt;&gt; x.grad
tensor([[ 2.0000, -2.0000],
        [ 2.0000,  2.0000]])

</code></pre>
<p>每个张量都有一个关联的<code>torch.Storage</code>，它保存其数据。 张量类提供了存储的多维<a href="https://en.wikipedia.org/wiki/Stride_of_an_array">跨度</a>视图，并定义了数字运算。</p>
<p>注意</p>
<p>有关 <a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> ， <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 和 <a href="tensor_attributes.html#torch.torch.layout" title="torch.torch.layout"><code>torch.layout</code></a> 属性的更多信息，请参阅[ <a href="tensor_attributes.html#tensor-attributes-doc">Tensor Attributes</a> 。</p>
<p>注意</p>
<p>改变张量的方法用下划线后缀标记。 例如，<code>torch.FloatTensor.abs_()</code>在原位计算绝对值并返回修改后的张量，而<code>torch.FloatTensor.abs()</code>在新张量中计算结果。</p>
<p>注意</p>
<p>要更改现有张量的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 和/或 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> ，请考虑在张量上使用 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 方法。</p>
<p>警告</p>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 的当前实现引入了内存开销，因此，在具有许多微小张量的应用程序中，它可能导致意外的高内存使用率。 如果是这种情况，请考虑使用一种大型结构。</p>
<hr />
<pre><code>class torch.Tensor
</code></pre>
<p>根据您的用例，创建张量的主要方法有几种。</p>
<ul>
<li>
<p>要使用现有数据创建张量，请使用 <a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> 。</p>
</li>
<li>
<p>要创建具有特定大小的张量，请使用<code>torch.*</code>张量创建操作(请参见 <a href="torch.html#tensor-creation-ops">Creation Ops</a>)。</p>
</li>
<li>
<p>要创建与另一个张量具有相同大小(和相似类型）的张量，请使用<code>torch.*_like</code>张量创建操作(请参见<a href="torch.html#tensor-creation-ops">创建操作</a>）。</p>
</li>
<li>
<p>要创建与其他张量具有相似类型但大小不同的张量，请使用<code>tensor.new_*</code>创建操作。</p>
</li>
</ul>
<hr />
<pre><code>new_tensor(data, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回以<code>data</code>作为张量数据的新张量。 默认情况下，返回的张量与此张量具有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>警告</p>
<p><a href="#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>new_tensor()</code></a> 始终复制<code>data</code>。 如果您有张量<code>data</code>并希望避免复制，请使用 <a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>torch.Tensor.requires_grad_()</code></a> 或 <a href="autograd.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>torch.Tensor.detach()</code></a> 。 如果您有一个 numpy 数组并且想要避免复制，请使用 <a href="torch.html#torch.from_numpy" title="torch.from_numpy"><code>torch.from_numpy()</code></a> 。</p>
<p>警告</p>
<p>当数据是张量 <em>x</em> 时， <a href="#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>new_tensor()</code></a> 从传递的任何数据中读出“数据”，并构造一个叶子变量。 因此，<code>tensor.new_tensor(x)</code>等同于<code>x.clone().detach()</code>，<code>tensor.new_tensor(x, requires_grad=True)</code>等同于<code>x.clone().detach().requires_grad_(True)</code>。 建议使用<code>clone()</code>和<code>detach()</code>的等效项。</p>
<p>参数</p>
<ul>
<li>
<p><strong>data</strong> (<em>array_like</em> )–返回的张量副本<code>data</code>。</p>
</li>
<li>
<p><strong>dtype</strong>  (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> ，可选）– 返回张量的所需类型。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 。</p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> ，可选）– 返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
</li>
<li>
<p><strong>require_grad</strong>  (<em>bool</em> <em>，</em> <em>可选</em>）– 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; tensor = torch.ones((2,), dtype=torch.int8)
&gt;&gt;&gt; data = [[0, 1], [2, 3]]
&gt;&gt;&gt; tensor.new_tensor(data)
tensor([[ 0,  1],
        [ 2,  3]], dtype=torch.int8)

</code></pre>
<hr />
<pre><code>new_full(size, fill_value, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的张量，并用<code>fill_value</code>填充。 默认情况下，返回的张量与此张量具有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>参数</p>
<ul>
<li>
<p><strong>fill_value</strong> (<em>标量</em>）–用来填充输出张量的数字。</p>
</li>
<li>
<p><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, optional) – 返回张量的所需类型。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 。</p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, optional) – 返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
</li>
<li>
<p><strong>requires_grad</strong> (<em>bool__,</em> <em>optional</em>) – 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例:</p>
<pre><code>&gt;&gt;&gt; tensor = torch.ones((2,), dtype=torch.float64)
&gt;&gt;&gt; tensor.new_full((3, 4), 3.141592)
tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],
        [ 3.1416,  3.1416,  3.1416,  3.1416],
        [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)

</code></pre>
<hr />
<pre><code>new_empty(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的张量，其中填充了未初始化的数据。 默认情况下，返回的张量具有与此张量相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, optional) – </p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, optional) – 返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
</li>
<li>
<p><strong>requires_grad</strong> (<em>bool__,</em> <em>optional</em>) – 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例:</p>
<pre><code>&gt;&gt;&gt; tensor = torch.ones(())
&gt;&gt;&gt; tensor.new_empty((2, 3))
tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],
        [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])

</code></pre>
<hr />
<pre><code>new_ones(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的张量，并用<code>1</code>填充。 默认情况下，返回的张量与此张量具有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>参数</p>
<ul>
<li>
<p><strong>大小</strong> (<em>python：int ...</em> )–定义输出张量形状的整数列表，元组或<code>torch.Size</code>。</p>
</li>
<li>
<p><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, optional) – 返回张量的所需类型。 默认: 如果是 None, 和 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 一样</p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, optional) – 返回张量所在的设备。 默认: 如果是 None, 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 一样</p>
</li>
<li>
<p><strong>requires_grad</strong> (<em>bool__,</em> <em>optional</em>) – 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例:</p>
<pre><code>&gt;&gt;&gt; tensor = torch.tensor((), dtype=torch.int32)
&gt;&gt;&gt; tensor.new_ones((2, 3))
tensor([[ 1,  1,  1],
        [ 1,  1,  1]], dtype=torch.int32)

</code></pre>
<hr />
<pre><code>new_zeros(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的张量，并用<code>0</code>填充。 默认情况下，返回的张量与此张量具有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>参数</p>
<ul>
<li>
<p><strong>size</strong> (<em>python:int...</em>) – a list, tuple, or <code>torch.Size</code> of integers defining the shape of the output tensor.</p>
</li>
<li>
<p><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, optional) – 返回张量的所需类型。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 。</p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, optional) – 返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
</li>
<li>
<p><strong>requires_grad</strong> (<em>bool__,</em> <em>optional</em>) – 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; tensor = torch.tensor((), dtype=torch.float64)
&gt;&gt;&gt; tensor.new_zeros((2, 3))
tensor([[ 0.,  0.,  0.],
        [ 0.,  0.,  0.]], dtype=torch.float64)

</code></pre>
<pre><code>is_cuda
</code></pre>
<p>如果张量存储在 GPU 上，则为<code>True</code>，否则为<code>False</code>。</p>
<pre><code>device
</code></pre>
<p>张量所在的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<pre><code>grad
</code></pre>
<p>此属性默认为<code>None</code>，并在首次调用 <a href="autograd.html#torch.Tensor.backward" title="torch.Tensor.backward"><code>backward()</code></a> 计算<code>self</code>的梯度时成为张量。 然后，该属性将包含计算出的梯度以及 <a href="autograd.html#torch.Tensor.backward" title="torch.Tensor.backward"><code>backward()</code></a>返回的梯度值，然后进行梯度累加。</p>
<pre><code>ndim
</code></pre>
<p><a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a> 的别名</p>
<pre><code>T
</code></pre>
<p>这个张量的尺寸是否颠倒了吗？</p>
<p>如果<code>n</code>是<code>x</code>中的尺寸数，则<code>x.T</code>等效于<code>x.permute(n-1, n-2, ..., 0)</code>。</p>
<hr />
<pre><code>abs() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.abs" title="torch.abs"><code>torch.abs()</code></a></p>
<hr />
<pre><code>abs_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.abs" title="torch.Tensor.abs"><code>abs()</code></a></p>
<hr />
<pre><code>acos() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.acos" title="torch.acos"><code>torch.acos()</code></a></p>
<hr />
<pre><code>acos_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.acos" title="torch.Tensor.acos"><code>acos()</code></a></p>
<hr />
<pre><code>add(value) → Tensor
</code></pre>
<p>add(value = 1，other）-&gt;张量</p>
<p>参见 <a href="torch.html#torch.add" title="torch.add"><code>torch.add()</code></a></p>
<hr />
<pre><code>add_(value) → Tensor
</code></pre>
<p>add_(value = 1，other）-&gt;张量</p>
<p>就地版本的 <a href="#torch.Tensor.add" title="torch.Tensor.add"><code>add()</code></a></p>
<hr />
<pre><code>addbmm(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.addbmm" title="torch.addbmm"><code>torch.addbmm()</code></a></p>
<hr />
<pre><code>addbmm_(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code>addbmm()</code></a></p>
<hr />
<pre><code>addcdiv(value=1, tensor1, tensor2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.addcdiv" title="torch.addcdiv"><code>torch.addcdiv()</code></a></p>
<hr />
<pre><code>addcdiv_(value=1, tensor1, tensor2) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code>addcdiv()</code></a></p>
<hr />
<pre><code>addcmul(value=1, tensor1, tensor2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.addcmul" title="torch.addcmul"><code>torch.addcmul()</code></a></p>
<hr />
<pre><code>addcmul_(value=1, tensor1, tensor2) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code>addcmul()</code></a></p>
<hr />
<pre><code>addmm(beta=1, alpha=1, mat1, mat2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.addmm" title="torch.addmm"><code>torch.addmm()</code></a></p>
<hr />
<pre><code>addmm_(beta=1, alpha=1, mat1, mat2) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.addmm" title="torch.Tensor.addmm"><code>addmm()</code></a></p>
<hr />
<pre><code>addmv(beta=1, alpha=1, mat, vec) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.addmv" title="torch.addmv"><code>torch.addmv()</code></a></p>
<hr />
<pre><code>addmv_(beta=1, alpha=1, mat, vec) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.addmv" title="torch.Tensor.addmv"><code>addmv()</code></a></p>
<hr />
<pre><code>addr(beta=1, alpha=1, vec1, vec2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.addr" title="torch.addr"><code>torch.addr()</code></a></p>
<hr />
<pre><code>addr_(beta=1, alpha=1, vec1, vec2) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.addr" title="torch.Tensor.addr"><code>addr()</code></a></p>
<hr />
<pre><code>allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.allclose" title="torch.allclose"><code>torch.allclose()</code></a></p>
<hr />
<pre><code>angle() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.angle" title="torch.angle"><code>torch.angle()</code></a></p>
<hr />
<pre><code>apply_(callable) → Tensor
</code></pre>
<p>将函数<code>callable</code>应用于张量中的每个元素，并用<code>callable</code>返回的值替换每个元素。</p>
<p>注意</p>
<p>此功能仅适用于 CPU 张量，不应在需要高性能的代码段中使用。</p>
<hr />
<pre><code>argmax(dim=None, keepdim=False) → LongTensor
</code></pre>
<p>参见 <a href="torch.html#torch.argmax" title="torch.argmax"><code>torch.argmax()</code></a></p>
<hr />
<pre><code>argmin(dim=None, keepdim=False) → LongTensor
</code></pre>
<p>参见 <a href="torch.html#torch.argmin" title="torch.argmin"><code>torch.argmin()</code></a></p>
<hr />
<pre><code>argsort(dim=-1, descending=False) → LongTensor
</code></pre>
<p>参见：func： &lt;cite&gt;torch.argsort&lt;/cite&gt;</p>
<hr />
<pre><code>asin() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.asin" title="torch.asin"><code>torch.asin()</code></a></p>
<hr />
<pre><code>asin_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.asin" title="torch.Tensor.asin"><code>asin()</code></a></p>
<hr />
<pre><code>as_strided(size, stride, storage_offset=0) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.as_strided" title="torch.as_strided"><code>torch.as_strided()</code></a></p>
<hr />
<pre><code>atan() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.atan" title="torch.atan"><code>torch.atan()</code></a></p>
<hr />
<pre><code>atan2(other) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.atan2" title="torch.atan2"><code>torch.atan2()</code></a></p>
<hr />
<pre><code>atan2_(other) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.atan2" title="torch.Tensor.atan2"><code>atan2()</code></a></p>
<hr />
<pre><code>atan_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.atan" title="torch.Tensor.atan"><code>atan()</code></a></p>
<hr />
<pre><code>backward(gradient=None, retain_graph=None, create_graph=False)
</code></pre>
<p>计算当前张量的梯度 w.r.t. 图叶。</p>
<p>该图使用链式法则进行区分。 如果张量是非标量的(即其数据具有多个元素）并且需要梯度，则该函数还需要指定<code>gradient</code>。 它应该是匹配类型和位置的张量，其中包含微分函数 w.r.t 的梯度。 <code>self</code>。</p>
<p>此函数是叶子梯度累加-调用它之前可能需要将它们归零。</p>
<p>参数</p>
<ul>
<li>
<p><strong>gradient</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a> <em>Tensor</em> <em>None</em>）– 梯度 w.r.t. 张量。 如果它是张量，除非<code>create_graph</code>为 True，否则它将自动转换为不需要 grad 的张量。 无法为标量张量或不需要等级的张量指定任何值。 如果 None 值可以接受，那么此参数是可选的。</p>
</li>
<li>
<p><strong>retian_graph</strong>  (<em>bool</em> <em>，</em> <em>可选</em>）– 如果<code>False</code>，则用于计算等级的图形将被释放。 请注意，几乎在所有情况下都不需要将此选项设置为 True，并且通常可以以更有效的方式解决它。 默认为<code>create_graph</code>的值。</p>
</li>
<li>
<p><strong>create_graph</strong>  (<em>bool</em> <em>，</em> <em>可选</em>）– 如果<code>True</code>，则将构造导数图，从而允许计算高阶导数产品。 默认为<code>False</code>。</p>
</li>
</ul>
<hr />
<pre><code>baddbmm(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.baddbmm" title="torch.baddbmm"><code>torch.baddbmm()</code></a></p>
<hr />
<pre><code>baddbmm_(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code>baddbmm()</code></a></p>
<hr />
<pre><code>bernoulli(*, generator=None) → Tensor
</code></pre>
<p>返回结果张量，其中每个<span class="arithmatex">\(result[i]\)</span>从<span class="arithmatex">\(Bernoulli(self[i])\)</span>中独立采样。 <code>self</code>必须具有浮点<code>dtype</code>，结果将具有相同的<code>dtype</code>。</p>
<p>参见 <a href="torch.html#torch.bernoulli" title="torch.bernoulli"><code>torch.bernoulli()</code></a></p>
<hr />
<pre><code>bernoulli_(p=0.5, *, generator=None) → Tensor
</code></pre>
<p>用<span class="arithmatex">\(Bernoulli(p)\)</span>的独立样本填充<code>self</code>的每个位置。 <code>self</code>可以具有整数<code>dtype</code>。</p>
<hr />
<pre><code>bfloat16() → Tensor
</code></pre>
<p><code>self.bfloat16()</code>等效于<code>self.to(torch.bfloat16)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>bincount(weights=None, minlength=0) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.bincount" title="torch.bincount"><code>torch.bincount()</code></a></p>
<hr />
<pre><code>bitwise_not() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.bitwise_not" title="torch.bitwise_not"><code>torch.bitwise_not()</code></a></p>
<hr />
<pre><code>bitwise_not_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.bitwise_not" title="torch.Tensor.bitwise_not"><code>bitwise_not()</code></a></p>
<hr />
<pre><code>bitwise_xor() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.bitwise_xor" title="torch.bitwise_xor"><code>torch.bitwise_xor()</code></a></p>
<hr />
<pre><code>bitwise_xor_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.bitwise_xor" title="torch.Tensor.bitwise_xor"><code>bitwise_xor()</code></a></p>
<hr />
<pre><code>bmm(batch2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.bmm" title="torch.bmm"><code>torch.bmm()</code></a></p>
<hr />
<pre><code>bool() → Tensor
</code></pre>
<p><code>self.bool()</code>等效于<code>self.to(torch.bool)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>byte() → Tensor
</code></pre>
<p><code>self.byte()</code>等效于<code>self.to(torch.uint8)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>cauchy_(median=0, sigma=1, *, generator=None) → Tensor
</code></pre>
<p>用从柯西分布中得出的数字填充张量：</p>
<div class="arithmatex">\[f(x)=\frac {1}{\pi}\frac {\sigma}{(x-median)^2+\sigma^2}\]</div>
<hr />
<pre><code>ceil() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.ceil" title="torch.ceil"><code>torch.ceil()</code></a></p>
<hr />
<pre><code>ceil_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.ceil" title="torch.Tensor.ceil"><code>ceil()</code></a></p>
<hr />
<pre><code>char() → Tensor
</code></pre>
<p><code>self.char()</code>等效于<code>self.to(torch.int8)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>cholesky(upper=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.cholesky" title="torch.cholesky"><code>torch.cholesky()</code></a></p>
<hr />
<pre><code>cholesky_inverse(upper=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.cholesky_inverse" title="torch.cholesky_inverse"><code>torch.cholesky_inverse()</code></a></p>
<hr />
<pre><code>cholesky_solve(input2, upper=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.cholesky_solve" title="torch.cholesky_solve"><code>torch.cholesky_solve()</code></a></p>
<hr />
<pre><code>chunk(chunks, dim=0) → List of Tensors
</code></pre>
<p>参见 <a href="torch.html#torch.chunk" title="torch.chunk"><code>torch.chunk()</code></a></p>
<hr />
<pre><code>clamp(min, max) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.clamp" title="torch.clamp"><code>torch.clamp()</code></a></p>
<hr />
<pre><code>clamp_(min, max) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>clamp()</code></a></p>
<hr />
<pre><code>clone() → Tensor
</code></pre>
<p>返回<code>self</code>张量的副本。 该副本的大小和数据类型与<code>self</code>相同。</p>
<p>注意</p>
<p>与 _copy__()不同，此功能记录在计算图中。 传播到克隆张量的渐变将传播到原始张量。</p>
<hr />
<pre><code>contiguous() → Tensor
</code></pre>
<p>返回包含与<code>self</code>张量相同的数据的连续张量。 如果<code>self</code>张量是连续的，则此函数返回<code>self</code>张量。</p>
<hr />
<pre><code>copy_(src, non_blocking=False) → Tensor
</code></pre>
<p>将元素从<code>src</code>复制到<code>self</code>张量并返回<code>self</code>。</p>
<p><code>src</code>张量必须与<code>self</code>张量一起<a href="注意s/broadcasting.html#broadcasting-semantics">广播</a>。 它可以具有不同的数据类型，也可以位于不同的设备上。</p>
<p>参数</p>
<ul>
<li>
<p><strong>src</strong>  (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–要从中复制的源张量</p>
</li>
<li>
<p><strong>non_blocking</strong>  (<em>bool</em> )–如果<code>True</code>并且此副本位于 CPU 和 GPU 之间，则该副本可能相对于主机异步发生。 在其他情况下，此参数无效。</p>
</li>
</ul>
<hr />
<pre><code>conj() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.conj" title="torch.conj"><code>torch.conj()</code></a></p>
<hr />
<pre><code>cos() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.cos" title="torch.cos"><code>torch.cos()</code></a></p>
<hr />
<pre><code>cos_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.cos" title="torch.Tensor.cos"><code>cos()</code></a></p>
<hr />
<pre><code>cosh() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.cosh" title="torch.cosh"><code>torch.cosh()</code></a></p>
<hr />
<pre><code>cosh_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.cosh" title="torch.Tensor.cosh"><code>cosh()</code></a></p>
<hr />
<pre><code>cpu() → Tensor
</code></pre>
<p>返回此对象在 CPU 内存中的副本。</p>
<p>如果该对象已经在 CPU 内存中并且在正确的设备上，则不执行任何复制操作并返回原始对象。</p>
<hr />
<pre><code>cross(other, dim=-1) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.cross" title="torch.cross"><code>torch.cross()</code></a></p>
<hr />
<pre><code>cuda(device=None, non_blocking=False) → Tensor
</code></pre>
<p>返回此对象在 CUDA 内存中的副本。</p>
<p>如果此对象已经在 CUDA 内存中并且在正确的设备上，则不执行任何复制，并返回原始对象。</p>
<p>参数</p>
<ul>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>) – 目标 GPU 设备。 默认为当前 CUDA 设备。</p>
</li>
<li>
<p><strong>non_blocking</strong>  (<em>bool</em> ) – 如果<code>True</code>并且源位于固定内存中，则副本将相对于主机是异步的。 否则，该参数无效。 默认值：<code>False</code>。</p>
</li>
</ul>
<hr />
<pre><code>cumprod(dim, dtype=None) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.cumprod" title="torch.cumprod"><code>torch.cumprod()</code></a></p>
<hr />
<pre><code>cumsum(dim, dtype=None) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.cumsum" title="torch.cumsum"><code>torch.cumsum()</code></a></p>
<hr />
<pre><code>data_ptr() → int
</code></pre>
<p>返回<code>self</code>张量的第一个元素的地址。</p>
<hr />
<pre><code>dequantize() → Tensor
</code></pre>
<p>给定量化的张量，对其进行反量化，然后返回反量化后的浮点张量。</p>
<hr />
<pre><code>det() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.det" title="torch.det"><code>torch.det()</code></a></p>
<hr />
<pre><code>dense_dim() → int
</code></pre>
<p>如果<code>self</code>是稀疏的 COO 张量(即<code>torch.sparse_coo</code>布局），则返回密集尺寸的数量。 否则，将引发错误。</p>
<p>另请参见 <a href="#torch.Tensor.sparse_dim" title="torch.Tensor.sparse_dim"><code>Tensor.sparse_dim()</code></a> 。</p>
<hr />
<pre><code>detach()
</code></pre>
<p>返回与当前图形分离的新 Tensor。</p>
<p>结果将永远不需要梯度。</p>
<p>注意</p>
<p>返回的 Tensor 与原始 Tensor 共享相同的存储。 可以看到对它们中的任何一个的就地修改，并且可能触发正确性检查中的错误。 重要说明：以前，就地大小/步幅/存储更改(例如 _resize__/_resize_as__/_set__/_transpose__) 返回的张量也会更新原始张量。 现在，这些就地更改将不再更新原始张量，而将触发错误。 对于稀疏张量：原位索引 / 值更改(例如 _zero__/_copy__/_add__)将不会再更新原始张量， 而是触发错误。</p>
<hr />
<pre><code>detach_()
</code></pre>
<p>从创建它的图形中分离张量，使其成为一片叶子。 视图不能就地分离。</p>
<hr />
<pre><code>diag(diagonal=0) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.diag" title="torch.diag"><code>torch.diag()</code></a></p>
<hr />
<pre><code>diag_embed(offset=0, dim1=-2, dim2=-1) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.diag_embed" title="torch.diag_embed"><code>torch.diag_embed()</code></a></p>
<hr />
<pre><code>diagflat(offset=0) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.diagflat" title="torch.diagflat"><code>torch.diagflat()</code></a></p>
<hr />
<pre><code>diagonal(offset=0, dim1=0, dim2=1) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.diagonal" title="torch.diagonal"><code>torch.diagonal()</code></a></p>
<hr />
<pre><code>fill_diagonal_(fill_value, wrap=False) → Tensor
</code></pre>
<p>填充具有至少 2 维的张量的主对角线。 当&gt; 2 变暗时，所有输入尺寸必须相等。 此函数就地修改输入张量，并返回输入张量。</p>
<p>参数</p>
<ul>
<li>
<p><strong>fill_value</strong> (<em>标量</em>）– 填充值</p>
</li>
<li>
<p><strong>wrap</strong> (<em>bool</em> ) – 对角线“包裹”在高列的 N 列之后。</p>
</li>
</ul>
<p>例:</p>
<pre><code>&gt;&gt;&gt; a = torch.zeros(3, 3)
&gt;&gt;&gt; a.fill_diagonal_(5)
tensor([[5., 0., 0.],
        [0., 5., 0.],
        [0., 0., 5.]])
&gt;&gt;&gt; b = torch.zeros(7, 3)
&gt;&gt;&gt; b.fill_diagonal_(5)
tensor([[5., 0., 0.],
        [0., 5., 0.],
        [0., 0., 5.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
&gt;&gt;&gt; c = torch.zeros(7, 3)
&gt;&gt;&gt; c.fill_diagonal_(5, wrap=True)
tensor([[5., 0., 0.],
        [0., 5., 0.],
        [0., 0., 5.],
        [0., 0., 0.],
        [5., 0., 0.],
        [0., 5., 0.],
        [0., 0., 5.]])

</code></pre>
<hr />
<pre><code>digamma() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.digamma" title="torch.digamma"><code>torch.digamma()</code></a></p>
<hr />
<pre><code>digamma_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.digamma" title="torch.Tensor.digamma"><code>digamma()</code></a></p>
<hr />
<pre><code>dim() → int
</code></pre>
<p>返回<code>self</code>张量的维数。</p>
<hr />
<pre><code>dist(other, p=2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.dist" title="torch.dist"><code>torch.dist()</code></a></p>
<hr />
<pre><code>div(value) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.div" title="torch.div"><code>torch.div()</code></a></p>
<hr />
<pre><code>div_(value) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.div" title="torch.Tensor.div"><code>div()</code></a></p>
<hr />
<pre><code>dot(tensor2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.dot" title="torch.dot"><code>torch.dot()</code></a></p>
<hr />
<pre><code>double() → Tensor
</code></pre>
<p><code>self.double()</code>等效于<code>self.to(torch.float64)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>eig(eigenvectors=False) -&gt; (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.eig" title="torch.eig"><code>torch.eig()</code></a></p>
<hr />
<pre><code>element_size() → int
</code></pre>
<p>返回单个元素的大小(以字节为单位）。</p>
<p>例:</p>
<pre><code>&gt;&gt;&gt; torch.tensor([]).element_size()
4
&gt;&gt;&gt; torch.tensor([], dtype=torch.uint8).element_size()
1

</code></pre>
<hr />
<pre><code>eq(other) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.eq" title="torch.eq"><code>torch.eq()</code></a></p>
<hr />
<pre><code>eq_(other) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.eq" title="torch.Tensor.eq"><code>eq()</code></a></p>
<hr />
<pre><code>equal(other) → bool
</code></pre>
<p>参见 <a href="torch.html#torch.equal" title="torch.equal"><code>torch.equal()</code></a></p>
<hr />
<pre><code>erf() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.erf" title="torch.erf"><code>torch.erf()</code></a></p>
<hr />
<pre><code>erf_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.erf" title="torch.Tensor.erf"><code>erf()</code></a></p>
<hr />
<pre><code>erfc() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.erfc" title="torch.erfc"><code>torch.erfc()</code></a></p>
<hr />
<pre><code>erfc_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.erfc" title="torch.Tensor.erfc"><code>erfc()</code></a></p>
<hr />
<pre><code>erfinv() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.erfinv" title="torch.erfinv"><code>torch.erfinv()</code></a></p>
<hr />
<pre><code>erfinv_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code>erfinv()</code></a></p>
<hr />
<pre><code>exp() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.exp" title="torch.exp"><code>torch.exp()</code></a></p>
<hr />
<pre><code>exp_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.exp" title="torch.Tensor.exp"><code>exp()</code></a></p>
<hr />
<pre><code>expm1() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.expm1" title="torch.expm1"><code>torch.expm1()</code></a></p>
<hr />
<pre><code>expm1_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.expm1" title="torch.Tensor.expm1"><code>expm1()</code></a></p>
<hr />
<pre><code>expand(*sizes) → Tensor
</code></pre>
<p>返回<code>self</code>张量的新视图，其中单例尺寸扩展为更大的尺寸。</p>
<p>将-1 传递为尺寸的大小表示不更改该尺寸的大小。</p>
<p>Tensor 也可以扩展到更大的尺寸，并且新尺寸将附加在前面。 对于新尺寸，尺寸不能设置为-1。</p>
<p>扩展张量不会分配新的内存，而只会在现有张量上创建一个新视图，其中通过将<code>stride</code>设置为 0，将尺寸为 1 的维扩展为更大的尺寸。尺寸为 1 的任何维都可以扩展为 不分配新内存的任意值。</p>
<p>参数</p>
<p><strong>*大小</strong>(<em>torch大小</em> <em>或</em> <em>python：int ...</em> )–所需的扩展大小</p>
<p>警告</p>
<p>扩展张量的一个以上元素可以引用单个存储位置。 结果，就地操作(尤其是矢量化的操作）可能会导致错误的行为。 如果需要写张量，请先克隆它们。</p>
<p>例:</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([[1], [2], [3]])
&gt;&gt;&gt; x.size()
torch.Size([3, 1])
&gt;&gt;&gt; x.expand(3, 4)
tensor([[ 1,  1,  1,  1],
        [ 2,  2,  2,  2],
        [ 3,  3,  3,  3]])
&gt;&gt;&gt; x.expand(-1, 4)   # -1 means not changing the size of that dimension
tensor([[ 1,  1,  1,  1],
        [ 2,  2,  2,  2],
        [ 3,  3,  3,  3]])

</code></pre>
<hr />
<pre><code>expand_as(other) → Tensor
</code></pre>
<p>将该张量扩展为与<code>other</code>相同的大小。 <code>self.expand_as(other)</code>等效于<code>self.expand(other.size())</code>。</p>
<p>有关<code>expand</code>的更多信息，请参见 <a href="#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand()</code></a> 。</p>
<p>参数</p>
<p><strong>其他</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>)–结果张量的大小与<code>other</code>相同。</p>
<hr />
<pre><code>exponential_(lambd=1, *, generator=None) → Tensor
</code></pre>
<p>用从指数分布中绘制的元素填充<code>self</code>张量：</p>
<div class="arithmatex">\[f(x)=\lambda e^{-\lambda x}\]</div>
<hr />
<pre><code>fft(signal_ndim, normalized=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.fft" title="torch.fft"><code>torch.fft()</code></a></p>
<hr />
<pre><code>fill_(value) → Tensor
</code></pre>
<p>用指定值填充<code>self</code>张量。</p>
<hr />
<pre><code>flatten(input, start_dim=0, end_dim=-1) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.flatten" title="torch.flatten"><code>torch.flatten()</code></a></p>
<hr />
<pre><code>flip(dims) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.flip" title="torch.flip"><code>torch.flip()</code></a></p>
<hr />
<pre><code>float() → Tensor
</code></pre>
<p><code>self.float()</code>等效于<code>self.to(torch.float32)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>floor() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.floor" title="torch.floor"><code>torch.floor()</code></a></p>
<hr />
<pre><code>floor_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.floor" title="torch.Tensor.floor"><code>floor()</code></a></p>
<hr />
<pre><code>fmod(divisor) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.fmod" title="torch.fmod"><code>torch.fmod()</code></a></p>
<hr />
<pre><code>fmod_(divisor) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.fmod" title="torch.Tensor.fmod"><code>fmod()</code></a></p>
<hr />
<pre><code>frac() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.frac" title="torch.frac"><code>torch.frac()</code></a></p>
<hr />
<pre><code>frac_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.frac" title="torch.Tensor.frac"><code>frac()</code></a></p>
<hr />
<pre><code>gather(dim, index) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.gather" title="torch.gather"><code>torch.gather()</code></a></p>
<hr />
<pre><code>ge(other) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.ge" title="torch.ge"><code>torch.ge()</code></a></p>
<hr />
<pre><code>ge_(other) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.ge" title="torch.Tensor.ge"><code>ge()</code></a></p>
<hr />
<pre><code>geometric_(p, *, generator=None) → Tensor
</code></pre>
<p>用从几何分布中绘制的元素填充<code>self</code>张量：</p>
<div class="arithmatex">\[f(X=k)=p^{k-1}(1-p)\]</div>
<hr />
<pre><code>geqrf() -&gt; (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.geqrf" title="torch.geqrf"><code>torch.geqrf()</code></a></p>
<hr />
<pre><code>ger(vec2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.ger" title="torch.ger"><code>torch.ger()</code></a></p>
<hr />
<pre><code>get_device() -&gt; Device ordinal (Integer)
</code></pre>
<p>对于 CUDA 张量，此函数返回张量所在的 GPU 的设备序号。 对于 CPU 张量，将引发错误。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.randn(3, 4, 5, device='cuda:0')
&gt;&gt;&gt; x.get_device()
0
&gt;&gt;&gt; x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor

</code></pre>
<hr />
<pre><code>gt(other) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.gt" title="torch.gt"><code>torch.gt()</code></a></p>
<hr />
<pre><code>gt_(other) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.gt" title="torch.Tensor.gt"><code>gt()</code></a></p>
<hr />
<pre><code>half() → Tensor
</code></pre>
<p><code>self.half()</code>等效于<code>self.to(torch.float16)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>hardshrink(lambd=0.5) → Tensor
</code></pre>
<p>参见 <a href="nn.functional.html#torch.nn.functional.hardshrink" title="torch.nn.functional.hardshrink"><code>torch.nn.functional.hardshrink()</code></a></p>
<hr />
<pre><code>histc(bins=100, min=0, max=0) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.histc" title="torch.histc"><code>torch.histc()</code></a></p>
<hr />
<pre><code>ifft(signal_ndim, normalized=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.ifft" title="torch.ifft"><code>torch.ifft()</code></a></p>
<hr />
<pre><code>imag() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.imag" title="torch.imag"><code>torch.imag()</code></a></p>
<hr />
<pre><code>index_add_(dim, index, tensor) → Tensor
</code></pre>
<p>通过按<code>index</code>中给定的顺序添加索引，将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的元素累积到<code>self</code>张量中。 例如，如果<code>dim == 0</code>和<code>index[i] == j</code>，则将<a href="torch.html#torch.tensor" title="torch.tensor">的第<code>i</code>行<code>tensor</code></a> 添加到<code>self</code>的第<code>j</code>行。</p>
<p><a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 尺寸必须与<code>index</code>的长度(必须为矢量）的尺寸相同，并且所有其他尺寸必须与<code>self</code> ]，否则将引发错误。</p>
<p>注意</p>
<p>使用 CUDA 后端时，此操作可能会导致不确定的行为，不容易关闭。 有关背景，请参见<a href="注意s/randomness.html">重现性</a>的注释。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python：int</em> )–索引所沿的维度</p>
</li>
<li>
<p><strong>索引</strong> (<em>LongTensor</em> )– <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的索引</p>
</li>
<li>
<p><strong>张量</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–张量包含要添加的值</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.ones(5, 3)
&gt;&gt;&gt; t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
&gt;&gt;&gt; index = torch.tensor([0, 4, 2])
&gt;&gt;&gt; x.index_add_(0, index, t)
tensor([[  2.,   3.,   4.],
        [  1.,   1.,   1.],
        [  8.,   9.,  10.],
        [  1.,   1.,   1.],
        [  5.,   6.,   7.]])

</code></pre>
<hr />
<pre><code>index_add(dim, index, tensor) → Tensor
</code></pre>
<p><a href="#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code>torch.Tensor.index_add_()</code></a> 的替代版本</p>
<hr />
<pre><code>index_copy_(dim, index, tensor) → Tensor
</code></pre>
<p>通过按<code>index</code>中给定的顺序选择索引，将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的元素复制到<code>self</code>张量中。 例如，如果<code>dim == 0</code>和<code>index[i] == j</code>，则将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的第<code>i</code>行复制到<code>self</code>的第<code>j</code>行。</p>
<p>The <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a>th dimension of <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> must have the same size as the length of <code>index</code> (which must be a vector), and all other dimensions must match <code>self</code>, or an error will be raised.</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python:int</em>) – dimension along which to index</p>
</li>
<li>
<p><strong>index</strong> (<em>LongTensor</em>) – indices of <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> to select from</p>
</li>
<li>
<p><strong>张量</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–张量包含要复制的值</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.zeros(5, 3)
&gt;&gt;&gt; t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
&gt;&gt;&gt; index = torch.tensor([0, 4, 2])
&gt;&gt;&gt; x.index_copy_(0, index, t)
tensor([[ 1.,  2.,  3.],
        [ 0.,  0.,  0.],
        [ 7.,  8.,  9.],
        [ 0.,  0.,  0.],
        [ 4.,  5.,  6.]])

</code></pre>
<hr />
<pre><code>index_copy(dim, index, tensor) → Tensor
</code></pre>
<p><a href="#torch.Tensor.index_copy_" title="torch.Tensor.index_copy_"><code>torch.Tensor.index_copy_()</code></a> 的替代版本</p>
<hr />
<pre><code>index_fill_(dim, index, val) → Tensor
</code></pre>
<p>通过按<code>index</code>中给定的顺序选择索引，用值<code>val</code>填充<code>self</code>张量的元素。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python:int</em>) – dimension along which to index</p>
</li>
<li>
<p><strong>索引</strong> (<em>LongTensor</em> )–填写的<code>self</code>张量索引</p>
</li>
<li>
<p><strong>val</strong>  (<em>python：float</em> )–要填充的值</p>
</li>
</ul>
<pre><code>例：:
</code></pre>
<pre><code>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
&gt;&gt;&gt; index = torch.tensor([0, 2])
&gt;&gt;&gt; x.index_fill_(1, index, -1)
tensor([[-1.,  2., -1.],
        [-1.,  5., -1.],
        [-1.,  8., -1.]])

</code></pre>
<hr />
<pre><code>index_fill(dim, index, value) → Tensor
</code></pre>
<p><a href="#torch.Tensor.index_fill_" title="torch.Tensor.index_fill_"><code>torch.Tensor.index_fill_()</code></a> 的替代版本</p>
<hr />
<pre><code>index_put_(indices, value, accumulate=False) → Tensor
</code></pre>
<p>使用在 <a href="#torch.Tensor.indices" title="torch.Tensor.indices"><code>indices</code></a> 中指定的索引(张量的元组）将张量<code>value</code>的值放入张量<code>self</code>。 表达式<code>tensor.index_put_(indices, value)</code>等效于<code>tensor[indices] = value</code>。 返回<code>self</code>。</p>
<p>如果<code>accumulate</code>为<code>True</code>，则将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素添加到<code>self</code>中。 如果 accumulate 为<code>False</code>，则在索引包含重复元素的情况下行为未定义。</p>
<p>参数</p>
<ul>
<li>
<p><strong>索引</strong>(LongTensor 的_元组）–用于索引&lt;cite&gt;自身&lt;/cite&gt;的张量。_</p>
</li>
<li>
<p><strong>值</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–与&lt;cite&gt;自身&lt;/cite&gt;相同类型的张量。</p>
</li>
<li>
<p><strong>累积</strong> (<em>bool</em> )–是否累积</p>
</li>
</ul>
<hr />
<pre><code>index_put(indices, value, accumulate=False) → Tensor
</code></pre>
<p><a href="#torch.Tensor.index_put_" title="torch.Tensor.index_put_"><code>index_put_()</code></a> 的替代版本</p>
<hr />
<pre><code>index_select(dim, index) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.index_select" title="torch.index_select"><code>torch.index_select()</code></a></p>
<hr />
<pre><code>indices() → Tensor
</code></pre>
<p>如果<code>self</code>是稀疏的 COO 张量(即<code>torch.sparse_coo</code>布局），则返回包含的索引张量的视图。 否则，将引发错误。</p>
<p>另请参见 <a href="#torch.Tensor.values" title="torch.Tensor.values"><code>Tensor.values()</code></a> 。</p>
<p>注意</p>
<p>只能在合并的稀疏张量上调用此方法。 有关详细信息，请参见<code>Tensor.coalesce()</code>。</p>
<hr />
<pre><code>int() → Tensor
</code></pre>
<p><code>self.int()</code>等效于<code>self.to(torch.int32)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>int_repr() → Tensor
</code></pre>
<p>给定量化的 Tensor，<code>self.int_repr()</code>返回以 uint8_t 作为数据类型的 CPU Tensor，该数据类型存储给定 Tensor 的基础 uint8_t 值。</p>
<hr />
<pre><code>inverse() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.inverse" title="torch.inverse"><code>torch.inverse()</code></a></p>
<hr />
<pre><code>irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.irfft" title="torch.irfft"><code>torch.irfft()</code></a></p>
<hr />
<pre><code>is_contiguous() → bool
</code></pre>
<p>如果<code>self</code>张量在内存中以 C 顺序连续，则返回 True。</p>
<hr />
<pre><code>is_floating_point() → bool
</code></pre>
<p>如果<code>self</code>的数据类型是浮点数据类型，则返回 True。</p>
<pre><code>is_leaf
</code></pre>
<p>按照惯例，所有具有 <a href="autograd.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> 即<code>False</code>的张量将是叶张量。</p>
<p>对于具有 <a href="autograd.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> (即<code>True</code>）的张量，如果它们是由用户创建的，则它们将是叶张量。 这意味着它们不是运算的结果，因此<code>grad_fn</code>为“无”。</p>
<p>在调用 <a href="autograd.html#torch.Tensor.backward" title="torch.Tensor.backward"><code>backward()</code></a> 期间，仅叶子张量会填充其 <a href="autograd.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>grad</code></a> 。 要为非叶张量填充 <a href="autograd.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>grad</code></a> ，可以使用 <a href="autograd.html#torch.Tensor.retain_grad" title="torch.Tensor.retain_grad"><code>retain_grad()</code></a> 。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; a = torch.rand(10, requires_grad=True)
&gt;&gt;&gt; a.is_leaf
True
&gt;&gt;&gt; b = torch.rand(10, requires_grad=True).cuda()
&gt;&gt;&gt; b.is_leaf
False
# b was created by the operation that cast a cpu Tensor into a cuda Tensor
&gt;&gt;&gt; c = torch.rand(10, requires_grad=True) + 2
&gt;&gt;&gt; c.is_leaf
False
# c was created by the addition operation
&gt;&gt;&gt; d = torch.rand(10).cuda()
&gt;&gt;&gt; d.is_leaf
True
# d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)
&gt;&gt;&gt; e = torch.rand(10).cuda().requires_grad_()
&gt;&gt;&gt; e.is_leaf
True
# e requires gradients and has no operations creating it
&gt;&gt;&gt; f = torch.rand(10, requires_grad=True, device=&quot;cuda&quot;)
&gt;&gt;&gt; f.is_leaf
True
# f requires grad, has no operation creating it

</code></pre>
<hr />
<pre><code>is_pinned()
</code></pre>
<p>如果该张量驻留在固定的内存中，则返回 true。</p>
<hr />
<pre><code>is_set_to(tensor) → bool
</code></pre>
<p>如果此对象引用与 Torch C API 中相同的<code>THTensor</code>对象作为给定张量，则返回 True。</p>
<hr />
<pre><code>is_shared()
</code></pre>
<p>检查张量是否在共享内存中。</p>
<p>CUDA 张量始终为<code>True</code>。</p>
<hr />
<pre><code>is_signed() → bool
</code></pre>
<p>如果<code>self</code>的数据类型是带符号的数据类型，则返回 True。</p>
<pre><code>is_sparse
</code></pre>
<hr />
<pre><code>item() → number
</code></pre>
<p>返回此张量的值作为标准 Python 数。 这仅适用于具有一个元素的张量。 对于其他情况，请参见 <a href="#torch.Tensor.tolist" title="torch.Tensor.tolist"><code>tolist()</code></a> 。</p>
<p>此操作不可区分。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([1.0])
&gt;&gt;&gt; x.item()
1.0

</code></pre>
<hr />
<pre><code>kthvalue(k, dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre>
<p>参见 <a href="torch.html#torch.kthvalue" title="torch.kthvalue"><code>torch.kthvalue()</code></a></p>
<hr />
<pre><code>le(other) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.le" title="torch.le"><code>torch.le()</code></a></p>
<hr />
<pre><code>le_(other) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.le" title="torch.Tensor.le"><code>le()</code></a></p>
<hr />
<pre><code>lerp(end, weight) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.lerp" title="torch.lerp"><code>torch.lerp()</code></a></p>
<hr />
<pre><code>lerp_(end, weight) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.lerp" title="torch.Tensor.lerp"><code>lerp()</code></a></p>
<hr />
<pre><code>lgamma() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.lgamma" title="torch.lgamma"><code>torch.lgamma()</code></a></p>
<hr />
<pre><code>lgamma_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.lgamma" title="torch.Tensor.lgamma"><code>lgamma()</code></a></p>
<hr />
<pre><code>log() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.log" title="torch.log"><code>torch.log()</code></a></p>
<hr />
<pre><code>log_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.log" title="torch.Tensor.log"><code>log()</code></a></p>
<hr />
<pre><code>logdet() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.logdet" title="torch.logdet"><code>torch.logdet()</code></a></p>
<hr />
<pre><code>log10() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.log10" title="torch.log10"><code>torch.log10()</code></a></p>
<hr />
<pre><code>log10_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.log10" title="torch.Tensor.log10"><code>log10()</code></a></p>
<hr />
<pre><code>log1p() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.log1p" title="torch.log1p"><code>torch.log1p()</code></a></p>
<hr />
<pre><code>log1p_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.log1p" title="torch.Tensor.log1p"><code>log1p()</code></a></p>
<hr />
<pre><code>log2() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.log2" title="torch.log2"><code>torch.log2()</code></a></p>
<hr />
<pre><code>log2_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.log2" title="torch.Tensor.log2"><code>log2()</code></a></p>
<hr />
<pre><code>log_normal_(mean=1, std=2, *, generator=None)
</code></pre>
<p>用对数正态分布中由给定平均值<img alt="" src="../img/fba1f12214374ac856c1e4be142c9dff.jpg" />和标准偏差<img alt="" src="../img/cc84e998f72a1c5a0a5f736ba6a9ff34.jpg" />参数化的数字样本填充<code>self</code>张量。 请注意， <a href="torch.html#torch.mean" title="torch.mean"><code>mean</code></a> 和 <a href="torch.html#torch.std" title="torch.std"><code>std</code></a> 是基础正态分布的均值和标准偏差，而不是返回的正态分布：</p>
<div class="arithmatex">\[f(x)=\frac {1}{x\sigma \sqrt {2\pi}}e^{-\frac {(lnx - \mu)^2}{2\sigma^2}}\]</div>
<hr />
<pre><code>logsumexp(dim, keepdim=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.logsumexp" title="torch.logsumexp"><code>torch.logsumexp()</code></a></p>
<hr />
<pre><code>logical_not() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.logical_not" title="torch.logical_not"><code>torch.logical_not()</code></a></p>
<hr />
<pre><code>logical_not_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.logical_not" title="torch.Tensor.logical_not"><code>logical_not()</code></a></p>
<hr />
<pre><code>logical_xor() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.logical_xor" title="torch.logical_xor"><code>torch.logical_xor()</code></a></p>
<hr />
<pre><code>logical_xor_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.logical_xor" title="torch.Tensor.logical_xor"><code>logical_xor()</code></a></p>
<hr />
<pre><code>long() → Tensor
</code></pre>
<p><code>self.long()</code>等效于<code>self.to(torch.int64)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>lstsq(A) -&gt; (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.lstsq" title="torch.lstsq"><code>torch.lstsq()</code></a></p>
<hr />
<pre><code>lt(other) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.lt" title="torch.lt"><code>torch.lt()</code></a></p>
<hr />
<pre><code>lt_(other) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.lt" title="torch.Tensor.lt"><code>lt()</code></a></p>
<hr />
<pre><code>lu(pivot=True, get_infos=False)
</code></pre>
<p>参见 <a href="torch.html#torch.lu" title="torch.lu"><code>torch.lu()</code></a></p>
<hr />
<pre><code>lu_solve(LU_data, LU_pivots) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.lu_solve" title="torch.lu_solve"><code>torch.lu_solve()</code></a></p>
<hr />
<pre><code>map_(tensor, callable)
</code></pre>
<p>对<code>self</code>张量中的每个元素和给定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 应用<code>callable</code>，并将结果存储在<code>self</code>张量中。 <code>self</code>张量和给定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 必须是<a href="注意s/broadcasting.html#broadcasting-semantics">可广播的</a>。</p>
<p><code>callable</code>应具有签名：</p>
<pre><code>def callable(a, b) -&gt; number

</code></pre>
<hr />
<pre><code>masked_scatter_(mask, source)
</code></pre>
<p>在<code>mask</code>为 True 的位置将元素从<code>source</code>复制到<code>self</code>张量。 <code>mask</code>的形状必须是<a href="注意s/broadcasting.html#broadcasting-semantics">可广播的</a>，并具有基础张量的形状。 <code>source</code>中的元素数量至少应与<code>mask</code>中的元素数量一样多。</p>
<p>参数</p>
<ul>
<li>
<p><strong>掩码</strong> (<a href="#torch.BoolTensor" title="torch.BoolTensor"><em>BoolTensor</em></a>)–布尔掩码</p>
</li>
<li>
<p><strong>源</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–要从中复制的张量</p>
</li>
</ul>
<p>注意</p>
<p><code>mask</code>在<code>self</code>张量上运行，而不是在给定的<code>source</code>张量上运行。</p>
<hr />
<pre><code>masked_scatter(mask, tensor) → Tensor
</code></pre>
<p><a href="#torch.Tensor.masked_scatter_" title="torch.Tensor.masked_scatter_"><code>torch.Tensor.masked_scatter_()</code></a> 的替代版本</p>
<hr />
<pre><code>masked_fill_(mask, value)
</code></pre>
<p>用<code>value</code>填充<code>self</code>张量的元素，其中<code>mask</code>为 True。 <code>mask</code>的形状必须是<a href="注意s/broadcasting.html#broadcasting-semantics">可广播的</a>，并具有基础张量的形状。</p>
<p>参数</p>
<ul>
<li>
<p><strong>mask</strong> (<a href="#torch.BoolTensor" title="torch.BoolTensor"><em>BoolTensor</em></a>) – the boolean mask</p>
</li>
<li>
<p><strong>值</strong> (<em>python：float</em> )–要填写的值</p>
</li>
</ul>
<hr />
<pre><code>masked_fill(mask, value) → Tensor
</code></pre>
<p><a href="#torch.Tensor.masked_fill_" title="torch.Tensor.masked_fill_"><code>torch.Tensor.masked_fill_()</code></a> 的替代版本</p>
<hr />
<pre><code>masked_select(mask) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.masked_select" title="torch.masked_select"><code>torch.masked_select()</code></a></p>
<hr />
<pre><code>matmul(tensor2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.matmul" title="torch.matmul"><code>torch.matmul()</code></a></p>
<hr />
<pre><code>matrix_power(n) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.matrix_power" title="torch.matrix_power"><code>torch.matrix_power()</code></a></p>
<hr />
<pre><code>max(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.max" title="torch.max"><code>torch.max()</code></a></p>
<hr />
<pre><code>mean(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.mean" title="torch.mean"><code>torch.mean()</code></a></p>
<hr />
<pre><code>median(dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre>
<p>参见 <a href="torch.html#torch.median" title="torch.median"><code>torch.median()</code></a></p>
<hr />
<pre><code>min(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.min" title="torch.min"><code>torch.min()</code></a></p>
<hr />
<pre><code>mm(mat2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.mm" title="torch.mm"><code>torch.mm()</code></a></p>
<hr />
<pre><code>mode(dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre>
<p>参见 <a href="torch.html#torch.mode" title="torch.mode"><code>torch.mode()</code></a></p>
<hr />
<pre><code>mul(value) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.mul" title="torch.mul"><code>torch.mul()</code></a></p>
<hr />
<pre><code>mul_(value)
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.mul" title="torch.Tensor.mul"><code>mul()</code></a></p>
<hr />
<pre><code>multinomial(num_samples, replacement=False, *, generator=None) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.multinomial" title="torch.multinomial"><code>torch.multinomial()</code></a></p>
<hr />
<pre><code>mv(vec) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.mv" title="torch.mv"><code>torch.mv()</code></a></p>
<hr />
<pre><code>mvlgamma(p) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.mvlgamma" title="torch.mvlgamma"><code>torch.mvlgamma()</code></a></p>
<hr />
<pre><code>mvlgamma_(p) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code>mvlgamma()</code></a></p>
<hr />
<pre><code>narrow(dimension, start, length) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.narrow" title="torch.narrow"><code>torch.narrow()</code></a></p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
&gt;&gt;&gt; x.narrow(0, 0, 2)
tensor([[ 1,  2,  3],
        [ 4,  5,  6]])
&gt;&gt;&gt; x.narrow(1, 1, 2)
tensor([[ 2,  3],
        [ 5,  6],
        [ 8,  9]])

</code></pre>
<hr />
<pre><code>narrow_copy(dimension, start, length) → Tensor
</code></pre>
<p>与 <a href="#torch.Tensor.narrow" title="torch.Tensor.narrow"><code>Tensor.narrow()</code></a> 相同，只是返回副本而不是共享存储。 这主要用于稀疏张量，它们没有共享存储的窄方法。 用<code>dimemsion &amp;gt; self.sparse_dim()</code>调用<code>narrow_copy`将返回缩小了相关密集尺寸的副本，并相应地更新了</code>self.shape``。</p>
<hr />
<pre><code>ndimension() → int
</code></pre>
<p>Alias for <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a></p>
<hr />
<pre><code>ne(other) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.ne" title="torch.ne"><code>torch.ne()</code></a></p>
<hr />
<pre><code>ne_(other) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.ne" title="torch.Tensor.ne"><code>ne()</code></a></p>
<hr />
<pre><code>neg() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.neg" title="torch.neg"><code>torch.neg()</code></a></p>
<hr />
<pre><code>neg_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.neg" title="torch.Tensor.neg"><code>neg()</code></a></p>
<hr />
<pre><code>nelement() → int
</code></pre>
<p><a href="#torch.Tensor.numel" title="torch.Tensor.numel"><code>numel()</code></a> 的别名</p>
<hr />
<pre><code>nonzero() → LongTensor
</code></pre>
<p>参见 <a href="torch.html#torch.nonzero" title="torch.nonzero"><code>torch.nonzero()</code></a></p>
<hr />
<pre><code>norm(p='fro', dim=None, keepdim=False, dtype=None)
</code></pre>
<p>参见 <a href="torch.html#torch.norm" title="torch.norm"><code>torch.norm()</code></a></p>
<hr />
<pre><code>normal_(mean=0, std=1, *, generator=None) → Tensor
</code></pre>
<p>用由 <a href="torch.html#torch.mean" title="torch.mean"><code>mean</code></a> 和 <a href="torch.html#torch.std" title="torch.std"><code>std</code></a> 参数化的正态分布的元素样本填充<code>self</code>张量。</p>
<hr />
<pre><code>numel() → int
</code></pre>
<p>参见 <a href="torch.html#torch.numel" title="torch.numel"><code>torch.numel()</code></a></p>
<hr />
<pre><code>numpy() → numpy.ndarray
</code></pre>
<p>以 NumPy <code>ndarray</code>的形式返回<code>self</code>张量。 该张量和返回的<code>ndarray</code>共享相同的基础存储。 对<code>self</code>张量的更改将反映在<code>ndarray</code>中，反之亦然。</p>
<hr />
<pre><code>orgqr(input2) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.orgqr" title="torch.orgqr"><code>torch.orgqr()</code></a></p>
<hr />
<pre><code>ormqr(input2, input3, left=True, transpose=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.ormqr" title="torch.ormqr"><code>torch.ormqr()</code></a></p>
<hr />
<pre><code>permute(*dims) → Tensor
</code></pre>
<p>置换此张量的尺寸。</p>
<p>参数</p>
<p><strong>*dims</strong> (<em>python：int ...</em> ) – 所需的维度顺序</p>
<p>例:</p>
<pre><code>&gt;&gt;&gt; x = torch.randn(2, 3, 5)
&gt;&gt;&gt; x.size()
torch.Size([2, 3, 5])
&gt;&gt;&gt; x.permute(2, 0, 1).size()
torch.Size([5, 2, 3])

</code></pre>
<hr />
<pre><code>pin_memory() → Tensor
</code></pre>
<p>将张量复制到固定的内存(如果尚未固定）。</p>
<hr />
<pre><code>pinverse() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.pinverse" title="torch.pinverse"><code>torch.pinverse()</code></a></p>
<hr />
<pre><code>polygamma(n) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.polygamma" title="torch.polygamma"><code>torch.polygamma()</code></a></p>
<hr />
<pre><code>polygamma_(n) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.polygamma" title="torch.Tensor.polygamma"><code>polygamma()</code></a></p>
<hr />
<pre><code>pow(exponent) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.pow" title="torch.pow"><code>torch.pow()</code></a></p>
<hr />
<pre><code>pow_(exponent) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.pow" title="torch.Tensor.pow"><code>pow()</code></a></p>
<hr />
<pre><code>prod(dim=None, keepdim=False, dtype=None) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.prod" title="torch.prod"><code>torch.prod()</code></a></p>
<hr />
<pre><code>put_(indices, tensor, accumulate=False) → Tensor
</code></pre>
<p>将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素复制到索引指定的位置。 为了建立索引，将<code>self</code>张量视为一维张量。</p>
<p>If <code>accumulate</code> is <code>True</code>, the elements in <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> are added to <code>self</code>. If accumulate is <code>False</code>, the behavior is undefined if indices contain duplicate elements.</p>
<p>参数</p>
<ul>
<li>
<p><strong>索引</strong> (<em>LongTensor</em> )–自身索引</p>
</li>
<li>
<p><strong>张量</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–张量包含要复制的值</p>
</li>
<li>
<p><strong>accumulate</strong> (<em>bool</em>) – whether to accumulate into self</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; src = torch.tensor([[4, 3, 5],
                        [6, 7, 8]])
&gt;&gt;&gt; src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))
tensor([[  4,   9,   5],
        [ 10,   7,   8]])

</code></pre>
<hr />
<pre><code>qr(some=True) -&gt; (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.qr" title="torch.qr"><code>torch.qr()</code></a></p>
<hr />
<pre><code>qscheme() → torch.qscheme
</code></pre>
<p>返回给定 QTensor 的量化方案。</p>
<hr />
<pre><code>q_scale() → float
</code></pre>
<p>给定一个通过线性(仿射）量化量化的张量，返回基础量化器(）的比例尺。</p>
<hr />
<pre><code>q_zero_point() → int
</code></pre>
<p>给定一个通过线性(仿射）量化量化的张量，返回基础量化器(）的 zero_point。</p>
<hr />
<pre><code>q_per_channel_scales() → Tensor
</code></pre>
<p>给定通过线性(仿射）每通道量化进行量化的张量，返回基础量化器的比例的张量。 它具有与张量的相应尺寸(来自 q_per_channel_axis）匹配的元素数量。</p>
<hr />
<pre><code>q_per_channel_zero_points() → Tensor
</code></pre>
<p>给定一个通过线性(仿射）每通道量化量化的张量，返回基础量化器的 zero_points 张量。 它具有与张量的相应尺寸(来自 q_per_channel_axis）匹配的元素数量。</p>
<hr />
<pre><code>q_per_channel_axis() → int
</code></pre>
<p>给定通过线性(仿射）每通道量化量化的张量，返回在其上应用每通道量化的尺寸索引。</p>
<hr />
<pre><code>random_(from=0, to=None, *, generator=None) → Tensor
</code></pre>
<p>用从<code>[from, to - 1]</code>上的离散均匀分布采样的数字填充<code>self</code>张量。 如果未指定，则这些值通常仅受<code>self</code>张量的数据类型限制。 但是，对于浮点类型，如果未指定，范围将为<code>[0, 2^mantissa]</code>以确保每个值都是可表示的。 例如， &lt;cite&gt;torch.tensor(1，dtype = torch.double）.random_(）&lt;/cite&gt;在<code>[0, 2^53]</code>中将是统一的。</p>
<hr />
<pre><code>reciprocal() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.reciprocal" title="torch.reciprocal"><code>torch.reciprocal()</code></a></p>
<hr />
<pre><code>reciprocal_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code>reciprocal()</code></a></p>
<hr />
<pre><code>record_stream(stream)
</code></pre>
<p>确保在<code>stream</code>上排队的所有当前工作完成之前，张量存储器不会被其他张量重用。</p>
<p>注意</p>
<p>缓存分配器仅知道分配张量的流。 由于有了这种认识，它已经可以仅在一个流上正确管理张量的生命周期。 但是，如果在与原始流不同的流上使用张量，则分配器可能会意外地重用内存。 调用此方法可让分配器知道哪些流使用了张量。</p>
<hr />
<pre><code>register_hook(hook)
</code></pre>
<p>注册一个倒钩。</p>
<p>每当计算相对于张量的梯度时，都会调用该挂钩。 挂钩应具有以下签名：</p>
<pre><code>hook(grad) -&gt; Tensor or None

</code></pre>
<p>挂钩不应修改其自变量，但可以选择返回一个新的渐变，该渐变将代替 <a href="autograd.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>grad</code></a> 使用。</p>
<p>此函数返回带有方法<code>handle.remove()</code>的句柄，该方法可将钩子从模块中移除。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; v = torch.tensor([0., 0., 0.], requires_grad=True)
&gt;&gt;&gt; h = v.register_hook(lambda grad: grad * 2)  # double the gradient
&gt;&gt;&gt; v.backward(torch.tensor([1., 2., 3.]))
&gt;&gt;&gt; v.grad

 2
 4
 6
[torch.FloatTensor of size (3,)]

&gt;&gt;&gt; h.remove()  # removes the hook

</code></pre>
<hr />
<pre><code>remainder(divisor) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.remainder" title="torch.remainder"><code>torch.remainder()</code></a></p>
<hr />
<pre><code>remainder_(divisor) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.remainder" title="torch.Tensor.remainder"><code>remainder()</code></a></p>
<hr />
<pre><code>real() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.real" title="torch.real"><code>torch.real()</code></a></p>
<hr />
<pre><code>renorm(p, dim, maxnorm) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.renorm" title="torch.renorm"><code>torch.renorm()</code></a></p>
<hr />
<pre><code>renorm_(p, dim, maxnorm) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.renorm" title="torch.Tensor.renorm"><code>renorm()</code></a></p>
<hr />
<pre><code>repeat(*sizes) → Tensor
</code></pre>
<p>沿指定尺寸重复此张量。</p>
<p>与 <a href="#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand()</code></a> 不同，此功能复制张量的数据。</p>
<p>警告</p>
<p><code>torch.repeat()</code>的行为与 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html">numpy.repeat</a> 不同，但更类似于 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html">numpy.tile</a> 。 对于类似于 &lt;cite&gt;numpy.repeat&lt;/cite&gt; 的运算符，请参见 <a href="torch.html#torch.repeat_interleave" title="torch.repeat_interleave"><code>torch.repeat_interleave()</code></a> 。</p>
<p>参数</p>
<p><strong>大小</strong>(<em>torch大小</em> <em>或</em> <em>python：int ...</em> )–在每个维度上重复此张量的次数</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([1, 2, 3])
&gt;&gt;&gt; x.repeat(4, 2)
tensor([[ 1,  2,  3,  1,  2,  3],
        [ 1,  2,  3,  1,  2,  3],
        [ 1,  2,  3,  1,  2,  3],
        [ 1,  2,  3,  1,  2,  3]])
&gt;&gt;&gt; x.repeat(4, 2, 1).size()
torch.Size([4, 2, 3])

</code></pre>
<hr />
<pre><code>repeat_interleave(repeats, dim=None) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.repeat_interleave" title="torch.repeat_interleave"><code>torch.repeat_interleave()</code></a> 。</p>
<pre><code>requires_grad
</code></pre>
<p>如果需要为此张量计算梯度，则为<code>True</code>，否则为<code>False</code>。</p>
<p>注意</p>
<p>需要为张量计算梯度的事实并不意味着将填充 <a href="autograd.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>grad</code></a> 属性，有关更多详细信息，请参见 <a href="autograd.html#torch.Tensor.is_leaf" title="torch.Tensor.is_leaf"><code>is_leaf</code></a> 。</p>
<hr />
<pre><code>requires_grad_(requires_grad=True) → Tensor
</code></pre>
<p>更改 autograd 是否应记录该张量上的操作：适当地设置此张量的 <a href="autograd.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> 属性。 返回此张量。</p>
<p><a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a> 的主要用例是告诉 autograd 在 Tensor <code>tensor</code>上开始记录操作。 如果<code>tensor</code>具有<code>requires_grad=False</code>(因为它是通过 DataLoader 获得的，或者需要进行预处理或初始化），则<code>tensor.requires_grad_()</code>将其设置为使 autograd 将开始在<code>tensor</code>上记录操作。</p>
<p>参数</p>
<p><strong>require_grad</strong>  (<em>bool</em> )–如果 autograd 应该在该张量上记录操作。 默认值：<code>True</code>。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; # Let's say we want to preprocess some saved weights and use
&gt;&gt;&gt; # the result as new weights.
&gt;&gt;&gt; saved_weights = [0.1, 0.2, 0.3, 0.25]
&gt;&gt;&gt; loaded_weights = torch.tensor(saved_weights)
&gt;&gt;&gt; weights = preprocess(loaded_weights)  # some function
&gt;&gt;&gt; weights
tensor([-0.5503,  0.4926, -2.1158, -0.8303])

&gt;&gt;&gt; # Now, start to record operations done to weights
&gt;&gt;&gt; weights.requires_grad_()
&gt;&gt;&gt; out = weights.pow(2).sum()
&gt;&gt;&gt; out.backward()
&gt;&gt;&gt; weights.grad
tensor([-1.1007,  0.9853, -4.2316, -1.6606])

</code></pre>
<hr />
<pre><code>reshape(*shape) → Tensor
</code></pre>
<p>返回具有与<code>self</code>相同的数据和元素数量但具有指定形状的张量。 如果<code>shape</code>与当前形状兼容，则此方法返回一个视图。 当可以返回视图时，请参见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>torch.Tensor.view()</code></a> 。</p>
<p>参见 <a href="torch.html#torch.reshape" title="torch.reshape"><code>torch.reshape()</code></a></p>
<p>参数</p>
<p><strong>形状</strong> (<em>python：ints 的元组</em> <em>或</em> <em>python：int ...</em> )–所需的形状</p>
<hr />
<pre><code>reshape_as(other) → Tensor
</code></pre>
<p>以与<code>other</code>相同的形状返回此张量。 <code>self.reshape_as(other)</code>等效于<code>self.reshape(other.sizes())</code>。 如果<code>other.sizes()</code>与当前形状兼容，则此方法返回视图。 何时可以返回视图，请参见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>torch.Tensor.view()</code></a> 。</p>
<p>有关<code>reshape</code>的更多信息，请参见 <a href="torch.html#torch.reshape" title="torch.reshape"><code>reshape()</code></a> 。</p>
<p>参数</p>
<p><strong>其他</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>)–结果张量具有与<code>other</code>相同的形状。</p>
<hr />
<pre><code>resize_(*sizes) → Tensor
</code></pre>
<p>将<code>self</code>张量调整为指定大小。 如果元素数量大于当前存储大小，那么将调整基础存储的大小以适合新的元素数量。 如果元素数较小，则基础存储不会更改。 现有元素将保留，但任何新内存均未初始化。</p>
<p>警告</p>
<p>这是一种底层方法。 将存储重新解释为 C 连续的，而忽略当前步幅(除非目标大小等于当前大小，在这种情况下，张量保持不变）。 对于大多数目的，您将改为使用 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>view()</code></a> (检查连续性），或使用 <a href="#torch.Tensor.reshape" title="torch.Tensor.reshape"><code>reshape()</code></a> (如果需要，可复制数据）。 要使用自定义步幅就地更改大小，请参见 <a href="#torch.Tensor.set_" title="torch.Tensor.set_"><code>set_()</code></a> 。</p>
<p>参数</p>
<p><strong>大小</strong>(<em>torch大小</em> <em>或</em> <em>python：int ...</em> )–所需大小</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([[1, 2], [3, 4], [5, 6]])
&gt;&gt;&gt; x.resize_(2, 2)
tensor([[ 1,  2],
        [ 3,  4]])

</code></pre>
<hr />
<pre><code>resize_as_(tensor) → Tensor
</code></pre>
<p>将<code>self</code>张量调整为与指定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 相同的大小。 这等效于<code>self.resize_(tensor.size())</code>。</p>
<hr />
<pre><code>retain_grad()
</code></pre>
<p>为非叶张量启用.grad 属性。</p>
<hr />
<pre><code>rfft(signal_ndim, normalized=False, onesided=True) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.rfft" title="torch.rfft"><code>torch.rfft()</code></a></p>
<hr />
<pre><code>roll(shifts, dims) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.roll" title="torch.roll"><code>torch.roll()</code></a></p>
<hr />
<pre><code>rot90(k, dims) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.rot90" title="torch.rot90"><code>torch.rot90()</code></a></p>
<hr />
<pre><code>round() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.round" title="torch.round"><code>torch.round()</code></a></p>
<hr />
<pre><code>round_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.round" title="torch.Tensor.round"><code>round()</code></a></p>
<hr />
<pre><code>rsqrt() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.rsqrt" title="torch.rsqrt"><code>torch.rsqrt()</code></a></p>
<hr />
<pre><code>rsqrt_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code>rsqrt()</code></a></p>
<hr />
<pre><code>scatter(dim, index, source) → Tensor
</code></pre>
<p><a href="#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>torch.Tensor.scatter_()</code></a> 的替代版本</p>
<hr />
<pre><code>scatter_(dim, index, src) → Tensor
</code></pre>
<p>将张量<code>src</code>中的所有值写入<code>index</code>张量中指定的索引处的<code>self</code>中。 对于<code>src</code>中的每个值，其输出索引由<code>dimension != dim</code>的<code>src</code>中的索引以及<code>dimension = dim</code>的<code>index</code>中的相应值指定。</p>
<p>对于 3-D 张量，<code>self</code>更新为：</p>
<pre><code>self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0
self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1
self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2

</code></pre>
<p>这是 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a> 中描述的方式的相反操作。</p>
<p><code>self</code>，<code>index</code>和<code>src</code>(如果是张量）应具有相同数量的尺寸。 还要求对于所有尺寸<code>d</code>均为<code>index.size(d) &amp;lt;= src.size(d)</code>，并且对于所有尺寸<code>d != dim</code>均要求<code>index.size(d) &amp;lt;= self.size(d)</code>。</p>
<p>此外，对于 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a> ，<code>index</code>的值必须介于<code>0</code>和<code>self.size(dim) - 1</code>之间，且沿指定尺寸 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 必须是唯一的。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python：int</em> ) – 沿其索引的轴</p>
</li>
<li>
<p><strong>index</strong> (<em>LongTensor</em> ) – 要散布的元素的索引可以为空或 src 的大小相同。 如果为空，则操作返回标识</p>
</li>
<li>
<p><strong>src</strong>  (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>) – 要散布的源元素，如果未指定_值_</p>
</li>
<li>
<p><strong>value</strong> (<em>python：float</em> ) – 要分散的源元素，如果未指定_src_</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.rand(2, 5)
&gt;&gt;&gt; x
tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],
        [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])
&gt;&gt;&gt; torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)
tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],
        [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],
        [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])

&gt;&gt;&gt; z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)
&gt;&gt;&gt; z
tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  1.2300]])

</code></pre>
<hr />
<pre><code>scatter_add_(dim, index, other) → Tensor
</code></pre>
<p>将张量<code>other</code>中的所有值添加到<code>index</code>张量中指定的索引处的<code>self</code>中，其方式与 <a href="#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>scatter_()</code></a> 相似。 对于<code>other</code>中的每个值，将其添加到<code>self</code>中的索引，该索引由<code>dimension != dim</code>中的<code>other</code>中的索引和<code>dimension = dim</code>中的<code>index</code>中的对应值指定。</p>
<p>For a 3-D tensor, <code>self</code> is updated as:</p>
<pre><code>self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0
self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1
self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2

</code></pre>
<p><code>self</code>，<code>index</code>和<code>other</code>应具有相同的尺寸数。 还要求对于所有尺寸<code>d</code>均为<code>index.size(d) &amp;lt;= other.size(d)</code>，并且对于所有尺寸<code>d != dim</code>均要求<code>index.size(d) &amp;lt;= self.size(d)</code>。</p>
<p>注意</p>
<p>When using the CUDA backend, this operation may induce nondeterministic behaviour that is not easily switched off. Please see the 注意s on <a href="注意s/randomness.html">Reproducibility</a> for background.</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python:int</em>) – the axis along which to index</p>
</li>
<li>
<p><strong>index</strong> (<em>LongTensor</em> ) – 分散和添加元素的索引，可以为空或 src 大小相同。 为空时，该操作将返回标识。</p>
</li>
<li>
<p><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>) – 分散和添加的源元素</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.rand(2, 5)
&gt;&gt;&gt; x
tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],
        [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])
&gt;&gt;&gt; torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)
tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],
        [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],
        [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])

</code></pre>
<hr />
<pre><code>scatter_add(dim, index, source) → Tensor
</code></pre>
<p><a href="#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code>torch.Tensor.scatter_add_()</code></a> 的替代版本</p>
<hr />
<pre><code>select(dim, index) → Tensor
</code></pre>
<p>沿选定维度在给定索引处切片<code>self</code>张量。 该函数返回一个张量，其中给定尺寸被移除。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python：int</em> )–切片的尺寸</p>
</li>
<li>
<p><strong>索引</strong> (<em>python：int</em> )–要选择的索引</p>
</li>
</ul>
<p>注意</p>
<p><a href="#torch.Tensor.select" title="torch.Tensor.select"><code>select()</code></a> 相当于切片。 例如，<code>tensor.select(0, index)</code>等效于<code>tensor[index]</code>，<code>tensor.select(2, index)</code>等效于<code>tensor[:,:,index]</code>。</p>
<hr />
<pre><code>set_(source=None, storage_offset=0, size=None, stride=None) → Tensor
</code></pre>
<p>设置基础存储空间，大小和跨度。 如果<code>source</code>是张量，则<code>self</code>张量将与<code>source</code>共享相同的存储空间并具有相同的大小和跨度。 一个张量中元素的变化将反映在另一个张量中。</p>
<p>如果<code>source</code>是<code>Storage</code>，则该方法设置基础存储，偏移，大小和跨度。</p>
<p>参数</p>
<ul>
<li>
<p><strong>源</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a> <em>或</em> <em>存储器</em>）–使用的张量或存储器</p>
</li>
<li>
<p><strong>storage_offset</strong>  (<em>python：int</em> <em>，</em> <em>可选</em>）–存储中的偏移量</p>
</li>
<li>
<p><strong>大小</strong>(<em>torch大小</em> <em>，</em> <em>可选</em>）–所需大小。 默认为源大小。</p>
</li>
<li>
<p><strong>步幅</strong>(<em>元组</em> <em>，</em> <em>可选</em>）–所需的步幅。 默认为 C 连续跨步。</p>
</li>
</ul>
<hr />
<pre><code>share_memory_()
</code></pre>
<p>将基础存储移动到共享内存。</p>
<p>如果基础存储已经在共享内存中并且用于 CUDA 张量，则此操作不可操作。 共享内存中的张量无法调整大小。</p>
<hr />
<pre><code>short() → Tensor
</code></pre>
<p><code>self.short()</code>等效于<code>self.to(torch.int16)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<pre><code>sigmoid() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.sigmoid" title="torch.sigmoid"><code>torch.sigmoid()</code></a></p>
<hr />
<pre><code>sigmoid_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code>sigmoid()</code></a></p>
<hr />
<pre><code>sign() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.sign" title="torch.sign"><code>torch.sign()</code></a></p>
<hr />
<pre><code>sign_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.sign" title="torch.Tensor.sign"><code>sign()</code></a></p>
<hr />
<pre><code>sin() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.sin" title="torch.sin"><code>torch.sin()</code></a></p>
<hr />
<pre><code>sin_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.sin" title="torch.Tensor.sin"><code>sin()</code></a></p>
<hr />
<pre><code>sinh() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.sinh" title="torch.sinh"><code>torch.sinh()</code></a></p>
<hr />
<pre><code>sinh_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.sinh" title="torch.Tensor.sinh"><code>sinh()</code></a></p>
<hr />
<pre><code>size() → torch.Size
</code></pre>
<p>返回<code>self</code>张量的大小。 返回的值是<code>tuple</code>的子类。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; torch.empty(3, 4, 5).size()
torch.Size([3, 4, 5])

</code></pre>
<hr />
<pre><code>slogdet() -&gt; (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.slogdet" title="torch.slogdet"><code>torch.slogdet()</code></a></p>
<hr />
<pre><code>solve(A) → Tensor, Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.solve" title="torch.solve"><code>torch.solve()</code></a></p>
<hr />
<pre><code>sort(dim=-1, descending=False) -&gt; (Tensor, LongTensor)
</code></pre>
<p>参见 <a href="torch.html#torch.sort" title="torch.sort"><code>torch.sort()</code></a></p>
<hr />
<pre><code>split(split_size, dim=0)
</code></pre>
<p>参见 <a href="torch.html#torch.split" title="torch.split"><code>torch.split()</code></a></p>
<hr />
<pre><code>sparse_mask(input, mask) → Tensor
</code></pre>
<p>返回一个新的 SparseTensor，其 Tensor <code>input</code>中的值被<code>mask</code>的索引过滤，并且值被忽略。 <code>input</code>和<code>mask</code>必须具有相同的形状。</p>
<p>参数</p>
<ul>
<li>
<p><strong>input</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–输入张量</p>
</li>
<li>
<p><strong>mask</strong> (<em>SparseTensor</em> )–我们根据其索引过滤<code>input</code>的 SparseTensor</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; nnz = 5
&gt;&gt;&gt; dims = [5, 5, 2, 2]
&gt;&gt;&gt; I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),
                   torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)
&gt;&gt;&gt; V = torch.randn(nnz, dims[2], dims[3])
&gt;&gt;&gt; size = torch.Size(dims)
&gt;&gt;&gt; S = torch.sparse_coo_tensor(I, V, size).coalesce()
&gt;&gt;&gt; D = torch.randn(dims)
&gt;&gt;&gt; D.sparse_mask(S)
tensor(indices=tensor([[0, 0, 0, 2],
                       [0, 1, 4, 3]]),
       values=tensor([[[ 1.6550,  0.2397],
                       [-0.1611, -0.0779]],

                      [[ 0.2326, -1.0558],
                       [ 1.4711,  1.9678]],

                      [[-0.5138, -0.0411],
                       [ 1.9417,  0.5158]],

                      [[ 0.0793,  0.0036],
                       [-0.2569, -0.1055]]]),
       size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)

</code></pre>
<hr />
<pre><code>sparse_dim() → int
</code></pre>
<p>如果<code>self</code>是稀疏的 COO 张量(即<code>torch.sparse_coo</code>布局），则返回稀疏维度的数量。 否则，将引发错误。</p>
<p>另请参见 <a href="#torch.Tensor.dense_dim" title="torch.Tensor.dense_dim"><code>Tensor.dense_dim()</code></a> 。</p>
<hr />
<pre><code>sqrt() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.sqrt" title="torch.sqrt"><code>torch.sqrt()</code></a></p>
<hr />
<pre><code>sqrt_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code>sqrt()</code></a></p>
<hr />
<pre><code>squeeze(dim=None) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a></p>
<hr />
<pre><code>squeeze_(dim=None) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code>squeeze()</code></a></p>
<hr />
<pre><code>std(dim=None, unbiased=True, keepdim=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.std" title="torch.std"><code>torch.std()</code></a></p>
<hr />
<pre><code>stft(n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)
</code></pre>
<p>参见 <a href="torch.html#torch.stft" title="torch.stft"><code>torch.stft()</code></a></p>
<p>警告</p>
<p>此功能在版本 0.4.1 更改了签名。 使用前一个签名进行调用可能会导致错误或返回错误的结果。</p>
<hr />
<pre><code>storage() → torch.Storage
</code></pre>
<p>返回基础存储。</p>
<hr />
<pre><code>storage_offset() → int
</code></pre>
<p>根据存储元素的数量(不是字节），返回基础存储中的<code>self</code>张量偏移量。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([1, 2, 3, 4, 5])
&gt;&gt;&gt; x.storage_offset()
0
&gt;&gt;&gt; x[3:].storage_offset()
3

</code></pre>
<hr />
<pre><code>storage_type() → type
</code></pre>
<p>返回基础存储的类型。</p>
<hr />
<pre><code>stride(dim) → tuple or int
</code></pre>
<p>返回<code>self</code>张量的步幅。</p>
<p>跨度是在指定尺寸 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 中从一个元素跳至下一元素所需的跳跃。 当未传递任何参数时，将返回所有跨度的元组。否则，将返回整数值作为特定维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 中的跨度。</p>
<p>参数</p>
<p><strong>dim</strong> (<em>python：int</em> <em>，</em> <em>可选</em>）– 需要跨度的所需尺寸</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
&gt;&gt;&gt; x.stride()
(5, 1)
&gt;&gt;&gt;x.stride(0)
5
&gt;&gt;&gt; x.stride(-1)
1

</code></pre>
<hr />
<pre><code>sub(value, other) → Tensor
</code></pre>
<p>从<code>self</code>张量中减去标量或张量。 如果同时指定了<code>value</code>和<code>other</code>，则在使用前<code>other</code>的每个元素都会按<code>value</code>缩放。</p>
<p>当<code>other</code>是张量时，<code>other</code>的形状必须是<a href="注意s/broadcasting.html#broadcasting-semantics">可广播的</a>，并具有基础张量的形状。</p>
<hr />
<pre><code>sub_(x) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.sub" title="torch.Tensor.sub"><code>sub()</code></a></p>
<hr />
<pre><code>sum(dim=None, keepdim=False, dtype=None) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.sum" title="torch.sum"><code>torch.sum()</code></a></p>
<hr />
<pre><code>sum_to_size(*size) → Tensor
</code></pre>
<p>将<code>this</code>张量与 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 相加。 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 必须可广播到<code>this</code>张量大小。</p>
<p>参数</p>
<p><strong>大小</strong> (<em>python：int ...</em> )–定义输出张量形状的整数序列。</p>
<hr />
<pre><code>svd(some=True, compute_uv=True) -&gt; (Tensor, Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.svd" title="torch.svd"><code>torch.svd()</code></a></p>
<hr />
<pre><code>symeig(eigenvectors=False, upper=True) -&gt; (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.symeig" title="torch.symeig"><code>torch.symeig()</code></a></p>
<hr />
<pre><code>t() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.t" title="torch.t"><code>torch.t()</code></a></p>
<hr />
<pre><code>t_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.t" title="torch.Tensor.t"><code>t()</code></a></p>
<hr />
<pre><code>to(*args, **kwargs) → Tensor
</code></pre>
<p>执行 Tensor dtype 和/或设备转换。 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 是从<code>self.to(*args, **kwargs)</code>的论点推论出来的。</p>
<p>注意</p>
<p>如果<code>self</code>张量已经具有正确的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> ，则返回<code>self</code>。 否则，返回的张量是<code>self</code>与所需 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 的副本。</p>
<p>以下是调用<code>to</code>的方法：</p>
<hr />
<pre><code>to(dtype, non_blocking=False, copy=False) → Tensor
</code></pre>
<p>返回具有指定<code>dtype</code>的张量</p>
<hr />
<pre><code>to(device=None, dtype=None, non_blocking=False, copy=False) → Tensor
</code></pre>
<p>返回具有指定 <a href="#torch.Tensor.device" title="torch.Tensor.device"><code>device</code></a> 和(可选）<code>dtype</code>的张量。 如果<code>dtype</code>为<code>None</code>，则推断为<code>self.dtype</code>。 当<code>non_blocking</code>时，如果可能，尝试相对于主机进行异步转换，例如，将具有固定内存的 CPU 张量转换为 CUDA 张量。 设置<code>copy</code>时，即使张量已经匹配所需的转换，也会创建新的张量。</p>
<hr />
<pre><code>to(other, non_blocking=False, copy=False) → Tensor
</code></pre>
<p>返回与张量<code>other</code>相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 的张量。 当<code>non_blocking</code>时，如果可能，尝试相对于主机进行异步转换，例如，将具有固定内存的 CPU 张量转换为 CUDA 张量。 设置<code>copy</code>时，即使张量已经与所需的转换匹配，也会创建新的张量。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu
&gt;&gt;&gt; tensor.to(torch.float64)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64)

&gt;&gt;&gt; cuda0 = torch.device('cuda:0')
&gt;&gt;&gt; tensor.to(cuda0)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], device='cuda:0')

&gt;&gt;&gt; tensor.to(cuda0, dtype=torch.float64)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')

&gt;&gt;&gt; other = torch.randn((), dtype=torch.float64, device=cuda0)
&gt;&gt;&gt; tensor.to(other, non_blocking=True)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')

</code></pre>
<hr />
<pre><code>to_mkldnn() → Tensor
</code></pre>
<p>返回<code>torch.mkldnn</code>布局中的张量的副本。</p>
<hr />
<pre><code>take(indices) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.take" title="torch.take"><code>torch.take()</code></a></p>
<hr />
<pre><code>tan() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.tan" title="torch.tan"><code>torch.tan()</code></a></p>
<hr />
<pre><code>tan_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.tan" title="torch.Tensor.tan"><code>tan()</code></a></p>
<hr />
<pre><code>tanh() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.tanh" title="torch.tanh"><code>torch.tanh()</code></a></p>
<hr />
<pre><code>tanh_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.tanh" title="torch.Tensor.tanh"><code>tanh()</code></a></p>
<hr />
<pre><code>tolist()
</code></pre>
<p>” tolist(）-&gt;列表或编号</p>
<p>将张量作为(嵌套的）列表返回。 对于标量，将返回标准 Python 编号，就像 <a href="#torch.Tensor.item" title="torch.Tensor.item"><code>item()</code></a> 一样。 如有必要，张量会先自动移至 CPU。</p>
<p>This operation is not differentiable.</p>
<p>例子：</p>
<pre><code>&gt;&gt;&gt; a = torch.randn(2, 2)
&gt;&gt;&gt; a.tolist()
[[0.012766935862600803, 0.5415473580360413],
 [-0.08909505605697632, 0.7729271650314331]]
&gt;&gt;&gt; a[0,0].tolist()
0.012766935862600803

</code></pre>
<hr />
<pre><code>topk(k, dim=None, largest=True, sorted=True) -&gt; (Tensor, LongTensor)
</code></pre>
<p>参见 <a href="torch.html#torch.topk" title="torch.topk"><code>torch.topk()</code></a></p>
<hr />
<pre><code>to_sparse(sparseDims) → Tensor
</code></pre>
<p>返回张量的稀疏副本。 PyTorch 支持<a href="sparse.html#sparse-docs">坐标格式</a>的稀疏张量。</p>
<p>参数</p>
<p><strong>sparseDims</strong>  (<em>python：int</em> <em>，</em> <em>可选</em>）– 新稀疏张量中包含的稀疏维数</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])
&gt;&gt;&gt; d
tensor([[ 0,  0,  0],
        [ 9,  0, 10],
        [ 0,  0,  0]])
&gt;&gt;&gt; d.to_sparse()
tensor(indices=tensor([[1, 1],
                       [0, 2]]),
       values=tensor([ 9, 10]),
       size=(3, 3), nnz=2, layout=torch.sparse_coo)
&gt;&gt;&gt; d.to_sparse(1)
tensor(indices=tensor([[1]]),
       values=tensor([[ 9,  0, 10]]),
       size=(3, 3), nnz=1, layout=torch.sparse_coo)

</code></pre>
<hr />
<pre><code>trace() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.trace" title="torch.trace"><code>torch.trace()</code></a></p>
<hr />
<pre><code>transpose(dim0, dim1) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.transpose" title="torch.transpose"><code>torch.transpose()</code></a></p>
<hr />
<pre><code>transpose_(dim0, dim1) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.transpose" title="torch.Tensor.transpose"><code>transpose()</code></a></p>
<hr />
<pre><code>triangular_solve(A, upper=True, transpose=False, unitriangular=False) -&gt; (Tensor, Tensor)
</code></pre>
<p>参见 <a href="torch.html#torch.triangular_solve" title="torch.triangular_solve"><code>torch.triangular_solve()</code></a></p>
<hr />
<pre><code>tril(k=0) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.tril" title="torch.tril"><code>torch.tril()</code></a></p>
<hr />
<pre><code>tril_(k=0) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.tril" title="torch.Tensor.tril"><code>tril()</code></a></p>
<hr />
<pre><code>triu(k=0) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.triu" title="torch.triu"><code>torch.triu()</code></a></p>
<hr />
<pre><code>triu_(k=0) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.triu" title="torch.Tensor.triu"><code>triu()</code></a></p>
<hr />
<pre><code>trunc() → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.trunc" title="torch.trunc"><code>torch.trunc()</code></a></p>
<hr />
<pre><code>trunc_() → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.trunc" title="torch.Tensor.trunc"><code>trunc()</code></a></p>
<hr />
<pre><code>type(dtype=None, non_blocking=False, **kwargs) → str or Tensor
</code></pre>
<p>如果未提供_dtype_; ，则返回类型，否则将该对象强制转换为指定的类型。</p>
<p>如果它已经是正确的类型，则不执行任何复制，并返回原始对象。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dtype</strong>  (<em>python：type</em> <em>或</em> <em>字符串</em>）– 所需类型</p>
</li>
<li>
<p><strong>non_blocking</strong>  (<em>bool</em> ) – 如果<code>True</code>，并且源位于固定内存中，而目标位于 GPU 上，反之亦然，则相对于主机异步执行复制。 否则，该参数无效。</p>
</li>
<li>
<p><strong>**kwargs</strong> – 为兼容起见，可以包含键<code>async</code>来代替<code>non_blocking</code>参数。 不推荐使用<code>async</code> arg。</p>
</li>
</ul>
<hr />
<pre><code>type_as(tensor) → Tensor
</code></pre>
<p>将此张量转换为给定张量的类型。</p>
<p>如果张量已经是正确的类型，则这是无操作的。 相当于<code>self.type(tensor.type())</code></p>
<p>参数</p>
<p><strong>张量</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–具有所需类型的张量</p>
<hr />
<pre><code>unbind(dim=0) → seq
</code></pre>
<p>参见 <a href="torch.html#torch.unbind" title="torch.unbind"><code>torch.unbind()</code></a></p>
<hr />
<pre><code>unfold(dimension, size, step) → Tensor
</code></pre>
<p>返回一个张量，该张量包含<code>self</code>张量中尺寸为<code>dimension</code>的所有大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的切片。</p>
<p>两个切片之间的步长由<code>step</code>给出。</p>
<p>如果 <em>sizedim</em> 是<code>self</code>的尺寸<code>dimension</code>的大小，则返回张量中<code>dimension</code>的尺寸将是(<em>sizeim-size</em>）/<em>step</em>+ 1 。</p>
<p>在返回的张量中附加了尺寸为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的附加尺寸。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dimension</strong> (<em>python：int</em> )–发生展开的尺寸</p>
</li>
<li>
<p><strong>size</strong> (<em>python：int</em> )–展开的每个切片的大小</p>
</li>
<li>
<p><strong>step</strong> (<em>python：int</em> )–每个切片之间的步骤</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.arange(1., 8)
&gt;&gt;&gt; x
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])
&gt;&gt;&gt; x.unfold(0, 2, 1)
tensor([[ 1.,  2.],
        [ 2.,  3.],
        [ 3.,  4.],
        [ 4.,  5.],
        [ 5.,  6.],
        [ 6.,  7.]])
&gt;&gt;&gt; x.unfold(0, 2, 2)
tensor([[ 1.,  2.],
        [ 3.,  4.],
        [ 5.,  6.]])

</code></pre>
<hr />
<pre><code>uniform_(from=0, to=1) → Tensor
</code></pre>
<p>用从连续均匀分布中采样的数字填充<code>self</code>张量：</p>
<p><img alt="" src="../img/14837c97b5055932ef86ad2cd89a50be.jpg" /></p>
<hr />
<pre><code>unique(sorted=True, return_inverse=False, return_counts=False, dim=None)
</code></pre>
<p>返回输入张量的唯一元素。</p>
<p>参见 <a href="torch.html#torch.unique" title="torch.unique"><code>torch.unique()</code></a></p>
<hr />
<pre><code>unique_consecutive(return_inverse=False, return_counts=False, dim=None)
</code></pre>
<p>从每个连续的等效元素组中除去除第一个元素外的所有元素。</p>
<p>参见 <a href="torch.html#torch.unique_consecutive" title="torch.unique_consecutive"><code>torch.unique_consecutive()</code></a></p>
<hr />
<pre><code>unsqueeze(dim) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.unsqueeze" title="torch.unsqueeze"><code>torch.unsqueeze()</code></a></p>
<hr />
<pre><code>unsqueeze_(dim) → Tensor
</code></pre>
<p>就地版本的 <a href="#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code>unsqueeze()</code></a></p>
<hr />
<pre><code>values() → Tensor
</code></pre>
<p>如果<code>self</code>是稀疏的 COO 张量(即<code>torch.sparse_coo</code>布局），则返回包含值张量的视图。 否则，将引发错误。</p>
<p>另请参见 <a href="#torch.Tensor.indices" title="torch.Tensor.indices"><code>Tensor.indices()</code></a> 。</p>
<p>注意</p>
<p>This method can only be called on a coalesced sparse tensor. See <code>Tensor.coalesce()</code> for details.</p>
<hr />
<pre><code>var(dim=None, unbiased=True, keepdim=False) → Tensor
</code></pre>
<p>参见 <a href="torch.html#torch.var" title="torch.var"><code>torch.var()</code></a></p>
<hr />
<pre><code>view(*shape) → Tensor
</code></pre>
<p>返回具有与<code>self</code>张量相同的数据但具有不同<code>shape</code>的新张量。</p>
<p>返回的张量共享相同的数据，并且必须具有相同数量的元素，但可能具有不同的大小。 要查看张量，新视图尺寸必须与其原始尺寸和步幅兼容，即每个新视图尺寸必须是原始尺寸的子空间，或者仅跨越满足以下条件的原始尺寸<img alt="" src="../img/8145d811599f1a90bcb673523825c2d2.jpg" /> <img alt="" src="../img/935124691142e85d6cbbdab3f68cc1df.jpg" />的连续性状</p>
<p><img alt="" src="../img/b828b01a8af080958cc82bcc339c033a.jpg" /></p>
<p>否则，需要先调用 <a href="#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>contiguous()</code></a> 才能查看张量。 另请参见： <a href="torch.html#torch.reshape" title="torch.reshape"><code>reshape()</code></a> ，如果形状兼容则返回一个视图，否则复制(相当于调用 <a href="#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>contiguous()</code></a>)。</p>
<p>参数</p>
<p><strong>形状</strong>(<em>torch大小</em> <em>或</em> <em>python：int ...</em> )–所需大小</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; x = torch.randn(4, 4)
&gt;&gt;&gt; x.size()
torch.Size([4, 4])
&gt;&gt;&gt; y = x.view(16)
&gt;&gt;&gt; y.size()
torch.Size([16])
&gt;&gt;&gt; z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
&gt;&gt;&gt; z.size()
torch.Size([2, 8])

&gt;&gt;&gt; a = torch.randn(1, 2, 3, 4)
&gt;&gt;&gt; a.size()
torch.Size([1, 2, 3, 4])
&gt;&gt;&gt; b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension
&gt;&gt;&gt; b.size()
torch.Size([1, 3, 2, 4])
&gt;&gt;&gt; c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory
&gt;&gt;&gt; c.size()
torch.Size([1, 3, 2, 4])
&gt;&gt;&gt; torch.equal(b, c)
False

</code></pre>
<hr />
<pre><code>view_as(other) → Tensor
</code></pre>
<p>将此张量查看为与<code>other</code>相同的大小。 <code>self.view_as(other)</code>等效于<code>self.view(other.size())</code>。</p>
<p>有关<code>view</code>的更多信息，请参见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>view()</code></a> 。</p>
<p>参数</p>
<p><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>) – The result tensor has the same size as <code>other</code>.</p>
<hr />
<pre><code>where(condition, y) → Tensor
</code></pre>
<p><code>self.where(condition, y)</code>等效于<code>torch.where(condition, self, y)</code>。 参见 <a href="torch.html#torch.where" title="torch.where"><code>torch.where()</code></a></p>
<hr />
<pre><code>zero_() → Tensor
</code></pre>
<p>用零填充<code>self</code>张量。</p>
<hr />
<pre><code>class torch.BoolTensor
</code></pre>
<p>以下方法是 <a href="#torch.BoolTensor" title="torch.BoolTensor"><code>torch.BoolTensor</code></a> 独有的。</p>
<hr />
<pre><code>all()
</code></pre>
<hr />
<pre><code>all() → bool
</code></pre>
<p>如果张量中的所有元素均为 True，则返回 True，否则返回 False。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; a = torch.rand(1, 2).bool()
&gt;&gt;&gt; a
tensor([[False, True]], dtype=torch.bool)
&gt;&gt;&gt; a.all()
tensor(False, dtype=torch.bool)

</code></pre>
<hr />
<pre><code>all(dim, keepdim=False, out=None) → Tensor
</code></pre>
<p>如果张量的每一行中给定维度<code>dim</code>中的所有元素均为 True，则返回 True，否则返回 False。</p>
<p>如果<code>keepdim</code>为<code>True</code>，则输出张量的大小与<code>input</code>相同，但尺寸为<code>dim</code>的大小为 1。否则，将压缩<code>dim</code>(请参见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>)，导致输出张量的尺寸比<code>input</code>小 1。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python：int</em> ) – 缩小的尺寸</p>
</li>
<li>
<p><strong>keepdim</strong>  (<em>bool</em> ) – 输出张量是否保留<code>dim</code></p>
</li>
<li>
<p><strong>out</strong>  (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a> <em>，</em> <em>可选</em>）– 输出的张量</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; a = torch.rand(4, 2).bool()
&gt;&gt;&gt; a
tensor([[True, True],
        [True, False],
        [True, True],
        [True, True]], dtype=torch.bool)
&gt;&gt;&gt; a.all(dim=1)
tensor([ True, False,  True,  True], dtype=torch.bool)
&gt;&gt;&gt; a.all(dim=0)
tensor([ True, False], dtype=torch.bool)

</code></pre>
<hr />
<pre><code>any()
</code></pre>
<hr />
<pre><code>any() → bool
</code></pre>
<p>如果张量中的任何元素为 True，则返回 True，否则为 False。</p>
<p>例：</p>
<pre><code>&gt;&gt;&gt; a = torch.rand(1, 2).bool()
&gt;&gt;&gt; a
tensor([[False, True]], dtype=torch.bool)
&gt;&gt;&gt; a.any()
tensor(True, dtype=torch.bool)

</code></pre>
<hr />
<pre><code>any(dim, keepdim=False, out=None) → Tensor
</code></pre>
<p>如果张量的每一行中给定维度<code>dim</code>中的任何元素为 True，则返回 True，否则为 False。</p>
<p>如果<code>keepdim</code>为<code>True</code>，则输出张量的大小与<code>input</code>相同，但尺寸为<code>dim</code>的大小为 1。否则，将压缩<code>dim</code>(请参见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>)，导致输出张量的尺寸比<code>input</code>小 1。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python:int</em>) – 缩小的尺寸</p>
</li>
<li>
<p><strong>keepdim</strong> (<em>bool</em>) – 输出张量是否保留<code>dim</code></p>
</li>
<li>
<p><strong>out</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>optional</em>) – 输出的张量</p>
</li>
</ul>
<p>例：</p>
<pre><code>&gt;&gt;&gt; a = torch.randn(4, 2) &lt; 0
&gt;&gt;&gt; a
tensor([[ True,  True],
        [False,  True],
        [ True,  True],
        [False, False]])
&gt;&gt;&gt; a.any(1)
tensor([ True,  True,  True, False])
&gt;&gt;&gt; a.any(0)
tensor([True, True])

</code></pre>
<hr/>
<div align="center">
  <p><a href="https://www.apachecn.org/" target="_blank"><font face="KaiTi" size="6" color="red">我们一直在努力</font></a><p>
  <p><a href="https://github.com/apachecn/pytorch-doc-zh" target="_blank">apachecn/pytorch-doc-zh</a></p>
  <p><a target="_blank" href="https://qm.qq.com/cgi-bin/qm/qr?k=5u_aAU-YlY3fH-m8meXTJzBEo2boQIUs&jump_from=webapi&authKey=CVZcReMt/vKdTXZBQ8ly+jWncXiSzzWOlrx5hybX5pSrKu6s0fvGX54+vHHlgYNt"><img border="0" src="https://pub.idqqimg.com/wpa/images/group.png" alt="【布客】中文翻译组" title="【布客】中文翻译组"></a></p>
  <p><span id="cnzz_stat_icon_1275211409"></span></p>
  <!-- <p><a href="https://get.brightdata.com/apachecn" target="_blank"><img src="/assets/images/partnerstack.gif" /></a><p> -->
  <div class="wwads-cn wwads-horizontal" data-id="206" style="max-width:680px"></div>
  <div style="text-align:center;margin:0 0 10.5px;">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3565452474788507" crossorigin="anonymous"></script>
    <!-- ApacheCNWide -->
    <ins class="adsbygoogle"
        style="display:inline-block;width:680px;height:90px"
        data-ad-client="ca-pub-3565452474788507"
        data-ad-slot="2543897000"></ins>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
  </div>
</div>
<hr/>
<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC81ODA2NC8zNDUyNw==">
  <script type="text/javascript">
  (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];

      if (typeof LivereTower === 'function') { return; }

      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;

      e.parentNode.insertBefore(j, e);
  })(document, 'script');
  </script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->






                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../76/" class="md-footer__link md-footer__link--prev" aria-label="Previous: torch功能" rel="prev">
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                torch功能
              </div>
            </div>
          </a>
        
        
          
          <a href="../78/" class="md-footer__link md-footer__link--next" aria-label="Next: 张量属性" rel="next">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                张量属性
              </div>
            </div>
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright" style="text-align: center; width: 100%;">
  
  
    <div>
      <div style="margin:0 0 10.5px;"><script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1275211409'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s5.cnzz.com/z_stat.php%3Fid%3D1275211409%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script></div>
      <p>Copyright © 2023 学习网站 <a href="http://beian.miit.gov.cn" target="_blank">京ICP备19016010号-1</a><br/>网站由 <a href="https://apachecn.org/cooperate/">@片刻小哥哥</a> 提供支持 | 联系QQ/微信: 529815144 请注明来意！</p>
    </div>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
  
      <script src="../../assets/javascripts/bundle.b425cdc4.min.js"></script>
      
        
          <script src="../../javascripts/mathjax.js"></script>
        
      
        
          <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
    
  <script src="../../assets/javascripts/custom.a7283b5f.min.js"></script>

  </body>
</html>