
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/1.0/tensors/">
      
      
        <link rel="prev" href="../torch_math_operations_blas_lapack_ops/">
      
      
        <link rel="next" href="../tensor_attributes/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.17">
    
    
      
        <title>torch.Tensor - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.26e3688c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link rel="stylesheet" href="../../assets/stylesheets/custom.bea7efe8.min.css">
  <!-- google ads -->
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3565452474788507" crossorigin="anonymous"></script>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8DP4GX97XY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-8DP4GX97XY');
  </script>
  <!-- google webmaster -->
  <meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo" />

  <!-- wwads-cn union -->
  <meta name="wwads-cn-verify" content="03c6b06952c750899bb03d998e631860" />
  <script type="text/javascript" charset="UTF-8" src="https://cdn.wwads.cn/js/makemoney.js" async></script>

  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torchtensor" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
            
  => 组织无偿提供 中文版本（免费，秒级响应）
  <a target="_blank" href="https://chat.ibooker.org.cn/chat" style="color: red;">
    <span class="twemoji mastodon">
      <img src="https://data.apachecn.org/img/icon/ROBOT_TXT.svg" alt="ChatGPT - ailake.top">
    </span>
    <strong>ChatGPT - ailake.top</strong>
  </a> 一起来白嫖叭～！

          </div>
          
        </aside>
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              torch.Tensor
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        PyTorch 中文文档 & 教程
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          PyTorch 2.0 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 2.0 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/README.md" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          PyTorch 1.7 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.7 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
          学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
          PyTorch 深度学习：60 分钟的突击
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习：60 分钟的突击
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/02/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/03/" class="md-nav__link">
        张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/04/" class="md-nav__link">
        torch.autograd的简要介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/05/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/06/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
          通过示例学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          通过示例学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/07/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/08/" class="md-nav__link">
        热身：NumPy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/09/" class="md-nav__link">
        PyTorch：张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/10/" class="md-nav__link">
        PyTorch：张量和 Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/11/" class="md-nav__link">
        PyTorch：定义新的 Autograd 函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/12/" class="md-nav__link">
        PyTorch：nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/13/" class="md-nav__link">
        PyTorch：optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/14/" class="md-nav__link">
        PyTorch：自定义nn模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/15/" class="md-nav__link">
        PyTorch：控制流 - 权重共享
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/16/" class="md-nav__link">
        torch.nn到底是什么？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/17/" class="md-nav__link">
        使用 TensorBoard 可视化模型，数据和训练
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
          图片/视频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          图片/视频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/19/" class="md-nav__link">
        torchvision对象检测微调教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/20/" class="md-nav__link">
        计算机视觉的迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/21/" class="md-nav__link">
        对抗示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/22/" class="md-nav__link">
        DCGAN 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
          音频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          音频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/24/" class="md-nav__link">
        音频 I/O 和torchaudio的预处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/25/" class="md-nav__link">
        使用torchaudio的语音命令识别
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/27/" class="md-nav__link">
        使用nn.Transformer和torchtext的序列到序列建模
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/28/" class="md-nav__link">
        从零开始的 NLP：使用字符级 RNN 分类名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/29/" class="md-nav__link">
        从零开始的 NLP：使用字符级 RNN 生成名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/30/" class="md-nav__link">
        从零开始的 NLP：使用序列到序列网络和注意力的翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/31/" class="md-nav__link">
        使用torchtext的文本分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/32/" class="md-nav__link">
        torchtext语言翻译
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
      
      
      
        <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/34/" class="md-nav__link">
        强化学习（DQN）教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/35/" class="md-nav__link">
        训练玩马里奥的 RL 智能体
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
      
      
      
        <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
          在生产中部署 PyTorch 模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_6">
          <span class="md-nav__icon md-icon"></span>
          在生产中部署 PyTorch 模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/37/" class="md-nav__link">
        通过使用 Flask 的 REST API 在 Python 中部署 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/38/" class="md-nav__link">
        TorchScript 简介
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/39/" class="md-nav__link">
        在 C-- 中加载 TorchScript 模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/40/" class="md-nav__link">
        将模型从 PyTorch 导出到 ONNX 并使用 ONNX 运行时运行它（可选）
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
      
      
      
        <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
          前端 API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_7">
          <span class="md-nav__icon md-icon"></span>
          前端 API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/42/" class="md-nav__link">
        PyTorch 中的命名张量简介（原型）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/43/" class="md-nav__link">
        PyTorch 中通道在最后的内存格式（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/44/" class="md-nav__link">
        使用 PyTorch C-- 前端
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/45/" class="md-nav__link">
        自定义 C-- 和 CUDA 扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/46/" class="md-nav__link">
        使用自定义 C-- 运算符扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/47/" class="md-nav__link">
        使用自定义 C-- 类扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/48/" class="md-nav__link">
        TorchScript 中的动态并行性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/49/" class="md-nav__link">
        C-- 前端中的 Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/50/" class="md-nav__link">
        在 C-- 中注册调度运算符
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_8" >
      
      
      
        <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
          模型优化
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_8">
          <span class="md-nav__icon md-icon"></span>
          模型优化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/52/" class="md-nav__link">
        分析您的 PyTorch 模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/53/" class="md-nav__link">
        使用 Ray Tune 的超参数调整
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/54/" class="md-nav__link">
        模型剪裁教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/55/" class="md-nav__link">
        LSTM 单词语言模型上的动态量化（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/56/" class="md-nav__link">
        BERT 上的动态量化（Beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/57/" class="md-nav__link">
        PyTorch 中使用 Eager 模式的静态量化（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/58/" class="md-nav__link">
        计算机视觉的量化迁移学习教程（beta）
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_9" >
      
      
      
        <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
          并行和分布式训练
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_9">
          <span class="md-nav__icon md-icon"></span>
          并行和分布式训练
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/60/" class="md-nav__link">
        PyTorch 分布式概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/61/" class="md-nav__link">
        单机模型并行最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/62/" class="md-nav__link">
        分布式数据并行入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/63/" class="md-nav__link">
        用 PyTorch 编写分布式应用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/64/" class="md-nav__link">
        分布式 RPC 框架入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/65/" class="md-nav__link">
        使用分布式 RPC 框架实现参数服务器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/66/" class="md-nav__link">
        使用 RPC 的分布式管道并行化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/67/" class="md-nav__link">
        使用异步执行实现批量 RPC 处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/68/" class="md-nav__link">
        将分布式DataParallel与分布式 RPC 框架相结合
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          PyTorch 1.4 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.4 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
          入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1_1" id="__nav_4_1_1_label" tabindex="0">
          使用 PyTorch 进行深度学习：60 分钟的闪电战
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1_1">
          <span class="md-nav__icon md-icon"></span>
          使用 PyTorch 进行深度学习：60 分钟的闪电战
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/4/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/tensor_tutorial/" class="md-nav__link">
        什么是PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/autograd_tutorial/" class="md-nav__link">
        Autograd：自动求导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/cifar10_tutorial/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/data_parallel_tutorial/" class="md-nav__link">
        可选：数据并行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/5/" class="md-nav__link">
        编写自定义数据集，数据加载器和转换
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/6/" class="md-nav__link">
        使用 TensorBoard 可视化模型，数据和训练
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
      
      
      
        <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
          图片
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          图片
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/8/" class="md-nav__link">
        TorchVision 对象检测微调教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/9/" class="md-nav__link">
        转移学习的计算机视觉教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/10/" class="md-nav__link">
        空间变压器网络教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/11/" class="md-nav__link">
        使用 PyTorch 进行神经传递
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/12/" class="md-nav__link">
        对抗示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/13/" class="md-nav__link">
        DCGAN 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
      
      
      
        <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
          音频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          音频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/15/" class="md-nav__link">
        torchaudio 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/17/" class="md-nav__link">
        NLP From Scratch: 使用char-RNN对姓氏进行分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/18/" class="md-nav__link">
        NLP From Scratch: 生成名称与字符级RNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/19/" class="md-nav__link">
        NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/20/" class="md-nav__link">
        使用 TorchText 进行文本分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/21/" class="md-nav__link">
        使用 TorchText 进行语言翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/22/" class="md-nav__link">
        使用 nn.Transformer 和 TorchText 进行序列到序列建模
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
      
      
      
        <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
          命名为 Tensor(实验性）
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_5">
          <span class="md-nav__icon md-icon"></span>
          命名为 Tensor(实验性）
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/24/" class="md-nav__link">
        (实验性)PyTorch 中的命名张量简介
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6" >
      
      
      
        <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_6">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/26/" class="md-nav__link">
        强化学习(DQN)教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_7" >
      
      
      
        <label class="md-nav__link" for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
          在生产中部署 PyTorch 模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_7">
          <span class="md-nav__icon md-icon"></span>
          在生产中部署 PyTorch 模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/28/" class="md-nav__link">
        通过带有 Flask 的 REST API 在 Python 中部署 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/29/" class="md-nav__link">
        TorchScript 简介
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/30/" class="md-nav__link">
        在 C --中加载 TorchScript 模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/31/" class="md-nav__link">
        (可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_8" >
      
      
      
        <label class="md-nav__link" for="__nav_4_8" id="__nav_4_8_label" tabindex="0">
          并行和分布式训练
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_8">
          <span class="md-nav__icon md-icon"></span>
          并行和分布式训练
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/33/" class="md-nav__link">
        单机模型并行最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/34/" class="md-nav__link">
        分布式数据并行入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/35/" class="md-nav__link">
        用 PyTorch 编写分布式应用程序
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/36/" class="md-nav__link">
        分布式 RPC 框架入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/37/" class="md-nav__link">
        (高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_9" >
      
      
      
        <label class="md-nav__link" for="__nav_4_9" id="__nav_4_9_label" tabindex="0">
          扩展 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_9">
          <span class="md-nav__icon md-icon"></span>
          扩展 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/39/" class="md-nav__link">
        使用自定义 C --运算符扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/40/" class="md-nav__link">
        使用自定义 C --类扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/41/" class="md-nav__link">
        使用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/42/" class="md-nav__link">
        自定义 C --和 CUDA 扩展
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_10" >
      
      
      
        <label class="md-nav__link" for="__nav_4_10" id="__nav_4_10_label" tabindex="0">
          模型优化
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_10_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_10">
          <span class="md-nav__icon md-icon"></span>
          模型优化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/44/" class="md-nav__link">
        LSTM Word 语言模型上的(实验）动态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/45/" class="md-nav__link">
        (实验性）在 PyTorch 中使用 Eager 模式进行静态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/46/" class="md-nav__link">
        (实验性）计算机视觉教程的量化转移学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/47/" class="md-nav__link">
        (实验）BERT 上的动态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/48/" class="md-nav__link">
        修剪教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_11" >
      
      
      
        <label class="md-nav__link" for="__nav_4_11" id="__nav_4_11_label" tabindex="0">
          PyTorch 用其他语言
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_11_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_11">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 用其他语言
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/50/" class="md-nav__link">
        使用 PyTorch C --前端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_12" >
      
      
      
        <label class="md-nav__link" for="__nav_4_12" id="__nav_4_12_label" tabindex="0">
          PyTorch 基础知识
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_12_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_12">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 基础知识
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/52/" class="md-nav__link">
        通过示例学习 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/53/" class="md-nav__link">
        torch.nn 到底是什么？
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_13" >
      
      
      
        <label class="md-nav__link" for="__nav_4_13" id="__nav_4_13_label" tabindex="0">
          笔记
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_13_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_13">
          <span class="md-nav__icon md-icon"></span>
          笔记
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/56/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/57/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/58/" class="md-nav__link">
        CPU 线程和 TorchScript 推断
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/59/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/60/" class="md-nav__link">
        分布式 Autograd 设计
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/61/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/62/" class="md-nav__link">
        经常问的问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/63/" class="md-nav__link">
        大规模部署的功能
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/64/" class="md-nav__link">
        并行处理最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/65/" class="md-nav__link">
        重现性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/66/" class="md-nav__link">
        远程参考协议
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/67/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/68/" class="md-nav__link">
        Windows 常见问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/69/" class="md-nav__link">
        XLA 设备上的 PyTorch
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_14" >
      
      
      
        <label class="md-nav__link" for="__nav_4_14" id="__nav_4_14_label" tabindex="0">
          语言绑定
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_14_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_14">
          <span class="md-nav__icon md-icon"></span>
          语言绑定
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/71/" class="md-nav__link">
        PyTorch C -- API
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/72/" class="md-nav__link">
        PyTorch Java API
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_15" >
      
      
      
        <label class="md-nav__link" for="__nav_4_15" id="__nav_4_15_label" tabindex="0">
          Python API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_15_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_15">
          <span class="md-nav__icon md-icon"></span>
          Python API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/74/" class="md-nav__link">
        torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/75/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/76/" class="md-nav__link">
        torch功能
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/77/" class="md-nav__link">
        torch张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/78/" class="md-nav__link">
        张量属性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/79/" class="md-nav__link">
        自动差分包-Torch.Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/80/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/81/" class="md-nav__link">
        分布式通讯包-Torch.Distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/82/" class="md-nav__link">
        概率分布-torch分布
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/83/" class="md-nav__link">
        torch.hub
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/84/" class="md-nav__link">
        torch脚本
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/85/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/86/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/87/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/88/" class="md-nav__link">
        量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/89/" class="md-nav__link">
        分布式 RPC 框架
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/90/" class="md-nav__link">
        torch随机
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/91/" class="md-nav__link">
        torch稀疏
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/92/" class="md-nav__link">
        torch存储
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/93/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/94/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/95/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/96/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/97/" class="md-nav__link">
        torch.utils.dlpack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/98/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/99/" class="md-nav__link">
        torch.utils.tensorboard
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/100/" class="md-nav__link">
        类型信息
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/101/" class="md-nav__link">
        命名张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/102/" class="md-nav__link">
        命名为 Tensors 操作员范围
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/103/" class="md-nav__link">
        糟糕！
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_16" >
      
      
      
        <label class="md-nav__link" for="__nav_4_16" id="__nav_4_16_label" tabindex="0">
          torchvision参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_16_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_16">
          <span class="md-nav__icon md-icon"></span>
          torchvision参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/105/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_17" >
      
      
      
        <label class="md-nav__link" for="__nav_4_17" id="__nav_4_17_label" tabindex="0">
          音频参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_17_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_17">
          <span class="md-nav__icon md-icon"></span>
          音频参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/107/" class="md-nav__link">
        torchaudio
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_18" >
      
      
      
        <label class="md-nav__link" for="__nav_4_18" id="__nav_4_18_label" tabindex="0">
          torchtext参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_18_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_18">
          <span class="md-nav__icon md-icon"></span>
          torchtext参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/109/" class="md-nav__link">
        torchtext
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_19" >
      
      
      
        <label class="md-nav__link" for="__nav_4_19" id="__nav_4_19_label" tabindex="0">
          社区
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_19_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_19">
          <span class="md-nav__icon md-icon"></span>
          社区
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/111/" class="md-nav__link">
        PyTorch 贡献指南
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/112/" class="md-nav__link">
        PyTorch 治理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/113/" class="md-nav__link">
        PyTorch 治理| 感兴趣的人
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          PyTorch 1.0 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.0 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_1" id="__nav_5_2_1_label" tabindex="0">
          入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_1">
          <span class="md-nav__icon md-icon"></span>
          入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_1_1" id="__nav_5_2_1_1_label" tabindex="0">
          PyTorch 深度学习: 60 分钟极速入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习: 60 分钟极速入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning_60min_blitz/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_tensor_tutorial/" class="md-nav__link">
        什么是 PyTorch？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_autograd_tutorial/" class="md-nav__link">
        Autograd：自动求导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_cifar10_tutorial/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_data_parallel_tutorial/" class="md-nav__link">
        可选：数据并行处理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../data_loading_tutorial/" class="md-nav__link">
        数据加载和处理教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples/" class="md-nav__link">
        用例子学习 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../transfer_learning_tutorial/" class="md-nav__link">
        迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../deploy_seq2seq_hybrid_frontend_tutorial/" class="md-nav__link">
        混合前端的 seq2seq 模型部署
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../saving_loading_models/" class="md-nav__link">
        Saving and Loading Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nn_tutorial/" class="md-nav__link">
        What is torch.nn really?
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_2" id="__nav_5_2_2_label" tabindex="0">
          图像
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_2">
          <span class="md-nav__icon md-icon"></span>
          图像
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../finetuning_torchvision_models_tutorial/" class="md-nav__link">
        Torchvision 模型微调
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../spatial_transformer_tutorial/" class="md-nav__link">
        空间变换器网络教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../neural_style_tutorial/" class="md-nav__link">
        使用 PyTorch 进行图像风格转换
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../fgsm_tutorial/" class="md-nav__link">
        对抗性示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../super_resolution_with_caffe2/" class="md-nav__link">
        使用 ONNX 将模型从 PyTorch 传输到 Caffe2 和移动端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_3" id="__nav_5_2_3_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_3">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../chatbot_tutorial/" class="md-nav__link">
        聊天机器人教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_generation_tutorial/" class="md-nav__link">
        使用字符级别特征的 RNN 网络生成姓氏
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_classification_tutorial/" class="md-nav__link">
        使用字符级别特征的 RNN 网络进行姓氏分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3_4" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_3_4" id="__nav_5_2_3_4_label" tabindex="0">
          Deep Learning for NLP with Pytorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_3_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_3_4">
          <span class="md-nav__icon md-icon"></span>
          Deep Learning for NLP with Pytorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning_nlp_tutorial/" class="md-nav__link">
        在深度学习和 NLP 中使用 Pytorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_pytorch_tutorial/" class="md-nav__link">
        PyTorch 介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_deep_learning_tutorial/" class="md-nav__link">
        使用 PyTorch 进行深度学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_word_embeddings_tutorial/" class="md-nav__link">
        Word Embeddings: Encoding Lexical Semantics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_sequence_models_tutorial/" class="md-nav__link">
        序列模型和 LSTM 网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_advanced_tutorial/" class="md-nav__link">
        Advanced: Making Dynamic Decisions and the Bi-LSTM CRF
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../seq2seq_translation_tutorial/" class="md-nav__link">
        基于注意力机制的 seq2seq 神经网络翻译
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_4" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_4" id="__nav_5_2_4_label" tabindex="0">
          生成
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_4">
          <span class="md-nav__icon md-icon"></span>
          生成
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dcgan_faces_tutorial/" class="md-nav__link">
        DCGAN Tutorial
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_5" id="__nav_5_2_5_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_5">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../reinforcement_q_learning/" class="md-nav__link">
        Reinforcement Learning (DQN) Tutorial
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_6" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_6" id="__nav_5_2_6_label" tabindex="0">
          扩展 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_6">
          <span class="md-nav__icon md-icon"></span>
          扩展 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../numpy_extensions_tutorial/" class="md-nav__link">
        用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_extension/" class="md-nav__link">
        Custom C-- and CUDA Extensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_script_custom_ops/" class="md-nav__link">
        Extending TorchScript with Custom C-- Operators
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_7" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_7" id="__nav_5_2_7_label" tabindex="0">
          生产性使用
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_7">
          <span class="md-nav__icon md-icon"></span>
          生产性使用
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dist_tuto/" class="md-nav__link">
        Writing Distributed Applications with PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../aws_distributed_training_tutorial/" class="md-nav__link">
        使用 Amazon AWS 进行分布式训练
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ONNXLive/" class="md-nav__link">
        ONNX 现场演示教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_export/" class="md-nav__link">
        在 C-- 中加载 PYTORCH 模型
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_8" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_8" id="__nav_5_2_8_label" tabindex="0">
          其它语言中的 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_8">
          <span class="md-nav__icon md-icon"></span>
          其它语言中的 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_frontend/" class="md-nav__link">
        使用 PyTorch C-- 前端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" checked>
      
      
      
        <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_1" id="__nav_5_3_1_label" tabindex="0">
          注解
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_1">
          <span class="md-nav__icon md-icon"></span>
          注解
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_broadcasting/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_cuda/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_extending/" class="md-nav__link">
        Extending PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_faq/" class="md-nav__link">
        Frequently Asked Questions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_multiprocessing/" class="md-nav__link">
        Multiprocessing best practices
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_randomness/" class="md-nav__link">
        Reproducibility
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_serialization/" class="md-nav__link">
        Serialization semantics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_windows/" class="md-nav__link">
        Windows FAQ
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2" checked>
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2" id="__nav_5_3_2_label" tabindex="0">
          包参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_2_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5_3_2">
          <span class="md-nav__icon md-icon"></span>
          包参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2_1" id="__nav_5_3_2_1_label" tabindex="0">
          torch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_3_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_2_1">
          <span class="md-nav__icon md-icon"></span>
          torch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_tensors/" class="md-nav__link">
        Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_random_sampling/" class="md-nav__link">
        Random sampling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_serialization_parallelism_utilities/" class="md-nav__link">
        Serialization, Parallelism, Utilities
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2_1_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2_1_5" id="__nav_5_3_2_1_5_label" tabindex="0">
          Math operations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_5_3_2_1_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_2_1_5">
          <span class="md-nav__icon md-icon"></span>
          Math operations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_pointwise_ops/" class="md-nav__link">
        Pointwise Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_reduction_ops/" class="md-nav__link">
        Reduction Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_comparison_ops/" class="md-nav__link">
        Comparison Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_spectral_ops/" class="md-nav__link">
        Spectral Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_other_ops/" class="md-nav__link">
        Other Operations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_blas_lapack_ops/" class="md-nav__link">
        BLAS and LAPACK Operations
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        torch.Tensor
      </a>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tensor_attributes/" class="md-nav__link">
        Tensor Attributes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../type_info/" class="md-nav__link">
        数据类型信息
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../sparse/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nn_functional/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nn_init/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../autograd/" class="md-nav__link">
        Automatic differentiation package - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../distributed/" class="md-nav__link">
        Distributed communication package - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../distributions/" class="md-nav__link">
        Probability distributions - torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../jit/" class="md-nav__link">
        Torch Script
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../multiprocessing/" class="md-nav__link">
        多进程包 - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../bottleneck/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../checkpoint/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../docs_cpp_extension/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dlpack/" class="md-nav__link">
        torch.utils.dlpack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../hub/" class="md-nav__link">
        torch.hub
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../onnx/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../distributed_deprecated/" class="md-nav__link">
        Distributed communication package (deprecated) - torch.distributed.deprecated
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_3" id="__nav_5_3_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../docs_torchvision_ref/" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_transforms/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          PyTorch 0.4 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.4 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" >
      
      
      
        <label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
          笔记
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          笔记
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/1/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/2/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/3/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/4/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/5/" class="md-nav__link">
        常见问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/6/" class="md-nav__link">
        多进程最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/7/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/8/" class="md-nav__link">
        Windows 常见问题
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
      
      
      
        <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
          包参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_2">
          <span class="md-nav__icon md-icon"></span>
          包参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/10/" class="md-nav__link">
        Torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/11/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/12/" class="md-nav__link">
        Tensor Attributes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/13/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/14/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/15/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/16/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/17/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/18/" class="md-nav__link">
        自动差异化包 - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/19/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/20/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/21/" class="md-nav__link">
        torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/22/" class="md-nav__link">
        Multiprocessing 包 - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/23/" class="md-nav__link">
        分布式通讯包 - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/24/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/25/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/26/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/27/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/28/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/29/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/30/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/31/" class="md-nav__link">
        遗留包 - torch.legacy
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
      
      
      
        <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/33/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/34/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/35/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/36/" class="md-nav__link">
        torchvision.transform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/37/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
      
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          PyTorch 0.3 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.3 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1" id="__nav_7_2_1_label" tabindex="0">
          初学者教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1">
          <span class="md-nav__icon md-icon"></span>
          初学者教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_1" id="__nav_7_2_1_1_label" tabindex="0">
          PyTorch 深度学习: 60 分钟极速入门教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习: 60 分钟极速入门教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/deep_learning_60min_blitz/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_tensor_tutorial/" class="md-nav__link">
        PyTorch 是什么？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_autograd_tutorial/" class="md-nav__link">
        自动求导: 自动微分
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_cifar10_tutorial/" class="md-nav__link">
        训练一个分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/blitz_data_parallel_tutorial/" class="md-nav__link">
        可选: 数据并行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_2" id="__nav_7_2_1_2_label" tabindex="0">
          PyTorch for former Torch users
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_2">
          <span class="md-nav__icon md-icon"></span>
          PyTorch for former Torch users
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_tutorial/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_tensor_tutorial/" class="md-nav__link">
        Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_autograd_tutorial/" class="md-nav__link">
        Autograd (自动求导)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_nn_tutorial/" class="md-nav__link">
        nn package
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/former_torchies_parallelism_tutorial/" class="md-nav__link">
        Multi-GPU examples
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_3" id="__nav_7_2_1_3_label" tabindex="0">
          跟着例子学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_3">
          <span class="md-nav__icon md-icon"></span>
          跟着例子学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_warm-up-numpy/" class="md-nav__link">
        Warm-up: numpy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-tensors/" class="md-nav__link">
        PyTorch: Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-variables-and-autograd/" class="md-nav__link">
        PyTorch: 变量和autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-defining-new-autograd-functions/" class="md-nav__link">
        PyTorch: 定义新的autograd函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_tensorflow-static-graphs/" class="md-nav__link">
        TensorFlow: 静态图
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-nn/" class="md-nav__link">
        PyTorch: nn包
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-optim/" class="md-nav__link">
        PyTorch: optim包
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-custom-nn-modules/" class="md-nav__link">
        PyTorch: 定制化nn模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/pytorch_with_examples_pytorch-control-flow-weight-sharing/" class="md-nav__link">
        PyTorch: 动态控制流程 - 权重共享
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/transfer_learning_tutorial/" class="md-nav__link">
        迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/data_loading_tutorial/" class="md-nav__link">
        数据加载和处理教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_6" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_6" id="__nav_7_2_1_6_label" tabindex="0">
          针对NLP的Pytorch深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_6">
          <span class="md-nav__icon md-icon"></span>
          针对NLP的Pytorch深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/deep_learning_nlp_tutorial/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_pytorch_tutorial/" class="md-nav__link">
        PyTorch介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_deep_learning_tutorial/" class="md-nav__link">
        PyTorch深度学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_word_embeddings_tutorial/" class="md-nav__link">
        词汇嵌入:编码词汇语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_sequence_models_tutorial/" class="md-nav__link">
        序列模型和 LSTM 网络(长短记忆网络）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nlp_advanced_tutorial/" class="md-nav__link">
        高级教程: 作出动态决策和 Bi-LSTM CRF
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_2" id="__nav_7_2_2_label" tabindex="0">
          中级教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_2">
          <span class="md-nav__icon md-icon"></span>
          中级教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/char_rnn_classification_tutorial/" class="md-nav__link">
        用字符级RNN分类名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/char_rnn_generation_tutorial/" class="md-nav__link">
        基与字符级RNN(Char-RNN）的人名生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/seq2seq_translation_tutorial/" class="md-nav__link">
        用基于注意力机制的seq2seq神经网络进行翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/reinforcement_q_learning/" class="md-nav__link">
        强化学习(DQN）教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/dist_tuto/" class="md-nav__link">
        Writing Distributed Applications with PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/spatial_transformer_tutorial/" class="md-nav__link">
        空间转换网络 (Spatial Transformer Networks) 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_3" id="__nav_7_2_3_label" tabindex="0">
          高级教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_3">
          <span class="md-nav__icon md-icon"></span>
          高级教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/neural_style_tutorial/" class="md-nav__link">
        用 PyTorch 做 神经转换 (Neural Transfer)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/numpy_extensions_tutorial/" class="md-nav__link">
        使用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/super_resolution_with_caffe2/" class="md-nav__link">
        使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/c_extension/" class="md-nav__link">
        为 pytorch 自定义 C 扩展
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3_1" id="__nav_7_3_1_label" tabindex="0">
          介绍
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3_1">
          <span class="md-nav__icon md-icon"></span>
          介绍
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_broadcasting/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_cuda/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_extending/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_multiprocessing/" class="md-nav__link">
        多进程的最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/notes_serialization/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3_2" id="__nav_7_3_2_label" tabindex="0">
          Package 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3_2">
          <span class="md-nav__icon md-icon"></span>
          Package 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/torch/" class="md-nav__link">
        torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/tensors/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/sparse/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/autograd/" class="md-nav__link">
        Automatic differentiation package - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/distributions/" class="md-nav__link">
        Probability distributions - torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/multiprocessing/" class="md-nav__link">
        Multiprocessing package - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/distributed/" class="md-nav__link">
        Distributed communication package - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/legacy/" class="md-nav__link">
        Legacy package - torch.legacy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/ffi/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/onnx/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3_3" id="__nav_7_3_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/torchvision/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/transforms/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.3/utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
      
      
      
        <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
          PyTorch 0.2 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.2 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2" >
      
      
      
        <label class="md-nav__link" for="__nav_8_2" id="__nav_8_2_label" tabindex="0">
          说明
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_2">
          <span class="md-nav__icon md-icon"></span>
          说明
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/cuda/" class="md-nav__link">
        CUDA语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/extending/" class="md-nav__link">
        扩展PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/multiprocessing/" class="md-nav__link">
        多进程最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/serialization/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_3" >
      
      
      
        <label class="md-nav__link" for="__nav_8_3" id="__nav_8_3_label" tabindex="0">
          PACKAGE参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_3">
          <span class="md-nav__icon md-icon"></span>
          PACKAGE参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch/" class="md-nav__link">
        torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/Tensor/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/Storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/functional/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-autograd/" class="md-nav__link">
        torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/nn_init/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-multiprocessing/" class="md-nav__link">
        torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/legacy/" class="md-nav__link">
        torch.legacy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/ffi/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_4" >
      
      
      
        <label class="md-nav__link" for="__nav_8_4" id="__nav_8_4_label" tabindex="0">
          TORCHVISION参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_4">
          <span class="md-nav__icon md-icon"></span>
          TORCHVISION参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-transform/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/acknowledgement/" class="md-nav__link">
        致谢
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../contrib/" class="md-nav__link">
        贡献者
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about/" class="md-nav__link">
        关于我们
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        中文资源合集
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/1.0/tensors.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/1.0/tensors.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<div class="wwads-cn wwads-horizontal" data-id="206" style="max-width:680px"></div>
<h1 id="torchtensor">torch.Tensor</h1>
<blockquote>
<p>译者：<a href="https://github.com/hijkzzz">hijkzzz</a></p>
</blockquote>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 是一种包含单一数据类型元素的多维矩阵.</p>
<p>Torch定义了八种CPU张量类型和八种GPU张量类型：</p>
<table>
<thead>
<tr>
<th>Data type</th>
<th>dtype</th>
<th>CPU tensor</th>
<th>GPU tensor</th>
</tr>
</thead>
<tbody>
<tr>
<td>32-bit floating point</td>
<td><code>torch.float32</code> or <code>torch.float</code></td>
<td><code>torch.FloatTensor</code></td>
<td><code>torch.cuda.FloatTensor</code></td>
</tr>
<tr>
<td>64-bit floating point</td>
<td><code>torch.float64</code> or <code>torch.double</code></td>
<td><code>torch.DoubleTensor</code></td>
<td><code>torch.cuda.DoubleTensor</code></td>
</tr>
<tr>
<td>16-bit floating point</td>
<td><code>torch.float16</code> or <code>torch.half</code></td>
<td><code>torch.HalfTensor</code></td>
<td><code>torch.cuda.HalfTensor</code></td>
</tr>
<tr>
<td>8-bit integer (unsigned)</td>
<td><code>torch.uint8</code></td>
<td><a href="#torch.ByteTensor" title="torch.ByteTensor"><code>torch.ByteTensor</code></a></td>
<td><code>torch.cuda.ByteTensor</code></td>
</tr>
<tr>
<td>8-bit integer (signed)</td>
<td><code>torch.int8</code></td>
<td><code>torch.CharTensor</code></td>
<td><code>torch.cuda.CharTensor</code></td>
</tr>
<tr>
<td>16-bit integer (signed)</td>
<td><code>torch.int16</code> or <code>torch.short</code></td>
<td><code>torch.ShortTensor</code></td>
<td><code>torch.cuda.ShortTensor</code></td>
</tr>
<tr>
<td>32-bit integer (signed)</td>
<td><code>torch.int32</code> or <code>torch.int</code></td>
<td><code>torch.IntTensor</code></td>
<td><code>torch.cuda.IntTensor</code></td>
</tr>
<tr>
<td>64-bit integer (signed)</td>
<td><code>torch.int64</code> or <code>torch.long</code></td>
<td><code>torch.LongTensor</code></td>
<td><code>torch.cuda.LongTensor</code></td>
</tr>
</tbody>
</table>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 是默认的tensor类型 (<code>torch.FloatTensor</code>) 的简称.</p>
<p>Tensor 可以用<a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a>转换Python的 <a href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><code>list</code></a> 或序列​​生成：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.tensor([[1., -1.], [1., -1.]])
tensor([[ 1.0000, -1.0000],
 [ 1.0000, -1.0000]])
&gt;&gt;&gt; torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))
tensor([[ 1,  2,  3],
 [ 4,  5,  6]])

</code></pre>
<p>警告</p>
<p><a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> 总是拷贝 <code>data</code>. 如果你有一个 Tensor <code>data</code> 并且仅仅想改变它的 <code>requires_grad</code> 属性, 可用 <a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a> or <a href="autograd.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>detach()</code></a> 来避免拷贝. 如果你有一个 numpy 数组并且想避免拷贝, 请使用 <a href="torch.html#torch.as_tensor" title="torch.as_tensor"><code>torch.as_tensor()</code></a>.</p>
<p>指定数据类型的Tensor可以通过传递参数 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和/或者  <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 到构造函数生成：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.zeros([2, 4], dtype=torch.int32)
tensor([[ 0,  0,  0,  0],
 [ 0,  0,  0,  0]], dtype=torch.int32)
&gt;&gt;&gt; cuda0 = torch.device('cuda:0')
&gt;&gt;&gt; torch.ones([2, 4], dtype=torch.float64, device=cuda0)
tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],
 [ 1.0000,  1.0000,  1.0000,  1.0000]], dtype=torch.float64, device='cuda:0')

</code></pre>
<p>Tensor的内容可以通过Python索引或者切片访问以及修改：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6]])
&gt;&gt;&gt; print(x[1][2])
tensor(6)
&gt;&gt;&gt; x[0][1] = 8
&gt;&gt;&gt; print(x)
tensor([[ 1,  8,  3],
 [ 4,  5,  6]])

</code></pre>
<p>使用 <a href="#torch.Tensor.item" title="torch.Tensor.item"><code>torch.Tensor.item()</code></a> 从只有一个值的Tensor中获取Python Number：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([[1]])
&gt;&gt;&gt; x
tensor([[ 1]])
&gt;&gt;&gt; x.item()
1
&gt;&gt;&gt; x = torch.tensor(2.5)
&gt;&gt;&gt; x
tensor(2.5000)
&gt;&gt;&gt; x.item()
2.5

</code></pre>
<p>Tensor可以通过参数 <code>requires_grad=True</code> 创建, 这样 <a href="autograd.html#module-torch.autograd" title="torch.autograd"><code>torch.autograd</code></a> 会记录相关的运算实现自动求导.</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)
&gt;&gt;&gt; out = x.pow(2).sum()
&gt;&gt;&gt; out.backward()
&gt;&gt;&gt; x.grad
tensor([[ 2.0000, -2.0000],
 [ 2.0000,  2.0000]])

</code></pre>
<p>每一个tensor都有一个相应的 <code>torch.Storage</code> 保存其数据. tensor 类提供了一个多维的、<a href="https://en.wikipedia.org/wiki/Stride_of_an_array">strided</a>视图, 并定义了数值操作.</p>
<p>注意</p>
<p>更多关于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 和 <a href="tensor_attributes.html#torch.torch.layout" title="torch.torch.layout"><code>torch.layout</code></a>  等 <a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>的属性, 见 <a href="tensor_attributes.html#tensor-attributes-doc">Tensor Attributes</a>.</p>
<p>注意</p>
<p>注意：修改tensor的方法可以用一个下划线后缀来标示.比如, <code>torch.FloatTensor.abs_()</code> 会在原地计算绝对值并返回修改的张量, 而 <code>torch.FloatTensor.abs()</code> 将会在新张量中计算结果.</p>
<p>注意</p>
<p>为了改变已有的 tensor 的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 和/或者 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 考虑使用 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 方法.</p>
<pre><code class="language-py">class torch.Tensor
</code></pre>
<p>这里有少数几种生成Tensor的方法, 取决于你的实际情况.</p>
<ul>
<li>从已经存在的数据生成, 用 <a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a>.</li>
<li>生成特殊尺寸的Tensor, 用 <code>torch.*</code> creation ops (见 <a href="torch.html#tensor-creation-ops">Creation Ops</a>).</li>
<li>生成与其它Tensor尺寸相同的Tensor (并且数据类型相同), 用 <code>torch.*_like</code> creation ops (见 <a href="torch.html#tensor-creation-ops">Creation Ops</a>).</li>
<li>生成与其它Tesor数据类型相同但是尺寸不同的Tensor, 用 <code>tensor.new_*</code> creation ops.</li>
</ul>
<pre><code class="language-py">new_tensor(data, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回一个新的Tensor用 <code>data</code> 作为tensor data.默认情况下, 返回的Tensor有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> .</p>
<p>警告</p>
<p><a href="#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>new_tensor()</code></a> 总是拷贝 <code>data</code>. 如果 你有一个 Tensor <code>data</code> 并且想避免拷贝, 使用 <a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>torch.Tensor.requires_grad_()</code></a> 或者 <a href="autograd.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>torch.Tensor.detach()</code></a>. 如果你有一个 numpy 数组并且想避免拷贝, 使用 <a href="torch.html#torch.from_numpy" title="torch.from_numpy"><code>torch.from_numpy()</code></a>.</p>
<p>警告</p>
<p>当 data 是一个 tensor <code>x</code>, <a href="#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>new_tensor()</code></a> 读取 x 的 'data' 并且创建一个叶子变量. 因此 <code>tensor.new_tensor(x)</code> 等价于 <code>x.clone().detach()</code> 并且 <code>tensor.new_tensor(x, requires_grad=True)</code> 等价于 <code>x.clone().detach().requires_grad_(True)</code>. 推荐使用 <code>clone()</code> 和 <code>detach()</code>.</p>
<p>参数: </p>
<ul>
<li><strong>data</strong> (<em>array_like</em>) – 返回的 Tensor 拷贝 <code>data</code>.</li>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; tensor = torch.ones((2,), dtype=torch.int8)
&gt;&gt;&gt; data = [[0, 1], [2, 3]]
&gt;&gt;&gt; tensor.new_tensor(data)
tensor([[ 0,  1],
 [ 2,  3]], dtype=torch.int8)

</code></pre>
<pre><code class="language-py">new_full(size, fill_value, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回一个Tesnor的尺寸等于 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 用 <code>fill_value</code>填充. 默认情况下, 返回的 Tensor 具有与此Tensor相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>参数: </p>
<ul>
<li><strong>fill_value</strong> (<em>scalar</em>) – 用于填充的数值.</li>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; tensor = torch.ones((2,), dtype=torch.float64)
&gt;&gt;&gt; tensor.new_full((3, 4), 3.141592)
tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],
 [ 3.1416,  3.1416,  3.1416,  3.1416],
 [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)

</code></pre>
<pre><code class="language-py">new_empty(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回一个Tesnor的尺寸等于 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 用 <code>未初始化的值</code>填充. 默认情况下, 返回的 Tensor 具有与此Tensor相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>Parameters: </p>
<ul>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>Example:</p>
<pre><code class="language-py">&gt;&gt;&gt; tensor = torch.ones(())
&gt;&gt;&gt; tensor.new_empty((2, 3))
tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],
 [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])

</code></pre>
<pre><code class="language-py">new_ones(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回一个Tesnor的尺寸等于 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 用 <code>1</code>填充. 默认情况下, 返回的 Tensor 具有与此Tensor相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>Parameters: </p>
<ul>
<li><strong>size</strong> (<em>int...</em>) – list, tuple, 或者 <code>torch.Size</code> 定义了输出Tensor的形状.</li>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; tensor = torch.tensor((), dtype=torch.int32)
&gt;&gt;&gt; tensor.new_ones((2, 3))
tensor([[ 1,  1,  1],
 [ 1,  1,  1]], dtype=torch.int32)

</code></pre>
<pre><code class="language-py">new_zeros(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre>
<p>返回一个Tesnor的尺寸等于 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 用 <code>0</code>填充. 默认情况下, 返回的 Tensor 具有与此Tensor相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>参数: </p>
<ul>
<li><strong>size</strong> (<em>int...</em>) – list, tuple, 或者 <code>torch.Size</code> 定义了输出Tensor的形状.</li>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; tensor = torch.tensor((), dtype=torch.float64)
&gt;&gt;&gt; tensor.new_zeros((2, 3))
tensor([[ 0.,  0.,  0.],
 [ 0.,  0.,  0.]], dtype=torch.float64)

</code></pre>
<pre><code class="language-py">is_cuda
</code></pre>
<p><code>True</code> 如果 Tensor 在 GPU 上, 否则 <code>False</code>.</p>
<pre><code class="language-py">device
</code></pre>
<p><a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> Tensor 所在的设备.</p>
<pre><code class="language-py">abs() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.abs" title="torch.abs"><code>torch.abs()</code></a></p>
<pre><code class="language-py">abs_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.abs" title="torch.Tensor.abs"><code>abs()</code></a></p>
<pre><code class="language-py">acos() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.acos" title="torch.acos"><code>torch.acos()</code></a></p>
<pre><code class="language-py">acos_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.acos" title="torch.Tensor.acos"><code>acos()</code></a></p>
<pre><code class="language-py">add(value) → Tensor
</code></pre>
<p>add(value=1, other) -&gt; Tensor</p>
<p>见 <a href="torch.html#torch.add" title="torch.add"><code>torch.add()</code></a></p>
<pre><code class="language-py">add_(value) → Tensor
</code></pre>
<p>add_(value=1, other) -&gt; Tensor</p>
<p>原地版本的 <a href="#torch.Tensor.add" title="torch.Tensor.add"><code>add()</code></a></p>
<pre><code class="language-py">addbmm(beta=1, mat, alpha=1, batch1, batch2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.addbmm" title="torch.addbmm"><code>torch.addbmm()</code></a></p>
<pre><code class="language-py">addbmm_(beta=1, mat, alpha=1, batch1, batch2) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code>addbmm()</code></a></p>
<pre><code class="language-py">addcdiv(value=1, tensor1, tensor2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.addcdiv" title="torch.addcdiv"><code>torch.addcdiv()</code></a></p>
<pre><code class="language-py">addcdiv_(value=1, tensor1, tensor2) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code>addcdiv()</code></a></p>
<pre><code class="language-py">addcmul(value=1, tensor1, tensor2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.addcmul" title="torch.addcmul"><code>torch.addcmul()</code></a></p>
<pre><code class="language-py">addcmul_(value=1, tensor1, tensor2) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code>addcmul()</code></a></p>
<pre><code class="language-py">addmm(beta=1, mat, alpha=1, mat1, mat2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.addmm" title="torch.addmm"><code>torch.addmm()</code></a></p>
<pre><code class="language-py">addmm_(beta=1, mat, alpha=1, mat1, mat2) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.addmm" title="torch.Tensor.addmm"><code>addmm()</code></a></p>
<pre><code class="language-py">addmv(beta=1, tensor, alpha=1, mat, vec) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.addmv" title="torch.addmv"><code>torch.addmv()</code></a></p>
<pre><code class="language-py">addmv_(beta=1, tensor, alpha=1, mat, vec) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.addmv" title="torch.Tensor.addmv"><code>addmv()</code></a></p>
<pre><code class="language-py">addr(beta=1, alpha=1, vec1, vec2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.addr" title="torch.addr"><code>torch.addr()</code></a></p>
<pre><code class="language-py">addr_(beta=1, alpha=1, vec1, vec2) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.addr" title="torch.Tensor.addr"><code>addr()</code></a></p>
<pre><code class="language-py">allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.allclose" title="torch.allclose"><code>torch.allclose()</code></a></p>
<pre><code class="language-py">apply_(callable) → Tensor
</code></pre>
<p>应用函数 <code>callable</code> 到Tensor中的每一个元素, 用 <code>callable</code>的返回值替换每一个元素.</p>
<p>注意</p>
<p>这个函数仅仅能在CPU上工作, 并且不要用于需要高性能的代码区域.</p>
<pre><code class="language-py">argmax(dim=None, keepdim=False)
</code></pre>
<p>见 <a href="torch.html#torch.argmax" title="torch.argmax"><code>torch.argmax()</code></a></p>
<pre><code class="language-py">argmin(dim=None, keepdim=False)
</code></pre>
<p>见 <a href="torch.html#torch.argmin" title="torch.argmin"><code>torch.argmin()</code></a></p>
<pre><code class="language-py">asin() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.asin" title="torch.asin"><code>torch.asin()</code></a></p>
<pre><code class="language-py">asin_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.asin" title="torch.Tensor.asin"><code>asin()</code></a></p>
<pre><code class="language-py">atan() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.atan" title="torch.atan"><code>torch.atan()</code></a></p>
<pre><code class="language-py">atan2(other) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.atan2" title="torch.atan2"><code>torch.atan2()</code></a></p>
<pre><code class="language-py">atan2_(other) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.atan2" title="torch.Tensor.atan2"><code>atan2()</code></a></p>
<pre><code class="language-py">atan_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.atan" title="torch.Tensor.atan"><code>atan()</code></a></p>
<pre><code class="language-py">baddbmm(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.baddbmm" title="torch.baddbmm"><code>torch.baddbmm()</code></a></p>
<pre><code class="language-py">baddbmm_(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code>baddbmm()</code></a></p>
<pre><code class="language-py">bernoulli(*, generator=None) → Tensor
</code></pre>
<p>返回一个Tensor, 每一个 <img alt="" src="../img/dc666b1cb085659ba80fe7af990d3fa4.jpg" /> 都是独立采样于 <img alt="" src="../img/0fafd43e45fa221cf2d8f0b6f69e5685.jpg" />. <code>self</code> 必须是浮点型 <code>dtype</code>, 并且返回值有相同的 <code>dtype</code>.</p>
<p>见 <a href="torch.html#torch.bernoulli" title="torch.bernoulli"><code>torch.bernoulli()</code></a></p>
<pre><code class="language-py">bernoulli_()
</code></pre>
<pre><code class="language-py">bernoulli_(p=0.5, *, generator=None) → Tensor
</code></pre>
<p>从 <img alt="" src="../img/25fd7267b85a9ee01d9c4b60beb89dc0.jpg" /> 独立采样填充 <code>self</code> 的每一个位置.<code>self</code> 可以是整型 <code>dtype</code>.</p>
<pre><code class="language-py">bernoulli_(p_tensor, *, generator=None) → Tensor
</code></pre>
<p><code>p_tensor</code> 必须是一个包含概率的 Tensor 用于取得二元随机数.</p>
<p><code>self</code> tensor 的 <img alt="" src="../img/511f5a204e4e69e0f1c374e9a5738214.jpg" /> 元素将会被设置为采样于 <img alt="" src="../img/403a44ffd5b7d1285b96a8270b00e335.jpg" /> 的值.</p>
<p><code>self</code> 可以有整型 <code>dtype</code>, 但是 :attr<code>p_tensor</code> 必须有浮点型 <code>dtype</code>.</p>
<p>可参考 <a href="#torch.Tensor.bernoulli" title="torch.Tensor.bernoulli"><code>bernoulli()</code></a> and <a href="torch.html#torch.bernoulli" title="torch.bernoulli"><code>torch.bernoulli()</code></a></p>
<pre><code class="language-py">bmm(batch2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.bmm" title="torch.bmm"><code>torch.bmm()</code></a></p>
<pre><code class="language-py">byte() → Tensor
</code></pre>
<p><code>self.byte()</code> is equivalent to <code>self.to(torch.uint8)</code>. See <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<pre><code class="language-py">btrifact(info=None, pivot=True)
</code></pre>
<p>见 <a href="torch.html#torch.btrifact" title="torch.btrifact"><code>torch.btrifact()</code></a></p>
<pre><code class="language-py">btrifact_with_info(pivot=True) -&gt; (Tensor, Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.btrifact_with_info" title="torch.btrifact_with_info"><code>torch.btrifact_with_info()</code></a></p>
<pre><code class="language-py">btrisolve(LU_data, LU_pivots) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.btrisolve" title="torch.btrisolve"><code>torch.btrisolve()</code></a></p>
<pre><code class="language-py">cauchy_(median=0, sigma=1, *, generator=None) → Tensor
</code></pre>
<p>用取自 Cauchy 分布得值填充Tensor:</p>
<p><img alt="" src="../img/3d4f188d97734e88873d6fe218ea4aa3.jpg" /></p>
<pre><code class="language-py">ceil() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.ceil" title="torch.ceil"><code>torch.ceil()</code></a></p>
<pre><code class="language-py">ceil_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.ceil" title="torch.Tensor.ceil"><code>ceil()</code></a></p>
<pre><code class="language-py">char() → Tensor
</code></pre>
<p><code>self.char()</code> 等价于 <code>self.to(torch.int8)</code>. 见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<pre><code class="language-py">cholesky(upper=False) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.cholesky" title="torch.cholesky"><code>torch.cholesky()</code></a></p>
<pre><code class="language-py">chunk(chunks, dim=0) → List of Tensors
</code></pre>
<p>见 <a href="torch.html#torch.chunk" title="torch.chunk"><code>torch.chunk()</code></a></p>
<pre><code class="language-py">clamp(min, max) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.clamp" title="torch.clamp"><code>torch.clamp()</code></a></p>
<pre><code class="language-py">clamp_(min, max) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>clamp()</code></a></p>
<pre><code class="language-py">clone() → Tensor
</code></pre>
<p>返回一份拷贝的 <code>self</code> tensor. 这份拷贝有 <code>self</code> 相同的数据和类型.</p>
<p>注意</p>
<p>与<code>copy_()</code>不同, 此函数会被记录在计算图中. 传给克隆tensor的梯度将传播到原始tensor.</p>
<pre><code class="language-py">contiguous() → Tensor
</code></pre>
<p>返回一个连续的得Tensor, 其data与 <code>self</code> 相同. 如果 <code>self</code> tensor 是连续的, 此函数返回 <code>self</code> tensor 自身.</p>
<pre><code class="language-py">copy_(src, non_blocking=False) → Tensor
</code></pre>
<p>从 <code>src</code> 拷贝元素到 <code>self</code> tensor 然后返回 <code>self</code>.</p>
<p><code>src</code> tensor 必须与 <code>self</code> tensor 是 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>. 但数据类型可以不同, 所在的设备也可以不同.</p>
<p>参数: </p>
<ul>
<li><strong>src</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 源 tensor</li>
<li><strong>non_blocking</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 如果是 <code>True</code> 并且这次复制在 CPU 和 GPU 之间进行, 这次复制将会是异步的. 其他情况则没有影响.</li>
</ul>
<pre><code class="language-py">cos() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.cos" title="torch.cos"><code>torch.cos()</code></a></p>
<pre><code class="language-py">cos_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.cos" title="torch.Tensor.cos"><code>cos()</code></a></p>
<pre><code class="language-py">cosh() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.cosh" title="torch.cosh"><code>torch.cosh()</code></a></p>
<pre><code class="language-py">cosh_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.cosh" title="torch.Tensor.cosh"><code>cosh()</code></a></p>
<pre><code class="language-py">cpu() → Tensor
</code></pre>
<p>返回一个拷贝对象于 CPU 内存中.</p>
<p>如果这个对象已经在 CPU 内存中, 并且在者正确的设备上, 那么将会返回其本身.</p>
<pre><code class="language-py">cross(other, dim=-1) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.cross" title="torch.cross"><code>torch.cross()</code></a></p>
<pre><code class="language-py">cuda(device=None, non_blocking=False) → Tensor
</code></pre>
<p>返回一个拷贝对象于 CUDA 内存中.</p>
<p>如果这个对象已经在 CUDA 内存中, 并且在者正确的设备上, 那么将会返回其本身.</p>
<p>参数: </p>
<ul>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>) –目标GPU设备. 默认值是当前GPU.</li>
<li><strong>non_blocking</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 如果是 <code>True</code> 并且源在pinned memory中, 这次拷贝将是异步的.否则此参数没有影响. 默认值: <code>False</code>.</li>
</ul>
<pre><code class="language-py">cumprod(dim, dtype=None) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.cumprod" title="torch.cumprod"><code>torch.cumprod()</code></a></p>
<pre><code class="language-py">cumsum(dim, dtype=None) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.cumsum" title="torch.cumsum"><code>torch.cumsum()</code></a></p>
<pre><code class="language-py">data_ptr() → int
</code></pre>
<p>返回 <code>self</code> tensor 的第一个元素的指针.</p>
<pre><code class="language-py">det() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.det" title="torch.det"><code>torch.det()</code></a></p>
<pre><code class="language-py">diag(diagonal=0) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.diag" title="torch.diag"><code>torch.diag()</code></a></p>
<pre><code class="language-py">diag_embed(offset=0, dim1=-2, dim2=-1) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.diag_embed" title="torch.diag_embed"><code>torch.diag_embed()</code></a></p>
<pre><code class="language-py">dim() → int
</code></pre>
<p>返回 <code>self</code> tensor 的维度.</p>
<pre><code class="language-py">dist(other, p=2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.dist" title="torch.dist"><code>torch.dist()</code></a></p>
<pre><code class="language-py">div(value) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.div" title="torch.div"><code>torch.div()</code></a></p>
<pre><code class="language-py">div_(value) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.div" title="torch.Tensor.div"><code>div()</code></a></p>
<pre><code class="language-py">dot(tensor2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.dot" title="torch.dot"><code>torch.dot()</code></a></p>
<pre><code class="language-py">double() → Tensor
</code></pre>
<p><code>self.double()</code> 等价于 <code>self.to(torch.float64)</code>. 见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<pre><code class="language-py">eig(eigenvectors=False) -&gt; (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.eig" title="torch.eig"><code>torch.eig()</code></a></p>
<pre><code class="language-py">element_size() → int
</code></pre>
<p>返回每个元素占用的字节数</p>
<p>Example:</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.tensor([]).element_size()
4
&gt;&gt;&gt; torch.tensor([], dtype=torch.uint8).element_size()
1

</code></pre>
<pre><code class="language-py">eq(other) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.eq" title="torch.eq"><code>torch.eq()</code></a></p>
<pre><code class="language-py">eq_(other) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.eq" title="torch.Tensor.eq"><code>eq()</code></a></p>
<pre><code class="language-py">equal(other) → bool
</code></pre>
<p>见 <a href="torch.html#torch.equal" title="torch.equal"><code>torch.equal()</code></a></p>
<pre><code class="language-py">erf() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.erf" title="torch.erf"><code>torch.erf()</code></a></p>
<pre><code class="language-py">erf_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.erf" title="torch.Tensor.erf"><code>erf()</code></a></p>
<pre><code class="language-py">erfc() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.erfc" title="torch.erfc"><code>torch.erfc()</code></a></p>
<pre><code class="language-py">erfc_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.erfc" title="torch.Tensor.erfc"><code>erfc()</code></a></p>
<pre><code class="language-py">erfinv() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.erfinv" title="torch.erfinv"><code>torch.erfinv()</code></a></p>
<pre><code class="language-py">erfinv_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code>erfinv()</code></a></p>
<pre><code class="language-py">exp() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.exp" title="torch.exp"><code>torch.exp()</code></a></p>
<pre><code class="language-py">exp_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.exp" title="torch.Tensor.exp"><code>exp()</code></a></p>
<pre><code class="language-py">expm1() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.expm1" title="torch.expm1"><code>torch.expm1()</code></a></p>
<pre><code class="language-py">expm1_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.expm1" title="torch.Tensor.expm1"><code>expm1()</code></a></p>
<pre><code class="language-py">expand(*sizes) → Tensor
</code></pre>
<p>返回一个新的 <code>self</code> tensor 的视图, 其中单一维度扩展到更大的尺寸.</p>
<p>传递<code>-1</code>意味着不改变该维度的大小.</p>
<p>tensor 也可以扩展到更大的维度, 新的维度将会附加在前面.对于新维度, 其大小不能设置为- 1.</p>
<p>扩展张量不会分配新的内存, 但只会在现有张量上创建一个新的视图, 其中通过将<code>stride</code>设置为0, 第一个尺寸的维度会扩展到更大的尺寸.大小为1的任何维度都可以扩展到任意值, 而无需分配新内存.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>*sizes</strong> (<em>torch.Size</em> <em>or</em> <em>int...</em>) – 期望扩展的尺寸</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([[1], [2], [3]])
&gt;&gt;&gt; x.size()
torch.Size([3, 1])
&gt;&gt;&gt; x.expand(3, 4)
tensor([[ 1,  1,  1,  1],
 [ 2,  2,  2,  2],
 [ 3,  3,  3,  3]])
&gt;&gt;&gt; x.expand(-1, 4)   # -1 意味着不会改变该维度
tensor([[ 1,  1,  1,  1],
 [ 2,  2,  2,  2],
 [ 3,  3,  3,  3]])

</code></pre>
<pre><code class="language-py">expand_as(other) → Tensor
</code></pre>
<p>扩展这个 tensor 使得其尺寸和 <code>other</code> 相同. <code>self.expand_as(other)</code> 等价于 <code>self.expand(other.size())</code>.</p>
<p>请看 <a href="#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand()</code></a> 获得更多关于 <code>expand</code> 的信息.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>) – 返回的 tensor 的尺寸和 <code>other</code>. 相同</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<pre><code class="language-py">exponential_(lambd=1, *, generator=None) → Tensor
</code></pre>
<p>用取自 <code>exponential 分布</code> 的元素填充 <code>self</code> tensor :</p>
<p><img alt="" src="../img/3ba5517bd8983486f896da97d259de60.jpg" /></p>
<pre><code class="language-py">fill_(value) → Tensor
</code></pre>
<p>用指定的值填充 <code>self</code>.</p>
<pre><code class="language-py">flatten(input, start_dim=0, end_dim=-1) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.flatten" title="torch.flatten"><code>torch.flatten()</code></a></p>
<pre><code class="language-py">flip(dims) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.flip" title="torch.flip"><code>torch.flip()</code></a></p>
<pre><code class="language-py">float() → Tensor
</code></pre>
<p><code>self.float()</code> 等价于 <code>self.to(torch.float32)</code>. See <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<pre><code class="language-py">floor() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.floor" title="torch.floor"><code>torch.floor()</code></a></p>
<pre><code class="language-py">floor_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.floor" title="torch.Tensor.floor"><code>floor()</code></a></p>
<pre><code class="language-py">fmod(divisor) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.fmod" title="torch.fmod"><code>torch.fmod()</code></a></p>
<pre><code class="language-py">fmod_(divisor) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.fmod" title="torch.Tensor.fmod"><code>fmod()</code></a></p>
<pre><code class="language-py">frac() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.frac" title="torch.frac"><code>torch.frac()</code></a></p>
<pre><code class="language-py">frac_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.frac" title="torch.Tensor.frac"><code>frac()</code></a></p>
<pre><code class="language-py">gather(dim, index) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.gather" title="torch.gather"><code>torch.gather()</code></a></p>
<pre><code class="language-py">ge(other) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.ge" title="torch.ge"><code>torch.ge()</code></a></p>
<pre><code class="language-py">ge_(other) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.ge" title="torch.Tensor.ge"><code>ge()</code></a></p>
<pre><code class="language-py">gels(A) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.gels" title="torch.gels"><code>torch.gels()</code></a></p>
<pre><code class="language-py">geometric_(p, *, generator=None) → Tensor
</code></pre>
<p>用取自<code>geometric 分布</code>的值填充 <code>self</code> :</p>
<p><img alt="" src="../img/d8f96bc88098f6c83428092c8773bb7a.jpg" /></p>
<pre><code class="language-py">geqrf() -&gt; (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.geqrf" title="torch.geqrf"><code>torch.geqrf()</code></a></p>
<pre><code class="language-py">ger(vec2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.ger" title="torch.ger"><code>torch.ger()</code></a></p>
<pre><code class="language-py">gesv(A) → Tensor, Tensor
</code></pre>
<p>见 <a href="torch.html#torch.gesv" title="torch.gesv"><code>torch.gesv()</code></a></p>
<pre><code class="language-py">get_device() -&gt; Device ordinal (Integer)
</code></pre>
<p>对于 CUDA tensors, 这个函数返回一个 GPU 序号, 对应 tensor 所在的设备. 对于 CPU tensors, 抛出一个错误.</p>
<p>Example:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(3, 4, 5, device='cuda:0')
&gt;&gt;&gt; x.get_device()
0
&gt;&gt;&gt; x.cpu().get_device()  # 运行时错误: get_device 没有在 torch.FloatTensor 上实现

</code></pre>
<pre><code class="language-py">gt(other) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.gt" title="torch.gt"><code>torch.gt()</code></a></p>
<pre><code class="language-py">gt_(other) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.gt" title="torch.Tensor.gt"><code>gt()</code></a></p>
<pre><code class="language-py">half() → Tensor
</code></pre>
<p><code>self.half()</code> 等价于 <code>self.to(torch.float16)</code>. 见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<pre><code class="language-py">histc(bins=100, min=0, max=0) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.histc" title="torch.histc"><code>torch.histc()</code></a></p>
<pre><code class="language-py">index_add_(dim, index, tensor) → Tensor
</code></pre>
<p>根据参数<code>index</code> 中的索引的顺序, 累加 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素到 <code>self</code> tensor, 例如, 如果 <code>dim == 0</code> 并且 <code>index[i] == j</code>, 则第 <code>i</code> 行 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 会被加到第 <code>j</code>行.</p>
<p><a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>tensor</code></a> 第 <a href="torch.html#torch.tensor" title="torch.tensor"><code>dim</code></a> 维度 必须和 <code>index</code>(必须是一个向量) 的长度相同, 并且其它维度必须和 <code>self</code> 匹配, 否则将会抛出一个错误.</p>
<p>注意</p>
<p>当使用 CUDA 作为后端, 这个操作可能导致不确定性行为, 且不容易关闭. 请看 <a href="notes/randomness.html">Reproducibility</a>.</p>
<p>Parameters: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要索引的维度</li>
<li><strong>index</strong> (<em>LongTensor</em>) – 从 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中选择的索引</li>
<li><strong>tensor</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 用于相加的tensor</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.ones(5, 3)
&gt;&gt;&gt; t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
&gt;&gt;&gt; index = torch.tensor([0, 4, 2])
&gt;&gt;&gt; x.index_add_(0, index, t)
tensor([[  2.,   3.,   4.],
 [  1.,   1.,   1.],
 [  8.,   9.,  10.],
 [  1.,   1.,   1.],
 [  5.,   6.,   7.]])

</code></pre>
<pre><code class="language-py">index_copy_(dim, index, tensor) → Tensor
</code></pre>
<p>根据参数<code>index</code> 中的选择的索引, 复制 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素到 <code>self</code> tensor, 例如, 如果 <code>dim == 0</code> 并且 <code>index[i] == j</code>, 则第 <code>i</code> 行 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 会被加到第 <code>j</code>行.</p>
<p><a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>tensor</code></a> 第 <a href="torch.html#torch.tensor" title="torch.tensor"><code>dim</code></a> 维度 必须和 <code>index</code>(必须是一个向量) 的长度相同, 并且其它维度必须和 <code>self</code> 匹配, 否则将会抛出一个错误.</p>
<p>Parameters: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要索引的维度</li>
<li><strong>index</strong> (<em>LongTensor</em>) – 从 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中选择的索引</li>
<li><strong>tensor</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 用于复制的tensor</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.zeros(5, 3)
&gt;&gt;&gt; t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
&gt;&gt;&gt; index = torch.tensor([0, 4, 2])
&gt;&gt;&gt; x.index_copy_(0, index, t)
tensor([[ 1.,  2.,  3.],
 [ 0.,  0.,  0.],
 [ 7.,  8.,  9.],
 [ 0.,  0.,  0.],
 [ 4.,  5.,  6.]])

</code></pre>
<pre><code class="language-py">index_fill_(dim, index, val) → Tensor
</code></pre>
<p>根据 <code>index</code> 中指定的顺序索引, 用值 <code>val</code>填充 <code>self</code> tensor 中的元素.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 指定索引对应的维度</li>
<li><strong>index</strong> (<em>LongTensor</em>) –  <code>self</code> tensor 中将被填充的索引值</li>
<li><strong>val</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – 用于填充的值</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
&gt;&gt;&gt; index = torch.tensor([0, 2])
&gt;&gt;&gt; x.index_fill_(1, index, -1)
tensor([[-1.,  2., -1.],
 [-1.,  5., -1.],
 [-1.,  8., -1.]])

</code></pre>
<pre><code class="language-py">index_put_(indices, value, accumulate=False) → Tensor
</code></pre>
<p>根据 <code>indices</code> (是一个 Tensors 的tuple)中指定的索引, 取出 tensor <code>value</code> 中的值放入 tensor <code>self</code> . 表达式 <code>tensor.index_put_(indices, value)</code> 等价于 <code>tensor[indices] = value</code>. 返回 <code>self</code>.</p>
<p>如果 <code>accumulate</code> 等于 <code>True</code>,  <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素会被加到 <code>self</code>. 如果是 <code>False</code>, 且 <code>indices</code> 中含有重复的元素, 则行为是未定义的.</p>
<p>参数: </p>
<ul>
<li><strong>indices</strong> (<em>tuple of LongTensor</em>) – tensors 用于索引 <code>self</code>.</li>
<li><strong>value</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 与 <code>self</code> 有相同数据类型的 tensor.</li>
<li><strong>accumulate</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 是否累加到自身</li>
</ul>
<pre><code class="language-py">index_select(dim, index) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.index_select" title="torch.index_select"><code>torch.index_select()</code></a></p>
<pre><code class="language-py">int() → Tensor
</code></pre>
<p><code>self.int()</code> is equivalent to <code>self.to(torch.int32)</code>. See <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<pre><code class="language-py">inverse() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.inverse" title="torch.inverse"><code>torch.inverse()</code></a></p>
<pre><code class="language-py">is_contiguous() → bool
</code></pre>
<p>返回 True 如果 <code>self</code> tensor 在内存中是连续存储的.</p>
<pre><code class="language-py">is_pinned()
</code></pre>
<p>返回 true 如果 tensor 储存在pinned memory</p>
<pre><code class="language-py">is_set_to(tensor) → bool
</code></pre>
<p>返回 True 如果此对象在 Torch C API 中引用的 <code>THTensor</code> 对象和给定 tensor 是相同的.</p>
<pre><code class="language-py">is_signed()
</code></pre>
<pre><code class="language-py">item() → number
</code></pre>
<p>返回 tensor 中的值作为一个标准的 Python number. 仅在只有一个元素的时候有效. 对于其他情况, 见 <a href="#torch.Tensor.tolist" title="torch.Tensor.tolist"><code>tolist()</code></a>.</p>
<p>这个操作是不可微分的.</p>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([1.0])
&gt;&gt;&gt; x.item()
1.0

</code></pre>
<pre><code class="language-py">kthvalue(k, dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre>
<p>见 <a href="torch.html#torch.kthvalue" title="torch.kthvalue"><code>torch.kthvalue()</code></a></p>
<pre><code class="language-py">le(other) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.le" title="torch.le"><code>torch.le()</code></a></p>
<pre><code class="language-py">le_(other) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.le" title="torch.Tensor.le"><code>le()</code></a></p>
<pre><code class="language-py">lerp(start, end, weight) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.lerp" title="torch.lerp"><code>torch.lerp()</code></a></p>
<pre><code class="language-py">lerp_(start, end, weight) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.lerp" title="torch.Tensor.lerp"><code>lerp()</code></a></p>
<pre><code class="language-py">log() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.log" title="torch.log"><code>torch.log()</code></a></p>
<pre><code class="language-py">log_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.log" title="torch.Tensor.log"><code>log()</code></a></p>
<pre><code class="language-py">logdet() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.logdet" title="torch.logdet"><code>torch.logdet()</code></a></p>
<pre><code class="language-py">log10() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.log10" title="torch.log10"><code>torch.log10()</code></a></p>
<pre><code class="language-py">log10_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.log10" title="torch.Tensor.log10"><code>log10()</code></a></p>
<pre><code class="language-py">log1p() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.log1p" title="torch.log1p"><code>torch.log1p()</code></a></p>
<pre><code class="language-py">log1p_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.log1p" title="torch.Tensor.log1p"><code>log1p()</code></a></p>
<pre><code class="language-py">log2() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.log2" title="torch.log2"><code>torch.log2()</code></a></p>
<pre><code class="language-py">log2_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.log2" title="torch.Tensor.log2"><code>log2()</code></a></p>
<pre><code class="language-py">log_normal_(mean=1, std=2, *, generator=None)
</code></pre>
<p>用 <code>mean</code> <img alt="" src="../img/4e4d506c887c843f43a8fbcbe1884ffd.jpg" />和<code>std</code> <img alt="" src="../img/2469b2bd2a1ab19ebfcee223dcb52bb1.jpg" />初始化的 <code>log-normal 分布</code> 中取出的值填充 <code>self</code>. 注意 <a href="torch.html#torch.mean" title="torch.mean"><code>mean</code></a> 和 <a href="torch.html#torch.std" title="torch.std"><code>std</code></a> 是下面的 normal 分布的平均值和标准差, 而不是返回的分布:</p>
<p><img alt="" src="../img/8672e701dc33c217b7d832207b171eed.jpg" /></p>
<pre><code class="language-py">logsumexp(dim, keepdim=False) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.logsumexp" title="torch.logsumexp"><code>torch.logsumexp()</code></a></p>
<pre><code class="language-py">long() → Tensor
</code></pre>
<p><code>self.long()</code> is equivalent to <code>self.to(torch.int64)</code>. See <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<pre><code class="language-py">lt(other) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.lt" title="torch.lt"><code>torch.lt()</code></a></p>
<pre><code class="language-py">lt_(other) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.lt" title="torch.Tensor.lt"><code>lt()</code></a></p>
<pre><code class="language-py">map_(tensor, callable)
</code></pre>
<p>对 <code>self</code> tensor 和 给定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的每一个元素应用 <code>callable</code> 然后把结果存于 <code>self</code> tensor. <code>self</code> tensor 和给定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 必须可广播 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p><code>callable</code> 应该有下面的函数签名:</p>
<pre><code class="language-py">def callable(a, b) -&gt; number

</code></pre>
<pre><code class="language-py">masked_scatter_(mask, source)
</code></pre>
<p>从 <code>source</code> 复制元素到 <code>self</code> tensor 当对应 <code>mask</code> 对应的值是 1.  <code>mask</code> 的形状必须和底层 tensor 可广播 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.  <code>source</code> 的元素数量至少和 <code>mask</code>里面的1一样多</p>
<p>Parameters: </p>
<ul>
<li><strong>mask</strong> (<a href="#torch.ByteTensor" title="torch.ByteTensor"><em>ByteTensor</em></a>) – 二值掩码</li>
<li><strong>source</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 源 tensor</li>
</ul>
<p>注意</p>
<p><code>mask</code> 操作于 <code>self</code> tensor, 而不是给定的 <code>source</code> tensor.</p>
<pre><code class="language-py">masked_fill_(mask, value)
</code></pre>
<p>用<code>value</code>填充 <code>self</code> tensor 中的元素, 当对应位置的 <code>mask</code> 是1. <code>mask</code> 的形状必须和底层 tensor <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>参数: </p>
<ul>
<li><strong>mask</strong> (<a href="#torch.ByteTensor" title="torch.ByteTensor"><em>ByteTensor</em></a>) – 二值掩码</li>
<li><strong>value</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – 用于填充的值</li>
</ul>
<pre><code class="language-py">masked_select(mask) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.masked_select" title="torch.masked_select"><code>torch.masked_select()</code></a></p>
<pre><code class="language-py">matmul(tensor2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.matmul" title="torch.matmul"><code>torch.matmul()</code></a></p>
<pre><code class="language-py">matrix_power(n) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.matrix_power" title="torch.matrix_power"><code>torch.matrix_power()</code></a></p>
<pre><code class="language-py">max(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.max" title="torch.max"><code>torch.max()</code></a></p>
<pre><code class="language-py">mean(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.mean" title="torch.mean"><code>torch.mean()</code></a></p>
<pre><code class="language-py">median(dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre>
<p>见 <a href="torch.html#torch.median" title="torch.median"><code>torch.median()</code></a></p>
<pre><code class="language-py">min(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.min" title="torch.min"><code>torch.min()</code></a></p>
<pre><code class="language-py">mm(mat2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.mm" title="torch.mm"><code>torch.mm()</code></a></p>
<pre><code class="language-py">mode(dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre>
<p>见 <a href="torch.html#torch.mode" title="torch.mode"><code>torch.mode()</code></a></p>
<pre><code class="language-py">mul(value) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.mul" title="torch.mul"><code>torch.mul()</code></a></p>
<pre><code class="language-py">mul_(value)
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.mul" title="torch.Tensor.mul"><code>mul()</code></a></p>
<pre><code class="language-py">multinomial(num_samples, replacement=False, *, generator=None) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.multinomial" title="torch.multinomial"><code>torch.multinomial()</code></a></p>
<pre><code class="language-py">mv(vec) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.mv" title="torch.mv"><code>torch.mv()</code></a></p>
<pre><code class="language-py">mvlgamma(p) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.mvlgamma" title="torch.mvlgamma"><code>torch.mvlgamma()</code></a></p>
<pre><code class="language-py">mvlgamma_(p) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code>mvlgamma()</code></a></p>
<pre><code class="language-py">narrow(dimension, start, length) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.narrow" title="torch.narrow"><code>torch.narrow()</code></a></p>
<p>Example:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
&gt;&gt;&gt; x.narrow(0, 0, 2)
tensor([[ 1,  2,  3],
 [ 4,  5,  6]])
&gt;&gt;&gt; x.narrow(1, 1, 2)
tensor([[ 2,  3],
 [ 5,  6],
 [ 8,  9]])

</code></pre>
<pre><code class="language-py">ndimension() → int
</code></pre>
<p>Alias for <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a></p>
<pre><code class="language-py">ne(other) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.ne" title="torch.ne"><code>torch.ne()</code></a></p>
<pre><code class="language-py">ne_(other) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.ne" title="torch.Tensor.ne"><code>ne()</code></a></p>
<pre><code class="language-py">neg() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.neg" title="torch.neg"><code>torch.neg()</code></a></p>
<pre><code class="language-py">neg_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.neg" title="torch.Tensor.neg"><code>neg()</code></a></p>
<pre><code class="language-py">nelement() → int
</code></pre>
<p>别名 <a href="#torch.Tensor.numel" title="torch.Tensor.numel"><code>numel()</code></a></p>
<pre><code class="language-py">nonzero() → LongTensor
</code></pre>
<p>见 <a href="torch.html#torch.nonzero" title="torch.nonzero"><code>torch.nonzero()</code></a></p>
<pre><code class="language-py">norm(p='fro', dim=None, keepdim=False)
</code></pre>
<p>见 :func: <code>torch.norm</code></p>
<pre><code class="language-py">normal_(mean=0, std=1, *, generator=None) → Tensor
</code></pre>
<p>用采样于 normal 分布的元素填充 <code>self</code> tensor, normal 分布使用参数 <a href="torch.html#torch.mean" title="torch.mean"><code>mean</code></a> and <a href="torch.html#torch.std" title="torch.std"><code>std</code></a>初始化.</p>
<pre><code class="language-py">numel() → int
</code></pre>
<p>见 <a href="torch.html#torch.numel" title="torch.numel"><code>torch.numel()</code></a></p>
<pre><code class="language-py">numpy() → numpy.ndarray
</code></pre>
<p>返回 <code>self</code> tensor 作为一个 NumPy <code>ndarray</code>. 此 tensor 和返回的 <code>ndarray</code> 共享同一个底层存储. 改变<code>self</code> tensor 将会同时改变 <code>ndarray</code> .</p>
<pre><code class="language-py">orgqr(input2) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.orgqr" title="torch.orgqr"><code>torch.orgqr()</code></a></p>
<pre><code class="language-py">ormqr(input2, input3, left=True, transpose=False) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.ormqr" title="torch.ormqr"><code>torch.ormqr()</code></a></p>
<pre><code class="language-py">permute(*dims) → Tensor
</code></pre>
<p>排列 tensor 的维度.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>*dims</strong> (<em>int...</em>) – 维度的排列顺序</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Example</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(2, 3, 5)
&gt;&gt;&gt; x.size()
torch.Size([2, 3, 5])
&gt;&gt;&gt; x.permute(2, 0, 1).size()
torch.Size([5, 2, 3])

</code></pre>
<pre><code class="language-py">pin_memory()
</code></pre>
<pre><code class="language-py">pinverse() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.pinverse" title="torch.pinverse"><code>torch.pinverse()</code></a></p>
<pre><code class="language-py">potrf(upper=True)
</code></pre>
<p>见 <a href="torch.html#torch.cholesky" title="torch.cholesky"><code>torch.cholesky()</code></a></p>
<pre><code class="language-py">potri(upper=True) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.potri" title="torch.potri"><code>torch.potri()</code></a></p>
<pre><code class="language-py">potrs(input2, upper=True) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.potrs" title="torch.potrs"><code>torch.potrs()</code></a></p>
<pre><code class="language-py">pow(exponent) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.pow" title="torch.pow"><code>torch.pow()</code></a></p>
<pre><code class="language-py">pow_(exponent) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.pow" title="torch.Tensor.pow"><code>pow()</code></a></p>
<pre><code class="language-py">prod(dim=None, keepdim=False, dtype=None) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.prod" title="torch.prod"><code>torch.prod()</code></a></p>
<pre><code class="language-py">pstrf(upper=True, tol=-1) -&gt; (Tensor, IntTensor)
</code></pre>
<p>见 <a href="torch.html#torch.pstrf" title="torch.pstrf"><code>torch.pstrf()</code></a></p>
<pre><code class="language-py">put_(indices, tensor, accumulate=False) → Tensor
</code></pre>
<p>从 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中复制元素到 indices 指定的位置. 对于目的索引,  <code>self</code> tensor 被当作一个 1-D tensor.</p>
<p>如果 <code>accumulate</code> 是 <code>True</code>, <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素被被加到 <code>self</code>. 如果 accumulate 是 <code>False</code>, 当 indices 中有重复索引时行为未定义.</p>
<p>Parameters: </p>
<ul>
<li><strong>indices</strong> (<em>LongTensor</em>) – self 的索引位置</li>
<li><strong>tensor</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 包含待复制元素的 tensor</li>
<li><strong>accumulate</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 是否累加到 self</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; src = torch.tensor([[4, 3, 5],
 [6, 7, 8]])
&gt;&gt;&gt; src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))
tensor([[  4,   9,   5],
 [ 10,   7,   8]])

</code></pre>
<pre><code class="language-py">qr() -&gt; (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.qr" title="torch.qr"><code>torch.qr()</code></a></p>
<pre><code class="language-py">random_(from=0, to=None, *, generator=None) → Tensor
</code></pre>
<p>用离散均匀分布介于  <code>[from, to - 1]</code> 采样的数字填充 <code>self</code> tensor. 如果没有特别指定, 这些采样的数值被 <code>self</code> tensor's 数据类型界定. 然而, 对于浮点型, 如果没有特别指定, 范围将是 <code>[0, 2^mantissa]</code> 来确保每一个值是可表示的. 例如, <code>torch.tensor(1, dtype=torch.double).random_()</code> 将会被设为 <code>[0, 2^53]</code>.</p>
<pre><code class="language-py">reciprocal() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.reciprocal" title="torch.reciprocal"><code>torch.reciprocal()</code></a></p>
<pre><code class="language-py">reciprocal_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code>reciprocal()</code></a></p>
<pre><code class="language-py">remainder(divisor) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.remainder" title="torch.remainder"><code>torch.remainder()</code></a></p>
<pre><code class="language-py">remainder_(divisor) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.remainder" title="torch.Tensor.remainder"><code>remainder()</code></a></p>
<pre><code class="language-py">renorm(p, dim, maxnorm) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.renorm" title="torch.renorm"><code>torch.renorm()</code></a></p>
<pre><code class="language-py">renorm_(p, dim, maxnorm) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.renorm" title="torch.Tensor.renorm"><code>renorm()</code></a></p>
<pre><code class="language-py">repeat(*sizes) → Tensor
</code></pre>
<p>在指定的维度重复这个 tensor.</p>
<p>不像 <a href="#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand()</code></a>, 这个函数会拷贝底层数据.</p>
<p>警告</p>
<p><code>torch.repeat()</code> 的行为和 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html">numpy.repeat</a> 不一样, 更类似于 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html">numpy.tile</a>.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>sizes</strong> (<em>torch.Size</em> <em>or</em> <em>int...</em>) – 每个维度重复的次数</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([1, 2, 3])
&gt;&gt;&gt; x.repeat(4, 2)
tensor([[ 1,  2,  3,  1,  2,  3],
 [ 1,  2,  3,  1,  2,  3],
 [ 1,  2,  3,  1,  2,  3],
 [ 1,  2,  3,  1,  2,  3]])
&gt;&gt;&gt; x.repeat(4, 2, 1).size()
torch.Size([4, 2, 3])

</code></pre>
<pre><code class="language-py">requires_grad_(requires_grad=True) → Tensor
</code></pre>
<p>设置是否应该自动求导: 原地设置这个 tensor 的 <a href="autograd.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> 属性.返回这个 tensor.</p>
<p><code>require_grad_()</code> 的主要使用情况是告诉自动求导开始记录Tensor <code>tensor</code>上的操作. 如果 <code>tensor</code> 的 <code>requires_grad=False</code> (因为它是通过 DataLoader 获得或者需要预处理或初始化), <code>tensor.requires_grad_()</code> 将会使得自动求导开始生效.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 是否自动求导应该记录相关操作. Default: <code>True</code>.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; # Let's say we want to preprocess some saved weights and use
&gt;&gt;&gt; # the result as new weights.
&gt;&gt;&gt; saved_weights = [0.1, 0.2, 0.3, 0.25]
&gt;&gt;&gt; loaded_weights = torch.tensor(saved_weights)
&gt;&gt;&gt; weights = preprocess(loaded_weights)  # some function
&gt;&gt;&gt; weights
tensor([-0.5503,  0.4926, -2.1158, -0.8303])

&gt;&gt;&gt; # Now, start to record operations done to weights
&gt;&gt;&gt; weights.requires_grad_()
&gt;&gt;&gt; out = weights.pow(2).sum()
&gt;&gt;&gt; out.backward()
&gt;&gt;&gt; weights.grad
tensor([-1.1007,  0.9853, -4.2316, -1.6606])

</code></pre>
<pre><code class="language-py">reshape(*shape) → Tensor
</code></pre>
<p>返回一个 tensor, 其data和元素数量与 <code>self</code> 一样, 但是改变成指定的形状. 这个方法返回一个tensor的试图 如果 <code>shape</code> 和当前的形状是兼容的. 见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>torch.Tensor.view()</code></a> 关于是什么时候返回一个 view.</p>
<p>见 <a href="torch.html#torch.reshape" title="torch.reshape"><code>torch.reshape()</code></a></p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>shape</strong> (<em>tuple of python:ints</em> <em>or</em> <em>int...</em>) – 期望变成的形状</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<pre><code class="language-py">reshape_as(other) → Tensor
</code></pre>
<p>返回一个tensor形状与 <code>other</code> 相同. <code>self.reshape_as(other)</code> 等价于 <code>self.reshape(other.sizes())</code>. 这个方法返回一个tensor的试图 如果 <code>self.reshape(other.sizes())</code> 和当前的形状是兼容的. 见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>torch.Tensor.view()</code></a> 关于是什么时候返回一个 view.</p>
<p>请参考 <a href="torch.html#torch.reshape" title="torch.reshape"><code>reshape()</code></a> 获得更多关于 <code>reshape</code> 的信息.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>) – 返回的tensor形状与 <code>other</code> 一致.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<pre><code class="language-py">resize_(*sizes) → Tensor
</code></pre>
<p>缩放 <code>self</code> tensor到指定的大小. 如果指定的元素数量比当前的要大, 底层的存储结构会缩放到合适的大小. 如果数量更小, 底层存储不变. 当前的元素都会被保留, 没有任何的新的初始化.</p>
<p>警告</p>
<p>这是一个底层的操作. 存储被重新解释为C-contiguous, 忽略当前stride(除非目标大小等于当前大小, 在这种情况下tensor保持不变）.在大多数情况下, 您将要使用 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>view()</code></a>, 它会检查连续性, 或者 <a href="#torch.Tensor.reshape" title="torch.Tensor.reshape"><code>reshape()</code></a>, 在必要的时候会拷贝数据. 如果想要改变大小并且自定义stride, 见 <a href="#torch.Tensor.set_" title="torch.Tensor.set_"><code>set_()</code></a>.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>sizes</strong> (<em>torch.Size</em> <em>or</em> <em>int...</em>) – 期望的大小</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([[1, 2], [3, 4], [5, 6]])
&gt;&gt;&gt; x.resize_(2, 2)
tensor([[ 1,  2],
 [ 3,  4]])

</code></pre>
<pre><code class="language-py">resize_as_(tensor) → Tensor
</code></pre>
<p>缩放 <code>self</code> tensor 的大小与参数 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 相同. 等价于 <code>self.resize_(tensor.size())</code>.</p>
<pre><code class="language-py">round() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.round" title="torch.round"><code>torch.round()</code></a></p>
<pre><code class="language-py">round_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.round" title="torch.Tensor.round"><code>round()</code></a></p>
<pre><code class="language-py">rsqrt() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.rsqrt" title="torch.rsqrt"><code>torch.rsqrt()</code></a></p>
<pre><code class="language-py">rsqrt_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code>rsqrt()</code></a></p>
<pre><code class="language-py">scatter_(dim, index, src) → Tensor
</code></pre>
<p>根据 <code>index</code> tensor 中指定的索引, 将所有 tensor <code>src</code> 中的值写入<code>self</code> . 对于  <code>src</code> 中的每一个值, 当 <code>dimension != dim</code>, 它的输出的索引由 <code>src</code> 中的索引指定, 当 <code>dimension = dim</code>,  由 <code>index</code> 中对应的值指定.</p>
<p>对于一个 3-D tensor, <code>self</code> 的更新规则如下:</p>
<pre><code class="language-py">self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0
self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1
self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2

</code></pre>
<p>这是 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a> 中描述的方式的逆向操作.</p>
<p><code>self</code>, <code>index</code> and <code>src</code> (if it is a Tensor) 应该有相同数量的维度. 同时也要求 <code>index.size(d) &lt;= src.size(d)</code> 对于每一个维度 <code>d</code>, 而且 <code>index.size(d) &lt;= self.size(d)</code> 对于每一个维度 <code>d != dim</code>.</p>
<p>此外, 关于 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a>,  <code>index</code> 的值必须介于 <code>0</code> 和 <code>self.size(dim) - 1</code> (包括), 并且沿着指定维度<a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a>的行中的所有值必须是唯一的.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要索引的轴</li>
<li><strong>index</strong> (<em>LongTensor</em>) – 需要 scatter 的元素的索引, 可以是空的，也可以与src大小相同。当为空时，操作返回恒等</li>
<li><strong>src</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a> <em>or</em> <a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – scatter 源</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.rand(2, 5)
&gt;&gt;&gt; x
tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],
 [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])
&gt;&gt;&gt; torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)
tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],
 [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],
 [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])

&gt;&gt;&gt; z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)
&gt;&gt;&gt; z
tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],
 [ 0.0000,  0.0000,  0.0000,  1.2300]])

</code></pre>
<pre><code class="language-py">scatter_add_(dim, index, other) → Tensor
</code></pre>
<p>根据 <code>index</code> tensor 中指定的索引(方式和<a href="#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>scatter_()</code></a>类似), 将所有 tensor <code>other</code> 中的值加到<code>self</code> . 对于  <code>other</code> 中的每一个值, 当 <code>dimension != dim</code>, 它的输出的索引由 <code>other</code> 中的索引指定, 当 <code>dimension = dim</code>,  由 <code>index</code> 中对应的值指定.</p>
<p>对于一个 3-D tensor, <code>self</code> 的更新规则如下:</p>
<pre><code class="language-py">self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0
self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1
self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2

</code></pre>
<p><code>self</code>, <code>index</code> and <code>other</code> 应该有相同数量的维度. 也要求 <code>index.size(d) &lt;= other.size(d)</code> 对于所有的维度 <code>d</code>, 并且 <code>index.size(d) &lt;= self.size(d)</code> 对于所有的维度 <code>d != dim</code>.</p>
<p>此外, 关于 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a>,  <code>index</code> 的值必须介于 <code>0</code> 和 <code>self.size(dim) - 1</code> (包括), 并且沿着指定维度<a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a>的行中的所有值必须是唯一的.</p>
<p>注意</p>
<p>当使用 CUDA 作为后端, 这个操作将导致不确定性行为, 并且难以停止. 请参考 <a href="notes/randomness.html">Reproducibility</a> 获得相关背景.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要索引的轴</li>
<li><strong>index</strong> (<em>LongTensor</em>) – 需要 scatter add 的元素的索引, 可以是空的，也可以与src大小相同。当为空时，操作返回恒等</li>
<li><strong>src</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a> <em>or</em> <a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – scatter 源</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.rand(2, 5)
&gt;&gt;&gt; x
tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],
 [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])
&gt;&gt;&gt; torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)
tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],
 [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],
 [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])

</code></pre>
<pre><code class="language-py">select(dim, index) → Tensor
</code></pre>
<p>沿着选择的维度在给定的索引处切取 <code>self</code> tensor.这个函数返回的 tensor 指定的维度被移除了.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要切片的维度</li>
<li><strong>index</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 选择的索引</li>
</ul>
<p>注意</p>
<p><a href="#torch.Tensor.select" title="torch.Tensor.select"><code>select()</code></a> 等价于切片. 例如, <code>tensor.select(0, index)</code> 等价于 <code>tensor[index]</code> and <code>tensor.select(2, index)</code> 等价于 <code>tensor[:,:,index]</code>.</p>
<pre><code class="language-py">set_(source=None, storage_offset=0, size=None, stride=None) → Tensor
</code></pre>
<p>设置底层存储, 大小, 和 strides. 如果 <code>source</code> 是一个 tensor, <code>self</code> tensor 将会和 <code>source</code> 共享底层存储, 并有用一样的大小和 strides. 在一个 tensor 中改变元素将会反应到另一个tensor.</p>
<p>如果 <code>source</code> 是一个 <code>Storage</code>, 此方法设置底层存储, offset, 大小, 和 stride.</p>
<p>参数: </p>
<ul>
<li><strong>source</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a> <em>or</em> <em>Storage</em>) – 要设置的 tensor 或者 storage</li>
<li><strong>storage_offset</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>optional</em>) – storage 的 offset</li>
<li><strong>size</strong> (<em>torch.Size__,</em> <em>optional</em>) – 期望的大小.默认是 source 的大小.</li>
<li><strong>stride</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>,</em> <em>optional</em>) – 期望的 stride.默认值是 C-contiguous strides.</li>
</ul>
<pre><code class="language-py">share_memory_()
</code></pre>
<p>移动底层存储到共享内存.</p>
<p>这是一个空操作如果底层存储已经在共享内存中或者是 CUDA tensors. 共享内存中的 tensor 不能 resize.</p>
<pre><code class="language-py">short() → Tensor
</code></pre>
<p><code>self.short()</code> 等价于 <code>self.to(torch.int16)</code>. 见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<pre><code class="language-py">sigmoid() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.sigmoid" title="torch.sigmoid"><code>torch.sigmoid()</code></a></p>
<pre><code class="language-py">sigmoid_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code>sigmoid()</code></a></p>
<pre><code class="language-py">sign() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.sign" title="torch.sign"><code>torch.sign()</code></a></p>
<pre><code class="language-py">sign_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.sign" title="torch.Tensor.sign"><code>sign()</code></a></p>
<pre><code class="language-py">sin() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.sin" title="torch.sin"><code>torch.sin()</code></a></p>
<pre><code class="language-py">sin_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.sin" title="torch.Tensor.sin"><code>sin()</code></a></p>
<pre><code class="language-py">sinh() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.sinh" title="torch.sinh"><code>torch.sinh()</code></a></p>
<pre><code class="language-py">sinh_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.sinh" title="torch.Tensor.sinh"><code>sinh()</code></a></p>
<pre><code class="language-py">size() → torch.Size
</code></pre>
<p>返回 <code>self</code> tensor 的尺寸. 返回值是  [<code>tuple</code>] 的子类(https://docs.python.org/3/library/stdtypes.html#tuple "(in Python v3.7)").</p>
<p>例如:</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.empty(3, 4, 5).size()
torch.Size([3, 4, 5])

</code></pre>
<pre><code class="language-py">slogdet() -&gt; (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.slogdet" title="torch.slogdet"><code>torch.slogdet()</code></a></p>
<pre><code class="language-py">sort(dim=None, descending=False) -&gt; (Tensor, LongTensor)
</code></pre>
<p>见 <a href="torch.html#torch.sort" title="torch.sort"><code>torch.sort()</code></a></p>
<pre><code class="language-py">split(split_size, dim=0)
</code></pre>
<p>见 <a href="torch.html#torch.split" title="torch.split"><code>torch.split()</code></a></p>
<pre><code class="language-py">sparse_mask(input, mask) → Tensor
</code></pre>
<p>用  <code>mask</code> 的索引过滤 Tensor <code>input</code>, 返回一个新的 SparseTensor. <code>input</code> 和 <code>mask</code> 必须有相同的形状.</p>
<p>参数: </p>
<ul>
<li><strong>input</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入 Tensor</li>
<li><strong>mask</strong> (<em>SparseTensor</em>) – SparseTensor 用其索引过滤 <code>input</code> </li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; nnz = 5
&gt;&gt;&gt; dims = [5, 5, 2, 2]
&gt;&gt;&gt; I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),
 torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)
&gt;&gt;&gt; V = torch.randn(nnz, dims[2], dims[3])
&gt;&gt;&gt; size = torch.Size(dims)
&gt;&gt;&gt; S = torch.sparse_coo_tensor(I, V, size).coalesce()
&gt;&gt;&gt; D = torch.randn(dims)
&gt;&gt;&gt; D.sparse_mask(S)
tensor(indices=tensor([[0, 0, 0, 2],
 [0, 1, 4, 3]]),
 values=tensor([[[ 1.6550,  0.2397],
 [-0.1611, -0.0779]],

 [[ 0.2326, -1.0558],
 [ 1.4711,  1.9678]],

 [[-0.5138, -0.0411],
 [ 1.9417,  0.5158]],

 [[ 0.0793,  0.0036],
 [-0.2569, -0.1055]]]),
 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)

</code></pre>
<pre><code class="language-py">sqrt() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.sqrt" title="torch.sqrt"><code>torch.sqrt()</code></a></p>
<pre><code class="language-py">sqrt_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code>sqrt()</code></a></p>
<pre><code class="language-py">squeeze(dim=None) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a></p>
<pre><code class="language-py">squeeze_(dim=None) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code>squeeze()</code></a></p>
<pre><code class="language-py">std(dim=None, unbiased=True, keepdim=False) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.std" title="torch.std"><code>torch.std()</code></a></p>
<pre><code class="language-py">storage() → torch.Storage
</code></pre>
<p>返回底层的 storage</p>
<pre><code class="language-py">storage_offset() → int
</code></pre>
<p>根据存储元素的数量(而不是字节)，返回底层存储中的<code>tesor</code>偏移量(offset)。</p>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([1, 2, 3, 4, 5])
&gt;&gt;&gt; x.storage_offset()
0
&gt;&gt;&gt; x[3:].storage_offset()
3

</code></pre>
<pre><code class="language-py">storage_type()
</code></pre>
<pre><code class="language-py">stride(dim) → tuple or int
</code></pre>
<p>返回 <code>self</code> tensor 的 stride.</p>
<p>stride 是必要的用于在指定的维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 找到下一个元素. 如果传入空, 则返回一个 tuple 包含所有维度的 stride. 否则, 将会返回一个 int 表示指定维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 的 stride.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>optional</em>) – 需要返回 stride 的维度</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
&gt;&gt;&gt; x.stride()
(5, 1)
&gt;&gt;&gt;x.stride(0)
5
&gt;&gt;&gt; x.stride(-1)
1

</code></pre>
<pre><code class="language-py">sub(value, other) → Tensor
</code></pre>
<p><code>self</code> tensor 减去一个 scalar 或者 tensor. 如果 <code>value</code> 和 <code>other</code> 都被指定,  在相减之前, <code>other</code> 的每个元素将会用 <code>value</code> 缩放.</p>
<p>当 <code>other</code> 是一个 tensor,  <code>other</code> 的形状必须和底层存储是可广播的 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> .</p>
<pre><code class="language-py">sub_(x) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.sub" title="torch.Tensor.sub"><code>sub()</code></a></p>
<pre><code class="language-py">sum(dim=None, keepdim=False, dtype=None) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.sum" title="torch.sum"><code>torch.sum()</code></a></p>
<pre><code class="language-py">svd(some=True, compute_uv=True) -&gt; (Tensor, Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.svd" title="torch.svd"><code>torch.svd()</code></a></p>
<pre><code class="language-py">symeig(eigenvectors=False, upper=True) -&gt; (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.symeig" title="torch.symeig"><code>torch.symeig()</code></a></p>
<pre><code class="language-py">t() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.t" title="torch.t"><code>torch.t()</code></a></p>
<pre><code class="language-py">t_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.t" title="torch.Tensor.t"><code>t()</code></a></p>
<pre><code class="language-py">to(*args, **kwargs) → Tensor
</code></pre>
<p>执行 tensor 类型或者设备转换. <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 是从参数中推断的 <code>self.to(*args, **kwargs)</code>.</p>
<p>注意</p>
<p>如果 <code>self</code> Tensor 已经有正确的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 则 <code>self</code> 被返回. 否则, 将返回复制的 <code>self</code> 期望的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>下面是调用的方法 <code>to</code>:</p>
<pre><code class="language-py">to(dtype, non_blocking=False, copy=False) → Tensor
</code></pre>
<p>返回一个 Tensor 指定类型 <code>dtype</code></p>
<pre><code class="language-py">to(device=None, dtype=None, non_blocking=False, copy=False) → Tensor
</code></pre>
<p>返回一个 Tensor 并指定 <a href="#torch.Tensor.device" title="torch.Tensor.device"><code>device</code></a> 和 (可选的) <code>dtype</code>. 如果 <code>dtype</code> 是 <code>None</code> 则推断为 <code>self.dtype</code> . 当启用 <code>non_blocking</code>, 试图在主机上执行异步转换, 例如, 转换一个 pinned memory 的 CPU Tensor 到 CUDA Tensor. 当 <code>copy</code> 被设置, 一个新的 tensor 被创建.</p>
<pre><code class="language-py">to(other, non_blocking=False, copy=False) → Tensor
</code></pre>
<p>返回一个 Tensor 并有和 Tensor <code>other</code> 相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>. 当启用 <code>non_blocking</code>, 试图在主机上执行异步转换, 例如, 转换一个 pinned memory 的 CPU Tensor 到 CUDA Tensor. 当 <code>copy</code> 被设置, 一个新的 tensor 被创建.</p>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu
&gt;&gt;&gt; tensor.to(torch.float64)
tensor([[-0.5044,  0.0005],
 [ 0.3310, -0.0584]], dtype=torch.float64)

&gt;&gt;&gt; cuda0 = torch.device('cuda:0')
&gt;&gt;&gt; tensor.to(cuda0)
tensor([[-0.5044,  0.0005],
 [ 0.3310, -0.0584]], device='cuda:0')

&gt;&gt;&gt; tensor.to(cuda0, dtype=torch.float64)
tensor([[-0.5044,  0.0005],
 [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')

&gt;&gt;&gt; other = torch.randn((), dtype=torch.float64, device=cuda0)
&gt;&gt;&gt; tensor.to(other, non_blocking=True)
tensor([[-0.5044,  0.0005],
 [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')

</code></pre>
<pre><code class="language-py">take(indices) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.take" title="torch.take"><code>torch.take()</code></a></p>
<pre><code class="language-py">tan()
</code></pre>
<pre><code class="language-py">tan_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.tan" title="torch.Tensor.tan"><code>tan()</code></a></p>
<pre><code class="language-py">tanh() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.tanh" title="torch.tanh"><code>torch.tanh()</code></a></p>
<pre><code class="language-py">tanh_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.tanh" title="torch.Tensor.tanh"><code>tanh()</code></a></p>
<pre><code class="language-py">tolist()
</code></pre>
<p>” tolist() -&gt; list or number</p>
<p>返回tensor 作为(嵌套的) list. 对于 scalars,一个标准的 Python number 被返回, 就像 <a href="#torch.Tensor.item" title="torch.Tensor.item"><code>item()</code></a> 一样. Tensors 会自动移动到 CPU 上如果有必要.</p>
<p>这个操作是不可微分的.</p>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(2, 2)
&gt;&gt;&gt; a.tolist()
[[0.012766935862600803, 0.5415473580360413],
 [-0.08909505605697632, 0.7729271650314331]]
&gt;&gt;&gt; a[0,0].tolist()
0.012766935862600803

</code></pre>
<pre><code class="language-py">topk(k, dim=None, largest=True, sorted=True) -&gt; (Tensor, LongTensor)
</code></pre>
<p>见 <a href="torch.html#torch.topk" title="torch.topk"><code>torch.topk()</code></a></p>
<pre><code class="language-py">to_sparse(sparseDims) → Tensor
</code></pre>
<p>返回一个稀疏复制的 tensor. PyTorch 支持 <a href="sparse.html#sparse-docs">coordinate 格式</a> 的稀疏 tensors. :param sparseDims: 要包含在新稀疏tensor中的稀疏维数 :type sparseDims: int, 可选的</p>
<pre><code class="language-py">例子::
</code></pre>
<pre><code class="language-py">&gt;&gt;&gt; d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])
&gt;&gt;&gt; d
tensor([[ 0,  0,  0],
 [ 9,  0, 10],
 [ 0,  0,  0]])
&gt;&gt;&gt; d.to_sparse()
tensor(indices=tensor([[1, 1],
 [0, 2]]),
 values=tensor([ 9, 10]),
 size=(3, 3), nnz=2, layout=torch.sparse_coo)
&gt;&gt;&gt; d.to_sparse(1)
tensor(indices=tensor([[1]]),
 values=tensor([[ 9,  0, 10]]),
 size=(3, 3), nnz=1, layout=torch.sparse_coo)

</code></pre>
<pre><code class="language-py">trace() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.trace" title="torch.trace"><code>torch.trace()</code></a></p>
<pre><code class="language-py">transpose(dim0, dim1) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.transpose" title="torch.transpose"><code>torch.transpose()</code></a></p>
<pre><code class="language-py">transpose_(dim0, dim1) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.transpose" title="torch.Tensor.transpose"><code>transpose()</code></a></p>
<pre><code class="language-py">tril(k=0) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.tril" title="torch.tril"><code>torch.tril()</code></a></p>
<pre><code class="language-py">tril_(k=0) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.tril" title="torch.Tensor.tril"><code>tril()</code></a></p>
<pre><code class="language-py">triu(k=0) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.triu" title="torch.triu"><code>torch.triu()</code></a></p>
<pre><code class="language-py">triu_(k=0) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.triu" title="torch.Tensor.triu"><code>triu()</code></a></p>
<pre><code class="language-py">trtrs(A, upper=True, transpose=False, unitriangular=False) -&gt; (Tensor, Tensor)
</code></pre>
<p>见 <a href="torch.html#torch.trtrs" title="torch.trtrs"><code>torch.trtrs()</code></a></p>
<pre><code class="language-py">trunc() → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.trunc" title="torch.trunc"><code>torch.trunc()</code></a></p>
<pre><code class="language-py">trunc_() → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.trunc" title="torch.Tensor.trunc"><code>trunc()</code></a></p>
<pre><code class="language-py">type(dtype=None, non_blocking=False, **kwargs) → str or Tensor
</code></pre>
<p>返回 type 如果 <code>dtype</code> 没有被设置, 否则将会强制转换成 <code>dtype</code> 类型.</p>
<p>如果这已经是正确的类型，则不执行复制，并返回原始对象.</p>
<p>参数: </p>
<ul>
<li><strong>dtype</strong> (<a href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.7)"><em>type</em></a> <em>or</em> <em>string</em>) – 期望类型</li>
<li><strong>non_blocking</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) –  如果 <code>True</code>，并且源在pinned memory中，目的地在GPU上，则拷贝相对于主机异步执行。否则，这个参数没有任何作用。</li>
<li><strong>**kwargs</strong> – 为了兼容性, 可能包含 <code>async</code> 用来置换 <code>non_blocking</code> 参数.  <code>async</code> 参数被废弃了.</li>
</ul>
<pre><code class="language-py">type_as(tensor) → Tensor
</code></pre>
<p>返回 tensor 强制转换为 tensor 的数据类型.</p>
<p>如果这已经是正确的类型，则是空操作. 等价于:</p>
<pre><code class="language-py">self.type(tensor.type())

</code></pre>
<pre><code class="language-py">Params:
</code></pre>
<p>tensor (Tensor): 拥有目标数据类型的 tensor</p>
<pre><code class="language-py">unfold(dim, size, step) → Tensor
</code></pre>
<p>返回一个 tensor 包含 <code>self</code> tensor 在维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 上的所有切片, 每一个的大小为 size.</p>
<p><code>step</code> 指定每一个切片的间距.</p>
<p>如果 <code>sizedim</code> 是 <code>self</code> dim 维度的大小, 返回的 tensor 的维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 大小是 <code>(sizedim - size) / step + 1</code>.</p>
<p>一个附加的size size的维度追加于返回的 tensor.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 指定 unfold 的维度</li>
<li><strong>size</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 指定每个slice的大小</li>
<li><strong>step</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 指定步长</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.arange(1., 8)
&gt;&gt;&gt; x
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])
&gt;&gt;&gt; x.unfold(0, 2, 1)
tensor([[ 1.,  2.],
 [ 2.,  3.],
 [ 3.,  4.],
 [ 4.,  5.],
 [ 5.,  6.],
 [ 6.,  7.]])
&gt;&gt;&gt; x.unfold(0, 2, 2)
tensor([[ 1.,  2.],
 [ 3.,  4.],
 [ 5.,  6.]])

</code></pre>
<pre><code class="language-py">uniform_(from=0, to=1) → Tensor
</code></pre>
<p>用连续均匀分布的采样值填充 <code>self</code> tensor:</p>
<p><img alt="" src="../img/759db301c6ca0348b6d47aaeac0a6b23.jpg" /></p>
<pre><code class="language-py">unique(sorted=False, return_inverse=False, dim=None)
</code></pre>
<p>返回 tensor 中唯一的标量作为 1-D tensor.</p>
<p>见 <a href="torch.html#torch.unique" title="torch.unique"><code>torch.unique()</code></a></p>
<pre><code class="language-py">unsqueeze(dim) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.unsqueeze" title="torch.unsqueeze"><code>torch.unsqueeze()</code></a></p>
<pre><code class="language-py">unsqueeze_(dim) → Tensor
</code></pre>
<p>原地版本的 <a href="#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code>unsqueeze()</code></a></p>
<pre><code class="language-py">var(dim=None, unbiased=True, keepdim=False) → Tensor
</code></pre>
<p>见 <a href="torch.html#torch.var" title="torch.var"><code>torch.var()</code></a></p>
<pre><code class="language-py">view(*shape) → Tensor
</code></pre>
<p>返回一个新的 tersor, 和 <code>self</code> 有相同的数据, 但是有不同的 <code>shape</code>.</p>
<p>返回的 tensor 共享相同的数据，并且具有相同数量的元素，但是可能有不同的大小。要 <code>view()</code> 一个tensor，新视图大小必须与其原始大小和 stride 兼容, 例如, 每个新视图维度必须是原始维度的子空间，或者仅跨越原始维度 <img alt="" src="../img/3e487bf64409a04d51b45d9f7de99192.jpg" /> 满足以下连续性条件 <img alt="" src="../img/286a7af66db16ee513cef761bb621504.jpg" />,</p>
<p><img alt="" src="../img/b7a97800576bc71106c2607bb5f1eb37.jpg" /></p>
<p>否则在 <code>view()</code> 之前, <a href="#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>contiguous()</code></a> 需要被调用. 可参考: <a href="torch.html#torch.reshape" title="torch.reshape"><code>reshape()</code></a>, 返回一个view 当形状是兼容的, 否则复制 (等价于调用 <a href="#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>contiguous()</code></a>).</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>shape</strong> (<em>torch.Size</em> <em>or</em> <em>int...</em>) – the desired size</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(4, 4)
&gt;&gt;&gt; x.size()
torch.Size([4, 4])
&gt;&gt;&gt; y = x.view(16)
&gt;&gt;&gt; y.size()
torch.Size([16])
&gt;&gt;&gt; z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
&gt;&gt;&gt; z.size()
torch.Size([2, 8])

</code></pre>
<pre><code class="language-py">view_as(other) → Tensor
</code></pre>
<p>使用 <code>other</code> 的大小 View tensor . <code>self.view_as(other)</code> 等价于 <code>self.view(other.size())</code>.</p>
<p>请参考 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>view()</code></a> 获得更多信息关于 <code>view</code>.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>) – 返回的tensor 和 <code>other</code> 大小相同.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<pre><code class="language-py">zero_() → Tensor
</code></pre>
<p>用 0 填充 <code>self</code> tensor.</p>
<pre><code class="language-py">class torch.ByteTensor
</code></pre>
<p>下面的方法是 <a href="#torch.ByteTensor" title="torch.ByteTensor"><code>torch.ByteTensor</code></a> 独占.</p>
<pre><code class="language-py">all()
</code></pre>
<pre><code class="language-py">all() → bool
</code></pre>
<p>返回 True 如果所有的元素非零, 否则 False.</p>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3).byte() % 2
&gt;&gt;&gt; a
tensor([[1, 0, 0]], dtype=torch.uint8)
&gt;&gt;&gt; a.all()
tensor(0, dtype=torch.uint8)

</code></pre>
<pre><code class="language-py">all(dim, keepdim=False, out=None) → Tensor
</code></pre>
<p>返回 True 如果 tensor 在指定维度<code>dim</code>每一行的所有的元素非零, 否则 False.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 则输出 tensor 的大小与 <code>input</code>相同, 但尺寸为1的维度<code>dim</code>除外. 否则, <code>dim</code> 会被压缩 (见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>), 导致输出张量比<code>input</code>少1维.</p>
<p>Parameters: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要reduce的维度</li>
<li><strong>keepdim</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – output tensor 是否保留 <code>dim</code> </li>
<li><strong>out</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – output tensor</li>
</ul>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 2).byte() % 2
&gt;&gt;&gt; a
tensor([[0, 0],
 [0, 0],
 [0, 1],
 [1, 1]], dtype=torch.uint8)
&gt;&gt;&gt; a.all(dim=1)
tensor([0, 0, 0, 1], dtype=torch.uint8)

</code></pre>
<pre><code class="language-py">any()
</code></pre>
<pre><code class="language-py">any() → bool
</code></pre>
<p>返回 True 如果任意元素非零, 否则 False.</p>
<p>例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3).byte() % 2
&gt;&gt;&gt; a
tensor([[0, 0, 1]], dtype=torch.uint8)
&gt;&gt;&gt; a.any()
tensor(1, dtype=torch.uint8)

</code></pre>
<pre><code class="language-py">any(dim, keepdim=False, out=None) → Tensor
</code></pre>
<p>返回 True 如果 tensor 在指定维度<code>dim</code>每一行的任意的元素非零, 否则 False.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 则输出 tensor 的大小与 <code>input</code>相同, 但尺寸为1的维度<code>dim</code>除外. 否则, <code>dim</code> 会被压缩 (见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>), 导致输出张量比<code>input</code>少1维.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要减少的维度</li>
<li><strong>keepdim</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – output tensor 是否保留 <code>dim</code> </li>
<li><strong>out</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – output tensor</li>
</ul>
<p>Example:</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 2).byte() % 2
&gt;&gt;&gt; a
tensor([[1, 0],
 [0, 0],
 [0, 1],
 [0, 0]], dtype=torch.uint8)
&gt;&gt;&gt; a.any(dim=1)
tensor([1, 0, 1, 0], dtype=torch.uint8)

</code></pre>
<hr/>
<div align="center">
  <p><a href="https://www.apachecn.org/" target="_blank"><font face="KaiTi" size="6" color="red">我们一直在努力</font></a><p>
  <p><a href="https://github.com/apachecn/pytorch-doc-zh" target="_blank">apachecn/pytorch-doc-zh</a></p>
  <p><a target="_blank" href="https://qm.qq.com/cgi-bin/qm/qr?k=5u_aAU-YlY3fH-m8meXTJzBEo2boQIUs&jump_from=webapi&authKey=CVZcReMt/vKdTXZBQ8ly+jWncXiSzzWOlrx5hybX5pSrKu6s0fvGX54+vHHlgYNt"><img border="0" src="https://pub.idqqimg.com/wpa/images/group.png" alt="【布客】中文翻译组" title="【布客】中文翻译组"></a></p>
  <p><span id="cnzz_stat_icon_1275211409"></span></p>
  <!-- <p><a href="https://get.brightdata.com/apachecn" target="_blank"><img src="/assets/images/partnerstack.gif" /></a><p> -->
  <div class="wwads-cn wwads-horizontal" data-id="206" style="max-width:680px"></div>
  <div style="text-align:center;margin:0 0 10.5px;">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3565452474788507" crossorigin="anonymous"></script>
    <!-- ApacheCNWide -->
    <ins class="adsbygoogle"
        style="display:inline-block;width:680px;height:90px"
        data-ad-client="ca-pub-3565452474788507"
        data-ad-slot="2543897000"></ins>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
  </div>
</div>
<hr/>
<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC81ODA2NC8zNDUyNw==">
  <script type="text/javascript">
  (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];

      if (typeof LivereTower === 'function') { return; }

      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;

      e.parentNode.insertBefore(j, e);
  })(document, 'script');
  </script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->






                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../torch_math_operations_blas_lapack_ops/" class="md-footer__link md-footer__link--prev" aria-label="Previous: BLAS and LAPACK Operations" rel="prev">
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                BLAS and LAPACK Operations
              </div>
            </div>
          </a>
        
        
          
          <a href="../tensor_attributes/" class="md-footer__link md-footer__link--next" aria-label="Next: Tensor Attributes" rel="next">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Tensor Attributes
              </div>
            </div>
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright" style="text-align: center; width: 100%;">
  
  
    <div>
      <div style="margin:0 0 10.5px;"><script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1275211409'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s5.cnzz.com/z_stat.php%3Fid%3D1275211409%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script></div>
      <p>Copyright © 2023 学习网站 <a href="http://beian.miit.gov.cn" target="_blank">京ICP备19016010号-1</a><br/>网站由 <a href="https://apachecn.org/cooperate/">@片刻小哥哥</a> 提供支持 | 联系QQ/微信: 529815144 请注明来意！</p>
    </div>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
  
      <script src="../../assets/javascripts/bundle.b425cdc4.min.js"></script>
      
        
          <script src="../../javascripts/mathjax.js"></script>
        
      
        
          <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
    
  <script src="../../assets/javascripts/custom.a7283b5f.min.js"></script>

  </body>
</html>