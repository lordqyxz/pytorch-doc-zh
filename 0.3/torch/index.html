
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/0.3/torch/">
      
      
        <link rel="prev" href="../notes_serialization/">
      
      
        <link rel="next" href="../tensors/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.17">
    
    
      
        <title>torch - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.26e3688c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link rel="stylesheet" href="../../assets/stylesheets/custom.bea7efe8.min.css">
  <!-- google ads -->
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3565452474788507" crossorigin="anonymous"></script>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8DP4GX97XY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-8DP4GX97XY');
  </script>
  <!-- google webmaster -->
  <meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo" />

  <!-- wwads-cn union -->
  <meta name="wwads-cn-verify" content="03c6b06952c750899bb03d998e631860" />
  <script type="text/javascript" charset="UTF-8" src="https://cdn.wwads.cn/js/makemoney.js" async></script>

  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
            
  => 组织无偿提供 中文版本（免费，秒级响应）
  <a target="_blank" href="https://chat.ibooker.org.cn/chat" style="color: red;">
    <span class="twemoji mastodon">
      <img src="https://data.apachecn.org/img/icon/ROBOT_TXT.svg" alt="ChatGPT - ailake.top">
    </span>
    <strong>ChatGPT - ailake.top</strong>
  </a> 一起来白嫖叭～！

          </div>
          
        </aside>
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              torch
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        PyTorch 中文文档 & 教程
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          PyTorch 2.0 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 2.0 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/README.md" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          PyTorch 1.7 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.7 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
          学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
          PyTorch 深度学习：60 分钟的突击
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习：60 分钟的突击
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/02/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/03/" class="md-nav__link">
        张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/04/" class="md-nav__link">
        torch.autograd的简要介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/05/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/06/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
          通过示例学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          通过示例学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/07/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/08/" class="md-nav__link">
        热身：NumPy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/09/" class="md-nav__link">
        PyTorch：张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/10/" class="md-nav__link">
        PyTorch：张量和 Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/11/" class="md-nav__link">
        PyTorch：定义新的 Autograd 函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/12/" class="md-nav__link">
        PyTorch：nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/13/" class="md-nav__link">
        PyTorch：optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/14/" class="md-nav__link">
        PyTorch：自定义nn模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/15/" class="md-nav__link">
        PyTorch：控制流 - 权重共享
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/16/" class="md-nav__link">
        torch.nn到底是什么？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/17/" class="md-nav__link">
        使用 TensorBoard 可视化模型，数据和训练
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
          图片/视频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          图片/视频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/19/" class="md-nav__link">
        torchvision对象检测微调教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/20/" class="md-nav__link">
        计算机视觉的迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/21/" class="md-nav__link">
        对抗示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/22/" class="md-nav__link">
        DCGAN 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
          音频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          音频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/24/" class="md-nav__link">
        音频 I/O 和torchaudio的预处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/25/" class="md-nav__link">
        使用torchaudio的语音命令识别
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/27/" class="md-nav__link">
        使用nn.Transformer和torchtext的序列到序列建模
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/28/" class="md-nav__link">
        从零开始的 NLP：使用字符级 RNN 分类名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/29/" class="md-nav__link">
        从零开始的 NLP：使用字符级 RNN 生成名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/30/" class="md-nav__link">
        从零开始的 NLP：使用序列到序列网络和注意力的翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/31/" class="md-nav__link">
        使用torchtext的文本分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/32/" class="md-nav__link">
        torchtext语言翻译
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
      
      
      
        <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/34/" class="md-nav__link">
        强化学习（DQN）教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/35/" class="md-nav__link">
        训练玩马里奥的 RL 智能体
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
      
      
      
        <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
          在生产中部署 PyTorch 模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_6">
          <span class="md-nav__icon md-icon"></span>
          在生产中部署 PyTorch 模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/37/" class="md-nav__link">
        通过使用 Flask 的 REST API 在 Python 中部署 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/38/" class="md-nav__link">
        TorchScript 简介
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/39/" class="md-nav__link">
        在 C-- 中加载 TorchScript 模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/40/" class="md-nav__link">
        将模型从 PyTorch 导出到 ONNX 并使用 ONNX 运行时运行它（可选）
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
      
      
      
        <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
          前端 API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_7">
          <span class="md-nav__icon md-icon"></span>
          前端 API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/42/" class="md-nav__link">
        PyTorch 中的命名张量简介（原型）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/43/" class="md-nav__link">
        PyTorch 中通道在最后的内存格式（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/44/" class="md-nav__link">
        使用 PyTorch C-- 前端
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/45/" class="md-nav__link">
        自定义 C-- 和 CUDA 扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/46/" class="md-nav__link">
        使用自定义 C-- 运算符扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/47/" class="md-nav__link">
        使用自定义 C-- 类扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/48/" class="md-nav__link">
        TorchScript 中的动态并行性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/49/" class="md-nav__link">
        C-- 前端中的 Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/50/" class="md-nav__link">
        在 C-- 中注册调度运算符
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_8" >
      
      
      
        <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
          模型优化
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_8">
          <span class="md-nav__icon md-icon"></span>
          模型优化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/52/" class="md-nav__link">
        分析您的 PyTorch 模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/53/" class="md-nav__link">
        使用 Ray Tune 的超参数调整
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/54/" class="md-nav__link">
        模型剪裁教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/55/" class="md-nav__link">
        LSTM 单词语言模型上的动态量化（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/56/" class="md-nav__link">
        BERT 上的动态量化（Beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/57/" class="md-nav__link">
        PyTorch 中使用 Eager 模式的静态量化（beta）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/58/" class="md-nav__link">
        计算机视觉的量化迁移学习教程（beta）
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_9" >
      
      
      
        <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
          并行和分布式训练
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_9">
          <span class="md-nav__icon md-icon"></span>
          并行和分布式训练
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/60/" class="md-nav__link">
        PyTorch 分布式概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/61/" class="md-nav__link">
        单机模型并行最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/62/" class="md-nav__link">
        分布式数据并行入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/63/" class="md-nav__link">
        用 PyTorch 编写分布式应用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/64/" class="md-nav__link">
        分布式 RPC 框架入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/65/" class="md-nav__link">
        使用分布式 RPC 框架实现参数服务器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/66/" class="md-nav__link">
        使用 RPC 的分布式管道并行化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/67/" class="md-nav__link">
        使用异步执行实现批量 RPC 处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/68/" class="md-nav__link">
        将分布式DataParallel与分布式 RPC 框架相结合
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          PyTorch 1.4 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.4 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
          入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1_1" id="__nav_4_1_1_label" tabindex="0">
          使用 PyTorch 进行深度学习：60 分钟的闪电战
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1_1">
          <span class="md-nav__icon md-icon"></span>
          使用 PyTorch 进行深度学习：60 分钟的闪电战
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/4/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/tensor_tutorial/" class="md-nav__link">
        什么是PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/autograd_tutorial/" class="md-nav__link">
        Autograd：自动求导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/cifar10_tutorial/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/data_parallel_tutorial/" class="md-nav__link">
        可选：数据并行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/5/" class="md-nav__link">
        编写自定义数据集，数据加载器和转换
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/6/" class="md-nav__link">
        使用 TensorBoard 可视化模型，数据和训练
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
      
      
      
        <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
          图片
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          图片
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/8/" class="md-nav__link">
        TorchVision 对象检测微调教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/9/" class="md-nav__link">
        转移学习的计算机视觉教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/10/" class="md-nav__link">
        空间变压器网络教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/11/" class="md-nav__link">
        使用 PyTorch 进行神经传递
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/12/" class="md-nav__link">
        对抗示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/13/" class="md-nav__link">
        DCGAN 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
      
      
      
        <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
          音频
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          音频
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/15/" class="md-nav__link">
        torchaudio 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/17/" class="md-nav__link">
        NLP From Scratch: 使用char-RNN对姓氏进行分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/18/" class="md-nav__link">
        NLP From Scratch: 生成名称与字符级RNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/19/" class="md-nav__link">
        NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/20/" class="md-nav__link">
        使用 TorchText 进行文本分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/21/" class="md-nav__link">
        使用 TorchText 进行语言翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/22/" class="md-nav__link">
        使用 nn.Transformer 和 TorchText 进行序列到序列建模
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
      
      
      
        <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
          命名为 Tensor(实验性）
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_5">
          <span class="md-nav__icon md-icon"></span>
          命名为 Tensor(实验性）
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/24/" class="md-nav__link">
        (实验性)PyTorch 中的命名张量简介
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6" >
      
      
      
        <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_6">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/26/" class="md-nav__link">
        强化学习(DQN)教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_7" >
      
      
      
        <label class="md-nav__link" for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
          在生产中部署 PyTorch 模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_7">
          <span class="md-nav__icon md-icon"></span>
          在生产中部署 PyTorch 模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/28/" class="md-nav__link">
        通过带有 Flask 的 REST API 在 Python 中部署 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/29/" class="md-nav__link">
        TorchScript 简介
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/30/" class="md-nav__link">
        在 C --中加载 TorchScript 模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/31/" class="md-nav__link">
        (可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_8" >
      
      
      
        <label class="md-nav__link" for="__nav_4_8" id="__nav_4_8_label" tabindex="0">
          并行和分布式训练
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_8">
          <span class="md-nav__icon md-icon"></span>
          并行和分布式训练
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/33/" class="md-nav__link">
        单机模型并行最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/34/" class="md-nav__link">
        分布式数据并行入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/35/" class="md-nav__link">
        用 PyTorch 编写分布式应用程序
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/36/" class="md-nav__link">
        分布式 RPC 框架入门
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/37/" class="md-nav__link">
        (高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_9" >
      
      
      
        <label class="md-nav__link" for="__nav_4_9" id="__nav_4_9_label" tabindex="0">
          扩展 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_9">
          <span class="md-nav__icon md-icon"></span>
          扩展 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/39/" class="md-nav__link">
        使用自定义 C --运算符扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/40/" class="md-nav__link">
        使用自定义 C --类扩展 TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/41/" class="md-nav__link">
        使用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/42/" class="md-nav__link">
        自定义 C --和 CUDA 扩展
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_10" >
      
      
      
        <label class="md-nav__link" for="__nav_4_10" id="__nav_4_10_label" tabindex="0">
          模型优化
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_10_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_10">
          <span class="md-nav__icon md-icon"></span>
          模型优化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/44/" class="md-nav__link">
        LSTM Word 语言模型上的(实验）动态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/45/" class="md-nav__link">
        (实验性）在 PyTorch 中使用 Eager 模式进行静态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/46/" class="md-nav__link">
        (实验性）计算机视觉教程的量化转移学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/47/" class="md-nav__link">
        (实验）BERT 上的动态量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/48/" class="md-nav__link">
        修剪教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_11" >
      
      
      
        <label class="md-nav__link" for="__nav_4_11" id="__nav_4_11_label" tabindex="0">
          PyTorch 用其他语言
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_11_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_11">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 用其他语言
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/50/" class="md-nav__link">
        使用 PyTorch C --前端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_12" >
      
      
      
        <label class="md-nav__link" for="__nav_4_12" id="__nav_4_12_label" tabindex="0">
          PyTorch 基础知识
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_12_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_12">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 基础知识
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/52/" class="md-nav__link">
        通过示例学习 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/53/" class="md-nav__link">
        torch.nn 到底是什么？
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_13" >
      
      
      
        <label class="md-nav__link" for="__nav_4_13" id="__nav_4_13_label" tabindex="0">
          笔记
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_13_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_13">
          <span class="md-nav__icon md-icon"></span>
          笔记
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/56/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/57/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/58/" class="md-nav__link">
        CPU 线程和 TorchScript 推断
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/59/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/60/" class="md-nav__link">
        分布式 Autograd 设计
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/61/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/62/" class="md-nav__link">
        经常问的问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/63/" class="md-nav__link">
        大规模部署的功能
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/64/" class="md-nav__link">
        并行处理最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/65/" class="md-nav__link">
        重现性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/66/" class="md-nav__link">
        远程参考协议
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/67/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/68/" class="md-nav__link">
        Windows 常见问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/69/" class="md-nav__link">
        XLA 设备上的 PyTorch
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_14" >
      
      
      
        <label class="md-nav__link" for="__nav_4_14" id="__nav_4_14_label" tabindex="0">
          语言绑定
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_14_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_14">
          <span class="md-nav__icon md-icon"></span>
          语言绑定
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/71/" class="md-nav__link">
        PyTorch C -- API
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/72/" class="md-nav__link">
        PyTorch Java API
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_15" >
      
      
      
        <label class="md-nav__link" for="__nav_4_15" id="__nav_4_15_label" tabindex="0">
          Python API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_15_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_15">
          <span class="md-nav__icon md-icon"></span>
          Python API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/74/" class="md-nav__link">
        torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/75/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/76/" class="md-nav__link">
        torch功能
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/77/" class="md-nav__link">
        torch张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/78/" class="md-nav__link">
        张量属性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/79/" class="md-nav__link">
        自动差分包-Torch.Autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/80/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/81/" class="md-nav__link">
        分布式通讯包-Torch.Distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/82/" class="md-nav__link">
        概率分布-torch分布
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/83/" class="md-nav__link">
        torch.hub
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/84/" class="md-nav__link">
        torch脚本
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/85/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/86/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/87/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/88/" class="md-nav__link">
        量化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/89/" class="md-nav__link">
        分布式 RPC 框架
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/90/" class="md-nav__link">
        torch随机
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/91/" class="md-nav__link">
        torch稀疏
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/92/" class="md-nav__link">
        torch存储
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/93/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/94/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/95/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/96/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/97/" class="md-nav__link">
        torch.utils.dlpack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/98/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/99/" class="md-nav__link">
        torch.utils.tensorboard
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/100/" class="md-nav__link">
        类型信息
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/101/" class="md-nav__link">
        命名张量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/102/" class="md-nav__link">
        命名为 Tensors 操作员范围
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/103/" class="md-nav__link">
        糟糕！
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_16" >
      
      
      
        <label class="md-nav__link" for="__nav_4_16" id="__nav_4_16_label" tabindex="0">
          torchvision参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_16_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_16">
          <span class="md-nav__icon md-icon"></span>
          torchvision参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/105/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_17" >
      
      
      
        <label class="md-nav__link" for="__nav_4_17" id="__nav_4_17_label" tabindex="0">
          音频参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_17_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_17">
          <span class="md-nav__icon md-icon"></span>
          音频参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/107/" class="md-nav__link">
        torchaudio
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_18" >
      
      
      
        <label class="md-nav__link" for="__nav_4_18" id="__nav_4_18_label" tabindex="0">
          torchtext参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_18_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_18">
          <span class="md-nav__icon md-icon"></span>
          torchtext参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/109/" class="md-nav__link">
        torchtext
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_19" >
      
      
      
        <label class="md-nav__link" for="__nav_4_19" id="__nav_4_19_label" tabindex="0">
          社区
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_19_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_19">
          <span class="md-nav__icon md-icon"></span>
          社区
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/111/" class="md-nav__link">
        PyTorch 贡献指南
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/112/" class="md-nav__link">
        PyTorch 治理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/113/" class="md-nav__link">
        PyTorch 治理| 感兴趣的人
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          PyTorch 1.0 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 1.0 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_1" id="__nav_5_2_1_label" tabindex="0">
          入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_1">
          <span class="md-nav__icon md-icon"></span>
          入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_1_1" id="__nav_5_2_1_1_label" tabindex="0">
          PyTorch 深度学习: 60 分钟极速入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习: 60 分钟极速入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deep_learning_60min_blitz/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_tensor_tutorial/" class="md-nav__link">
        什么是 PyTorch？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_autograd_tutorial/" class="md-nav__link">
        Autograd：自动求导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_cifar10_tutorial/" class="md-nav__link">
        训练分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_data_parallel_tutorial/" class="md-nav__link">
        可选：数据并行处理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/data_loading_tutorial/" class="md-nav__link">
        数据加载和处理教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/pytorch_with_examples/" class="md-nav__link">
        用例子学习 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/transfer_learning_tutorial/" class="md-nav__link">
        迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deploy_seq2seq_hybrid_frontend_tutorial/" class="md-nav__link">
        混合前端的 seq2seq 模型部署
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/saving_loading_models/" class="md-nav__link">
        Saving and Loading Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_tutorial/" class="md-nav__link">
        What is torch.nn really?
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_2" id="__nav_5_2_2_label" tabindex="0">
          图像
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_2">
          <span class="md-nav__icon md-icon"></span>
          图像
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/finetuning_torchvision_models_tutorial/" class="md-nav__link">
        Torchvision 模型微调
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/spatial_transformer_tutorial/" class="md-nav__link">
        空间变换器网络教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/neural_style_tutorial/" class="md-nav__link">
        使用 PyTorch 进行图像风格转换
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/fgsm_tutorial/" class="md-nav__link">
        对抗性示例生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/super_resolution_with_caffe2/" class="md-nav__link">
        使用 ONNX 将模型从 PyTorch 传输到 Caffe2 和移动端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_3" id="__nav_5_2_3_label" tabindex="0">
          文本
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_3">
          <span class="md-nav__icon md-icon"></span>
          文本
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/chatbot_tutorial/" class="md-nav__link">
        聊天机器人教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/char_rnn_generation_tutorial/" class="md-nav__link">
        使用字符级别特征的 RNN 网络生成姓氏
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/char_rnn_classification_tutorial/" class="md-nav__link">
        使用字符级别特征的 RNN 网络进行姓氏分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3_4" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_3_4" id="__nav_5_2_3_4_label" tabindex="0">
          Deep Learning for NLP with Pytorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_3_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_3_4">
          <span class="md-nav__icon md-icon"></span>
          Deep Learning for NLP with Pytorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deep_learning_nlp_tutorial/" class="md-nav__link">
        在深度学习和 NLP 中使用 Pytorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_pytorch_tutorial/" class="md-nav__link">
        PyTorch 介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_deep_learning_tutorial/" class="md-nav__link">
        使用 PyTorch 进行深度学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_word_embeddings_tutorial/" class="md-nav__link">
        Word Embeddings: Encoding Lexical Semantics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_sequence_models_tutorial/" class="md-nav__link">
        序列模型和 LSTM 网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_advanced_tutorial/" class="md-nav__link">
        Advanced: Making Dynamic Decisions and the Bi-LSTM CRF
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/seq2seq_translation_tutorial/" class="md-nav__link">
        基于注意力机制的 seq2seq 神经网络翻译
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_4" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_4" id="__nav_5_2_4_label" tabindex="0">
          生成
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_4">
          <span class="md-nav__icon md-icon"></span>
          生成
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dcgan_faces_tutorial/" class="md-nav__link">
        DCGAN Tutorial
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_5" id="__nav_5_2_5_label" tabindex="0">
          强化学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_5">
          <span class="md-nav__icon md-icon"></span>
          强化学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/reinforcement_q_learning/" class="md-nav__link">
        Reinforcement Learning (DQN) Tutorial
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_6" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_6" id="__nav_5_2_6_label" tabindex="0">
          扩展 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_6">
          <span class="md-nav__icon md-icon"></span>
          扩展 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/numpy_extensions_tutorial/" class="md-nav__link">
        用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_extension/" class="md-nav__link">
        Custom C-- and CUDA Extensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_script_custom_ops/" class="md-nav__link">
        Extending TorchScript with Custom C-- Operators
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_7" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_7" id="__nav_5_2_7_label" tabindex="0">
          生产性使用
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_7">
          <span class="md-nav__icon md-icon"></span>
          生产性使用
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dist_tuto/" class="md-nav__link">
        Writing Distributed Applications with PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/aws_distributed_training_tutorial/" class="md-nav__link">
        使用 Amazon AWS 进行分布式训练
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/ONNXLive/" class="md-nav__link">
        ONNX 现场演示教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_export/" class="md-nav__link">
        在 C-- 中加载 PYTORCH 模型
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_8" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2_8" id="__nav_5_2_8_label" tabindex="0">
          其它语言中的 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2_8">
          <span class="md-nav__icon md-icon"></span>
          其它语言中的 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_frontend/" class="md-nav__link">
        使用 PyTorch C-- 前端
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_1" id="__nav_5_3_1_label" tabindex="0">
          注解
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_1">
          <span class="md-nav__icon md-icon"></span>
          注解
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_broadcasting/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_cuda/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_extending/" class="md-nav__link">
        Extending PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_faq/" class="md-nav__link">
        Frequently Asked Questions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_multiprocessing/" class="md-nav__link">
        Multiprocessing best practices
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_randomness/" class="md-nav__link">
        Reproducibility
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_serialization/" class="md-nav__link">
        Serialization semantics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_windows/" class="md-nav__link">
        Windows FAQ
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2" id="__nav_5_3_2_label" tabindex="0">
          包参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_2">
          <span class="md-nav__icon md-icon"></span>
          包参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2_1" id="__nav_5_3_2_1_label" tabindex="0">
          torch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_3_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_2_1">
          <span class="md-nav__icon md-icon"></span>
          torch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_tensors/" class="md-nav__link">
        Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_random_sampling/" class="md-nav__link">
        Random sampling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_serialization_parallelism_utilities/" class="md-nav__link">
        Serialization, Parallelism, Utilities
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_2_1_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_2_1_5" id="__nav_5_3_2_1_5_label" tabindex="0">
          Math operations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_5_3_2_1_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_2_1_5">
          <span class="md-nav__icon md-icon"></span>
          Math operations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_pointwise_ops/" class="md-nav__link">
        Pointwise Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_reduction_ops/" class="md-nav__link">
        Reduction Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_comparison_ops/" class="md-nav__link">
        Comparison Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_spectral_ops/" class="md-nav__link">
        Spectral Ops
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_other_ops/" class="md-nav__link">
        Other Operations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_blas_lapack_ops/" class="md-nav__link">
        BLAS and LAPACK Operations
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/tensors/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/tensor_attributes/" class="md-nav__link">
        Tensor Attributes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/type_info/" class="md-nav__link">
        数据类型信息
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/sparse/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_functional/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_init/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/autograd/" class="md-nav__link">
        Automatic differentiation package - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributed/" class="md-nav__link">
        Distributed communication package - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributions/" class="md-nav__link">
        Probability distributions - torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/jit/" class="md-nav__link">
        Torch Script
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/multiprocessing/" class="md-nav__link">
        多进程包 - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/bottleneck/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/checkpoint/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/docs_cpp_extension/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dlpack/" class="md-nav__link">
        torch.utils.dlpack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/hub/" class="md-nav__link">
        torch.hub
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/onnx/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributed_deprecated/" class="md-nav__link">
        Distributed communication package (deprecated) - torch.distributed.deprecated
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3_3" id="__nav_5_3_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/docs_torchvision_ref/" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_transforms/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          PyTorch 0.4 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.4 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" >
      
      
      
        <label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
          笔记
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          笔记
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/1/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/2/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/3/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/4/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/5/" class="md-nav__link">
        常见问题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/6/" class="md-nav__link">
        多进程最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/7/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/8/" class="md-nav__link">
        Windows 常见问题
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
      
      
      
        <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
          包参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_2">
          <span class="md-nav__icon md-icon"></span>
          包参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/10/" class="md-nav__link">
        Torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/11/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/12/" class="md-nav__link">
        Tensor Attributes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/13/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/14/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/15/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/16/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/17/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/18/" class="md-nav__link">
        自动差异化包 - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/19/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/20/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/21/" class="md-nav__link">
        torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/22/" class="md-nav__link">
        Multiprocessing 包 - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/23/" class="md-nav__link">
        分布式通讯包 - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/24/" class="md-nav__link">
        torch.utils.bottleneck
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/25/" class="md-nav__link">
        torch.utils.checkpoint
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/26/" class="md-nav__link">
        torch.utils.cpp_extension
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/27/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/28/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/29/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/30/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/31/" class="md-nav__link">
        遗留包 - torch.legacy
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
      
      
      
        <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/33/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/34/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/35/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/36/" class="md-nav__link">
        torchvision.transform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.4/37/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
      
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          PyTorch 0.3 中文文档 & 教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.3 中文文档 & 教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
          中文教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2">
          <span class="md-nav__icon md-icon"></span>
          中文教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1" id="__nav_7_2_1_label" tabindex="0">
          初学者教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1">
          <span class="md-nav__icon md-icon"></span>
          初学者教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_1" id="__nav_7_2_1_1_label" tabindex="0">
          PyTorch 深度学习: 60 分钟极速入门教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 深度学习: 60 分钟极速入门教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning_60min_blitz/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_tensor_tutorial/" class="md-nav__link">
        PyTorch 是什么？
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_autograd_tutorial/" class="md-nav__link">
        自动求导: 自动微分
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_neural_networks_tutorial/" class="md-nav__link">
        神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_cifar10_tutorial/" class="md-nav__link">
        训练一个分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_data_parallel_tutorial/" class="md-nav__link">
        可选: 数据并行
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_2" id="__nav_7_2_1_2_label" tabindex="0">
          PyTorch for former Torch users
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_2">
          <span class="md-nav__icon md-icon"></span>
          PyTorch for former Torch users
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../former_torchies_tutorial/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../former_torchies_tensor_tutorial/" class="md-nav__link">
        Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../former_torchies_autograd_tutorial/" class="md-nav__link">
        Autograd (自动求导)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../former_torchies_nn_tutorial/" class="md-nav__link">
        nn package
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../former_torchies_parallelism_tutorial/" class="md-nav__link">
        Multi-GPU examples
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_3" id="__nav_7_2_1_3_label" tabindex="0">
          跟着例子学习 PyTorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_3">
          <span class="md-nav__icon md-icon"></span>
          跟着例子学习 PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_warm-up-numpy/" class="md-nav__link">
        Warm-up: numpy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_pytorch-tensors/" class="md-nav__link">
        PyTorch: Tensors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_pytorch-variables-and-autograd/" class="md-nav__link">
        PyTorch: 变量和autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_pytorch-defining-new-autograd-functions/" class="md-nav__link">
        PyTorch: 定义新的autograd函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_tensorflow-static-graphs/" class="md-nav__link">
        TensorFlow: 静态图
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_pytorch-nn/" class="md-nav__link">
        PyTorch: nn包
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_pytorch-optim/" class="md-nav__link">
        PyTorch: optim包
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_pytorch-custom-nn-modules/" class="md-nav__link">
        PyTorch: 定制化nn模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples_pytorch-control-flow-weight-sharing/" class="md-nav__link">
        PyTorch: 动态控制流程 - 权重共享
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../transfer_learning_tutorial/" class="md-nav__link">
        迁移学习教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../data_loading_tutorial/" class="md-nav__link">
        数据加载和处理教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_1_6" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_1_6" id="__nav_7_2_1_6_label" tabindex="0">
          针对NLP的Pytorch深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_2_1_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_1_6">
          <span class="md-nav__icon md-icon"></span>
          针对NLP的Pytorch深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning_nlp_tutorial/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_pytorch_tutorial/" class="md-nav__link">
        PyTorch介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_deep_learning_tutorial/" class="md-nav__link">
        PyTorch深度学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_word_embeddings_tutorial/" class="md-nav__link">
        词汇嵌入:编码词汇语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_sequence_models_tutorial/" class="md-nav__link">
        序列模型和 LSTM 网络(长短记忆网络）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_advanced_tutorial/" class="md-nav__link">
        高级教程: 作出动态决策和 Bi-LSTM CRF
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_2" id="__nav_7_2_2_label" tabindex="0">
          中级教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_2">
          <span class="md-nav__icon md-icon"></span>
          中级教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_classification_tutorial/" class="md-nav__link">
        用字符级RNN分类名称
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_generation_tutorial/" class="md-nav__link">
        基与字符级RNN(Char-RNN）的人名生成
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../seq2seq_translation_tutorial/" class="md-nav__link">
        用基于注意力机制的seq2seq神经网络进行翻译
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../reinforcement_q_learning/" class="md-nav__link">
        强化学习(DQN）教程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dist_tuto/" class="md-nav__link">
        Writing Distributed Applications with PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../spatial_transformer_tutorial/" class="md-nav__link">
        空间转换网络 (Spatial Transformer Networks) 教程
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_2_3" id="__nav_7_2_3_label" tabindex="0">
          高级教程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_2_3">
          <span class="md-nav__icon md-icon"></span>
          高级教程
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../neural_style_tutorial/" class="md-nav__link">
        用 PyTorch 做 神经转换 (Neural Transfer)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../numpy_extensions_tutorial/" class="md-nav__link">
        使用 numpy 和 scipy 创建扩展
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../super_resolution_with_caffe2/" class="md-nav__link">
        使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../c_extension/" class="md-nav__link">
        为 pytorch 自定义 C 扩展
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3" checked>
      
      
      
        <label class="md-nav__link" for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
          中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_7_3">
          <span class="md-nav__icon md-icon"></span>
          中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3_1" id="__nav_7_3_1_label" tabindex="0">
          介绍
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3_1">
          <span class="md-nav__icon md-icon"></span>
          介绍
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_broadcasting/" class="md-nav__link">
        广播语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_cuda/" class="md-nav__link">
        CUDA 语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_extending/" class="md-nav__link">
        扩展 PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_multiprocessing/" class="md-nav__link">
        多进程的最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notes_serialization/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_2" checked>
      
      
      
        <label class="md-nav__link" for="__nav_7_3_2" id="__nav_7_3_2_label" tabindex="0">
          Package 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_2_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_7_3_2">
          <span class="md-nav__icon md-icon"></span>
          Package 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          torch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        torch
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensors" class="md-nav__link">
    Tensors (张量)
  </a>
  
    <nav class="md-nav" aria-label="Tensors (张量)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creation-ops" class="md-nav__link">
    Creation Ops (创建操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indexing-slicing-joining-mutating-ops" class="md-nav__link">
    Indexing, Slicing, Joining, Mutating Ops (索引, 切片, 连接, 换位) 操作
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-sampling" class="md-nav__link">
    Random sampling (随机采样)
  </a>
  
    <nav class="md-nav" aria-label="Random sampling (随机采样)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#in-place-random-sampling" class="md-nav__link">
    In-place random sampling (直接随机采样)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#serialization" class="md-nav__link">
    Serialization (序列化)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parallelism" class="md-nav__link">
    Parallelism (并行化)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#math-operations" class="md-nav__link">
    Math operations (数学操作)
  </a>
  
    <nav class="md-nav" aria-label="Math operations (数学操作)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pointwise-ops" class="md-nav__link">
    Pointwise Ops (逐点操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduction-ops" class="md-nav__link">
    Reduction Ops (归约操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparison-ops" class="md-nav__link">
    Comparison Ops (比较操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-operations" class="md-nav__link">
    Other Operations (其它操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#blas-and-lapack-operations-blaslapack" class="md-nav__link">
    BLAS and LAPACK Operations (BLAS和LAPACK操作)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tensors/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../sparse/" class="md-nav__link">
        torch.sparse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../autograd/" class="md-nav__link">
        Automatic differentiation package - torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../distributions/" class="md-nav__link">
        Probability distributions - torch.distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../multiprocessing/" class="md-nav__link">
        Multiprocessing package - torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../distributed/" class="md-nav__link">
        Distributed communication package - torch.distributed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../legacy/" class="md-nav__link">
        Legacy package - torch.legacy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ffi/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../onnx/" class="md-nav__link">
        torch.onnx
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_7_3_3" id="__nav_7_3_3_label" tabindex="0">
          torchvision 参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7_3_3">
          <span class="md-nav__icon md-icon"></span>
          torchvision 参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../transforms/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
      
      
      
        <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
          PyTorch 0.2 中文文档
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          PyTorch 0.2 中文文档
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2" >
      
      
      
        <label class="md-nav__link" for="__nav_8_2" id="__nav_8_2_label" tabindex="0">
          说明
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_2">
          <span class="md-nav__icon md-icon"></span>
          说明
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/autograd/" class="md-nav__link">
        自动求导机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/cuda/" class="md-nav__link">
        CUDA语义
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/extending/" class="md-nav__link">
        扩展PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/multiprocessing/" class="md-nav__link">
        多进程最佳实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/notes/serialization/" class="md-nav__link">
        序列化语义
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_3" >
      
      
      
        <label class="md-nav__link" for="__nav_8_3" id="__nav_8_3_label" tabindex="0">
          PACKAGE参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_3">
          <span class="md-nav__icon md-icon"></span>
          PACKAGE参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch/" class="md-nav__link">
        torch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/Tensor/" class="md-nav__link">
        torch.Tensor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/Storage/" class="md-nav__link">
        torch.Storage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-nn/" class="md-nav__link">
        torch.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/functional/" class="md-nav__link">
        torch.nn.functional
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-autograd/" class="md-nav__link">
        torch.autograd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-optim/" class="md-nav__link">
        torch.optim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/nn_init/" class="md-nav__link">
        torch.nn.init
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-multiprocessing/" class="md-nav__link">
        torch.multiprocessing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/legacy/" class="md-nav__link">
        torch.legacy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/torch-cuda/" class="md-nav__link">
        torch.cuda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/ffi/" class="md-nav__link">
        torch.utils.ffi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/data/" class="md-nav__link">
        torch.utils.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/package_references/model_zoo/" class="md-nav__link">
        torch.utils.model_zoo
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_4" >
      
      
      
        <label class="md-nav__link" for="__nav_8_4" id="__nav_8_4_label" tabindex="0">
          TORCHVISION参考
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8_4">
          <span class="md-nav__icon md-icon"></span>
          TORCHVISION参考
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision/" class="md-nav__link">
        torchvision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-datasets/" class="md-nav__link">
        torchvision.datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-models/" class="md-nav__link">
        torchvision.models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-transform/" class="md-nav__link">
        torchvision.transforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/torchvision/torchvision-utils/" class="md-nav__link">
        torchvision.utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../0.2/acknowledgement/" class="md-nav__link">
        致谢
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../contrib/" class="md-nav__link">
        贡献者
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about/" class="md-nav__link">
        关于我们
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        中文资源合集
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensors" class="md-nav__link">
    Tensors (张量)
  </a>
  
    <nav class="md-nav" aria-label="Tensors (张量)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creation-ops" class="md-nav__link">
    Creation Ops (创建操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indexing-slicing-joining-mutating-ops" class="md-nav__link">
    Indexing, Slicing, Joining, Mutating Ops (索引, 切片, 连接, 换位) 操作
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-sampling" class="md-nav__link">
    Random sampling (随机采样)
  </a>
  
    <nav class="md-nav" aria-label="Random sampling (随机采样)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#in-place-random-sampling" class="md-nav__link">
    In-place random sampling (直接随机采样)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#serialization" class="md-nav__link">
    Serialization (序列化)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parallelism" class="md-nav__link">
    Parallelism (并行化)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#math-operations" class="md-nav__link">
    Math operations (数学操作)
  </a>
  
    <nav class="md-nav" aria-label="Math operations (数学操作)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pointwise-ops" class="md-nav__link">
    Pointwise Ops (逐点操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduction-ops" class="md-nav__link">
    Reduction Ops (归约操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparison-ops" class="md-nav__link">
    Comparison Ops (比较操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-operations" class="md-nav__link">
    Other Operations (其它操作)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#blas-and-lapack-operations-blaslapack" class="md-nav__link">
    BLAS and LAPACK Operations (BLAS和LAPACK操作)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/0.3/torch.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/0.3/torch.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<div class="wwads-cn wwads-horizontal" data-id="206" style="max-width:680px"></div>
<h1 id="torch">torch</h1>
<blockquote>
<p>译者：<a href="https://github.com/wangyangting">@那伊抹微笑</a>、@yudong、<a href="https://github.com/chenyyx">@小瑶</a>、<a href="https://github.com/jiangzhonglian">@片刻</a>、<a href="https://github.com/sawyer7246">@李雨龙</a>、<a href="https://github.com/YaoSam">@K</a> <a href="https://github.com/EVYang1992">@devin</a>、<a href="https://github.com/nothingcouldbebetter">@张假飞</a>、<a href="https://github.com/rickllyxu">@rickllyxu</a></p>
<p>校对者：<a href="https://github.com/nothingcouldbebetter">@张假飞</a>、<a href="https://github.com/wizardforcel">@飞龙</a></p>
</blockquote>
<p>torch package 包含了多维张量的数据结构, 以及基于其上的多种数学操作. 此外, 它还提供了许多用于高效序列化 Tensor 和任意类型的实用工具包, 以及一起其它有用的实用工具包.</p>
<p>它有一个 CUDA 的对应实现, 它使您能够在计算能力 &gt;=0.3 的 NVIDIA GPU 上进行张量运算.</p>
<h2 id="tensors">Tensors (张量)</h2>
<pre><code class="language-py">torch.is_tensor(obj)
</code></pre>
<p>如果 <code>obj</code> 是一个 pytorch tensor, 则返回True.</p>
<p>参数：<code>obj (Object)</code> – 用于测试的对象</p>
<pre><code class="language-py">torch.is_storage(obj)
</code></pre>
<p>如果 <code>obj</code> 是一个 pytorch storage object, 则返回True.</p>
<p>参数：<code>obj (Object)</code> – 用于测试的对象</p>
<pre><code class="language-py">torch.set_default_tensor_type(t)
</code></pre>
<pre><code class="language-py">torch.numel(input) → int
</code></pre>
<p>返回 <code>input</code> Tensor 中的元素总数.</p>
<p>参数：<code>input (Tensor)</code> – 输入的 <code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1,2,3,4,5)
&gt;&gt;&gt; torch.numel(a)
120
&gt;&gt;&gt; a = torch.zeros(4,4)
&gt;&gt;&gt; torch.numel(a)
16

</code></pre>
<pre><code class="language-py">torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None)
</code></pre>
<p>设置打印选项. 从 Numpy 中采集数据</p>
<p>参数：</p>
<ul>
<li><code>precision</code> – 浮点输出精度的位数 (默认值为 8).</li>
<li><code>threshold</code> – 触发汇总显示而不是完全显示(repr)的数组元素的总数 (默认值为 1000).</li>
<li><code>edgeitems</code> – 每个维度开始和结束时总结的数组项数 (默认值为 3).</li>
<li><code>linewidth</code> – 插入换行符的每行字符数 (默认值为 80). Thresholded matricies(阈值矩阵) 将忽略这个参数.</li>
<li><code>profile</code> – 用于漂亮格式的打印. 可以用以下任何选项来进行覆盖 (default, short, full)</li>
</ul>
<h3 id="creation-ops">Creation Ops (创建操作)</h3>
<pre><code class="language-py">torch.eye(n, m=None, out=None)
</code></pre>
<p>返回对角线位置全为1, 其它位置全为0的二维 tensor.</p>
<p>参数：</p>
<ul>
<li><code>n (int)</code> – 行数</li>
<li><code>m (int, 可选)</code> – 列数. 如果为 None,则默认为 <code>n</code></li>
<li><code>out (Tensor, 可选)</code> – 输出 tensor</li>
</ul>
<p>返回值：一个对角线位置全为1, 其它位置全为0的二维 tensor.</p>
<p>返回类型：<code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.eye(3)
 1  0  0
 0  1  0
 0  0  1
[torch.FloatTensor of size 3x3]

</code></pre>
<pre><code class="language-py">torch.from_numpy(ndarray) → Tensor
</code></pre>
<p>从 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.14)"><code>numpy.ndarray</code></a> 类 创建一个 <a href="tensors.html#torch.Tensor" title="torch.Tensor"><code>Tensor</code></a> 类.</p>
<p>返回 tensor 和 <code>ndarray</code> 共享相同的内存. 对 tensor 的修改将反映在 <code>ndarray</code> 中, 反之亦然. 返回 tensor 不可调整大小.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = numpy.array([1, 2, 3])
&gt;&gt;&gt; t = torch.from_numpy(a)
&gt;&gt;&gt; t
torch.LongTensor([1, 2, 3])
&gt;&gt;&gt; t[0] = -1
&gt;&gt;&gt; a
array([-1,  2,  3])

</code></pre>
<pre><code class="language-py">torch.linspace(start, end, steps=100, out=None) → Tensor
</code></pre>
<p>返回 <code>start</code> 和 <code>end</code> 之间等间隔 <code>steps</code> 点的一维 Tensor.</p>
<p>输出 是尺寸 <code>steps</code> 为一维 tensor</p>
<p>参数：</p>
<ul>
<li><code>start (float)</code> – 点集合的起始值</li>
<li><code>end (float)</code> – 点集合的结束值</li>
<li><code>steps (int)</code> – 在 <code>start</code> 和 <code>end</code> 之间的样本数</li>
<li><code>out (Tensor, 可选)</code> – 输出结果的 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.linspace(3, 10, steps=5)

 3.0000
 4.7500
 6.5000
 8.2500
 10.0000
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.linspace(-10, 10, steps=5)

-10
 -5
 0
 5
 10
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.linspace(start=-10, end=10, steps=5)

-10
 -5
 0
 5
 10
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.logspace(start, end, steps=100, out=None) → Tensor
</code></pre>
<p>返回一个在 <img alt="10^{start}" src="../img/tex-123da6df98ad3e045d7be9648881f7b7.gif" /> 和 <img alt="10^{end}" src="../img/tex-1a05cc8eee633a0f91a082916d31f96e.gif" /> 之间的对数间隔 <code>steps</code> 点的一维 Tensor</p>
<p>输出是长度为 <code>steps</code> 的一维 tensor</p>
<p>参数：</p>
<ul>
<li><code>start (float)</code> – 点集合的起始值</li>
<li><code>end (float)</code> – 点集合的结束值</li>
<li><code>steps (int)</code> – 在 <code>start</code> 和 <code>end</code> 之间的样本数</li>
<li><code>out (Tensor, 可选)</code> – 输出结果<code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.logspace(start=-10, end=10, steps=5)

 1.0000e-10
 1.0000e-05
 1.0000e+00
 1.0000e+05
 1.0000e+10
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.logspace(start=0.1, end=1.0, steps=5)

 1.2589
 2.1135
 3.5481
 5.9566
 10.0000
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.ones(*sizes, out=None) → Tensor
</code></pre>
<p>返回填充了标量值 <code>1</code> 的 Tensor, 其形状由可变参数 <code>sizes</code> 定义.</p>
<p>参数：</p>
<ul>
<li><code>sizes (int...)</code> – 一组定义输出 Tensor 形状的整数</li>
<li><code>out (Tensor, 可选)</code> – 输出结果 Tensor</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.ones(2, 3)

 1  1  1
 1  1  1
[torch.FloatTensor of size 2x3]

&gt;&gt;&gt; torch.ones(5)

 1
 1
 1
 1
 1
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.ones_like(input, out=None) → Tensor
</code></pre>
<p>返回一个用标量值 <code>1</code> 填充的张量, 大小与 <code>input</code> 相同.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入的大小将决定输出的大小.</li>
<li><code>out (Tensor, 可选)</code> – 输出结果 Tensor</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; input = torch.FloatTensor(2, 3)
&gt;&gt;&gt; torch.ones_like(input)

 1  1  1
 1  1  1
[torch.FloatTensor of size 2x3]

</code></pre>
<pre><code class="language-py">torch.arange(start=0, end, step=1, out=None) → Tensor
</code></pre>
<p>从 <code>start</code> 用步长为 <code>step</code> 开始, 间隔在 <code>[start, end)</code> 中的值返回大小层次为 <img alt="floor((end - start) / step)" src="../img/tex-11a8e3f324d6a7b187a0eb8b25d3926e.gif" /> 的一维 Tensor.</p>
<p>参数：</p>
<ul>
<li><code>start (float)</code> – 点集合的起始值</li>
<li><code>end (float)</code> – 点集合的结束值</li>
<li><code>step (float)</code> – 每对相邻点之间的间隔</li>
<li><code>out (Tensor, 可选)</code> – 输出结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.arange(5)

 0
 1
 2
 3
 4
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.arange(1, 4)

 1
 2
 3
[torch.FloatTensor of size 3]

&gt;&gt;&gt; torch.arange(1, 2.5, 0.5)

 1.0000
 1.5000
 2.0000
[torch.FloatTensor of size 3]

</code></pre>
<pre><code class="language-py">torch.range(start, end, step=1, out=None) → Tensor
</code></pre>
<p>返回一个在 <code>start</code> 到 <code>end</code> 并且步长为 <code>step</code> 的区间内, 大小为 <img alt="floor((end - start) / step) + 1" src="../img/tex-a8d4b9eb08b29e4455688db33c092ae9.gif" /> 为一维 Tensor. <code>step</code> 是 tensor 中两个值之间的差距. <img alt="x_{i+1} = x_i + step" src="../img/tex-b99fbae9badbed7f3e2e937599966cd4.gif" /></p>
<p>警告：</p>
<p>此功能已被弃用, 以支持 <code>torch.arange()</code>.</p>
<p>参数：</p>
<ul>
<li><code>start (float)</code> – 点集合的起始值</li>
<li><code>end (float)</code> – 点集合的结束值</li>
<li><code>step (float)</code> – 每对相邻点之间的间隔</li>
<li><code>out (Tensor, 可选)</code> – 输出结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.range(1, 4)

 1
 2
 3
 4
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.range(1, 4, 0.5)

 1.0000
 1.5000
 2.0000
 2.5000
 3.0000
 3.5000
 4.0000
[torch.FloatTensor of size 7]

</code></pre>
<pre><code class="language-py">torch.zeros(*sizes, out=None) → Tensor
</code></pre>
<p>返回填充了标量值为 <code>0</code> 的 Tensor, 其形状由可变参数 <code>sizes</code> 定义.</p>
<p>参数：</p>
<ul>
<li><code>sizes (int...)</code> – 定义输出 Tensor 形状的一组整数.</li>
<li><code>out (Tensor, 可选)</code> – 输出结果 Tensor</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.zeros(2, 3)

 0  0  0
 0  0  0
[torch.FloatTensor of size 2x3]

&gt;&gt;&gt; torch.zeros(5)

 0
 0
 0
 0
 0
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.zeros_like(input, out=None) → Tensor
</code></pre>
<p>返回一个用标量值 <code>0</code> 填充的 Tensor, 其大小与 <code>input</code> 相同.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入的大小将决定输出的大小.</li>
<li><code>out (Tensor, 可选)</code> – 输出结果 Tensor</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; input = torch.FloatTensor(2, 3)
&gt;&gt;&gt; torch.zeros_like(input)

 0  0  0
 0  0  0
[torch.FloatTensor of size 2x3]

</code></pre>
<h3 id="indexing-slicing-joining-mutating-ops">Indexing, Slicing, Joining, Mutating Ops (索引, 切片, 连接, 换位) 操作</h3>
<pre><code class="language-py">torch.cat(seq, dim=0, out=None) → Tensor
</code></pre>
<p>在给定维度上对输入的张量序列 <code>seq</code> 进行连接操作. 所有张量必须具有相同的形状(在 <code>cat</code> 维度中除外) 或为空.</p>
<p><code>torch.cat()</code> 可以看做是 <code>torch.split()</code> 和 <code>torch.chunk()</code> 的逆操作.</p>
<p><code>cat()</code> 可以通过下面的例子更好地理解.</p>
<p>参数：</p>
<ul>
<li><code>seq (_sequence of Tensors_)</code> – 可以是任何相同类型的 <code>Tensor</code> 的 Python 序列.</li>
<li><code>dim (int, 可选)</code> – tensors 级联的维数</li>
<li><code>out (Tensor, 可选)</code> – 输出参数</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(2, 3)
&gt;&gt;&gt; x

 0.5983 -0.0341  2.4918
 1.5981 -0.5265 -0.8735
[torch.FloatTensor of size 2x3]

&gt;&gt;&gt; torch.cat((x, x, x), 0)

 0.5983 -0.0341  2.4918
 1.5981 -0.5265 -0.8735
 0.5983 -0.0341  2.4918
 1.5981 -0.5265 -0.8735
 0.5983 -0.0341  2.4918
 1.5981 -0.5265 -0.8735
[torch.FloatTensor of size 6x3]

&gt;&gt;&gt; torch.cat((x, x, x), 1)

 0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918
 1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735
[torch.FloatTensor of size 2x9]

</code></pre>
<pre><code class="language-py">torch.chunk(tensor, chunks, dim=0)
</code></pre>
<p>在给定维度(轴)上将输入张量进行分块处理.</p>
<p>参数：</p>
<ul>
<li><code>tensor (Tensor)</code> – 待分块的输入张量.</li>
<li><code>chunks (int)</code> – 要返回的分块的个数.</li>
<li><code>dim (int)</code> – 切分张量所需要沿着的维度.</li>
</ul>
<pre><code class="language-py">torch.gather(input, dim, index, out=None) → Tensor
</code></pre>
<p>沿给定轴 <code>dim</code> ,将输入索引张量 <code>index</code> 指定位置的值进行聚合.</p>
<p>对一个 3 维张量,输出可以定义为:</p>
<pre><code class="language-py">out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0
out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1
out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2

</code></pre>
<p>如果 <code>input</code> 是 size 为 <img alt="(x_0, x_1..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})" src="../img/tex-b2b722f612a0a739ffabe888b56158d5.gif" /> 且 <code>dim</code> = i 的 n 维张量,则 <code>index</code> 必须是具有 size 为 <img alt="(x_0, x_1, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})" src="../img/tex-07123a18476a076323dd412ea5acc56c.gif" /> 的 n 维张量,其中 y &gt;= 1 ,并且 <code>out</code> 将与 <code>index</code> 的 size 相同.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 源张量</li>
<li><code>dim (int)</code> – 索引的轴</li>
<li><code>index (LongTensor)</code> – 聚合元素的下标</li>
<li><code>out (Tensor, 可选)</code> – 目标张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; t = torch.Tensor([[1,2],[3,4]])
&gt;&gt;&gt; torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]]))
 1  1
 4  3
[torch.FloatTensor of size 2x2]

</code></pre>
<pre><code class="language-py">torch.index_select(input, dim, index, out=None) → Tensor
</code></pre>
<p>沿着指定维度 <code>dim</code> 对输入进行切片,取 <code>index</code> 中指定的相应项 ( <code>index</code> 为一个 <code>LongTensor</code> ),然后返回到一个新的张量.</p>
<blockquote>
<p>返回的张量与原始张量 <code>Tensor</code> 有相同的维度(在指定轴上).</p>
</blockquote>
<p>注解：</p>
<p>返回的张量不与原始张量共享内存空间.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>dim (int)</code> – 索引的轴</li>
<li><code>index (LongTensor)</code> – 包含索引下标的一维张量</li>
<li><code>out (Tensor, 可选)</code> – 输出参数/目标张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(3, 4)
&gt;&gt;&gt; x

 1.2045  2.4084  0.4001  1.1372
 0.5596  1.5677  0.6219 -0.7954
 1.3635 -1.2313 -0.5414 -1.8478
[torch.FloatTensor of size 3x4]

&gt;&gt;&gt; indices = torch.LongTensor([0, 2])
&gt;&gt;&gt; torch.index_select(x, 0, indices)

 1.2045  2.4084  0.4001  1.1372
 1.3635 -1.2313 -0.5414 -1.8478
[torch.FloatTensor of size 2x4]

&gt;&gt;&gt; torch.index_select(x, 1, indices)

 1.2045  0.4001
 0.5596  0.6219
 1.3635 -0.5414
[torch.FloatTensor of size 3x2]

</code></pre>
<pre><code class="language-py">torch.masked_select(input, mask, out=None) → Tensor
</code></pre>
<p>根据掩码张量 <code>mask</code> 中的二元值,取输入张量中的指定项 ( <code>mask</code> 为一个 <code>ByteTensor</code> ),将取值返回到一个新的一维张量.</p>
<p>张量 <code>mask</code> 与 <code>input</code> 的 shape 或维度不需要相同,但是他们必须是 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> .</p>
<p>注解：</p>
<p>返回的张量不与原始张量共享内存空间.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>mask (ByteTensor)</code> – 掩码张量,包含了二元索引值</li>
<li><code>out (Tensor, 可选)</code> – 输出参数/目标张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(3, 4)
&gt;&gt;&gt; x

 1.2045  2.4084  0.4001  1.1372
 0.5596  1.5677  0.6219 -0.7954
 1.3635 -1.2313 -0.5414 -1.8478
[torch.FloatTensor of size 3x4]

&gt;&gt;&gt; mask = x.ge(0.5)
&gt;&gt;&gt; mask

 1  1  0  1
 1  1  1  0
 1  0  0  0
[torch.ByteTensor of size 3x4]

&gt;&gt;&gt; torch.masked_select(x, mask)

 1.2045
 2.4084
 1.1372
 0.5596
 1.5677
 0.6219
 1.3635
[torch.FloatTensor of size 7]

</code></pre>
<pre><code class="language-py">torch.nonzero(input, out=None) → LongTensor
</code></pre>
<p>返回一个包含输入 <code>input</code> 中非零元素索引的张量. 输出张量中的每行包含 <code>input</code> 中非零元素的索引.</p>
<p>如果输入张量 <code>input</code> 有 <code>n</code> 维,则输出的索引张量 <code>out</code> 的 size 为 <code>z x n</code> , 这里 <code>z</code> 是输入张量 <code>input</code> 中所有非零元素的个数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量/源张量</li>
<li><code>out (LongTensor, 可选)</code> – 包含索引值的输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.nonzero(torch.Tensor([1, 1, 1, 0, 1]))

 0
 1
 2
 4
[torch.LongTensor of size 4x1]

&gt;&gt;&gt; torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0],
...                             [0.0, 0.4, 0.0, 0.0],
...                             [0.0, 0.0, 1.2, 0.0],
...                             [0.0, 0.0, 0.0,-0.4]]))

 0  0
 1  1
 2  2
 3  3
[torch.LongTensor of size 4x2]

</code></pre>
<pre><code class="language-py">torch.split(tensor, split_size, dim=0)
</code></pre>
<p>将输入张量分割成相等 size 的 chunks (如果可分).</p>
<p>如果沿指定维的张量形状大小不能被 <code>split_size</code> 整分, 则最后一个分块会小于其它分块.</p>
<p>参数：</p>
<ul>
<li><code>tensor (Tensor)</code> – 待分割张量.</li>
<li><code>split_size (int)</code> – 单个分块的 size 大小.</li>
<li><code>dim (int)</code> – 沿着此维进行分割.</li>
</ul>
<pre><code class="language-py">torch.squeeze(input, dim=None, out=None)
</code></pre>
<p>将 <code>input</code> 张量 size 中的 <code>1</code> 去除并返回.</p>
<p>如果 <code>input</code> 的 shape 如 <img alt="(A x 1 x B x C x 1 x D)" src="../img/tex-1869e4162adae0b82c80adec1915082e.gif" /> ,那么输出 shape 就为: <img alt="(A x B x C x D)" src="../img/tex-22bdd4f99e29b716e084e048da31a1bb.gif" /></p>
<p>当给定 <code>dim</code> 时,那么挤压操作只在给定维度上.例如, <code>input</code> 的 shape 为: <img alt="(A x 1 x B)" src="../img/tex-b06a8b322f4713a58fe712d57c9ceda0.gif" /> , <code>squeeze(input, 0)</code> 将会保持张量不变,只有用 <code>squeeze(input, 1)</code> , shape 会变成 <img alt="(A x B)" src="../img/tex-c6d3e8cfc2d4f7d1ef61fc25eb14f67f.gif" /> .</p>
<p>注解：</p>
<p>作为上述的一个例外,size 为 1 的一维张量不会改变维度.</p>
<p>注解：</p>
<p>返回张量与输入张量共享内存,所以改变其中一个的内容会改变另一个.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>dim (int, 可选)</code> – 如果给定 <code>dim</code> 时,则 <code>input</code> 只会在给定维度执行挤压</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.zeros(2,1,2,1,2)
&gt;&gt;&gt; x.size()
(2L, 1L, 2L, 1L, 2L)
&gt;&gt;&gt; y = torch.squeeze(x)
&gt;&gt;&gt; y.size()
(2L, 2L, 2L)
&gt;&gt;&gt; y = torch.squeeze(x, 0)
&gt;&gt;&gt; y.size()
(2L, 1L, 2L, 1L, 2L)
&gt;&gt;&gt; y = torch.squeeze(x, 1)
&gt;&gt;&gt; y.size()
(2L, 2L, 1L, 2L)

</code></pre>
<pre><code class="language-py">torch.stack(sequence, dim=0, out=None)
</code></pre>
<p>沿着一个新维度对输入张量序列进行连接.</p>
<p>序列中所有的张量都应该为相同 size .</p>
<p>参数：</p>
<ul>
<li><code>sequence (_Sequence_)</code> – 待连接的张量序列.</li>
<li><code>dim (int)</code> – 插入的维度.必须介于 0 与待连接的张量序列数(包含）之间.</li>
</ul>
<pre><code class="language-py">torch.t(input, out=None) → Tensor
</code></pre>
<p>预期 <code>input</code> 为一个矩阵 (2 维张量), 并转置 0, 1 维.</p>
<p>可以被视为函数 <code>transpose(input, 0, 1)</code> 的简写函数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(2, 3)
&gt;&gt;&gt; x

 0.4834  0.6907  1.3417
-0.1300  0.5295  0.2321
[torch.FloatTensor of size 2x3]

&gt;&gt;&gt; torch.t(x)

 0.4834 -0.1300
 0.6907  0.5295
 1.3417  0.2321
[torch.FloatTensor of size 3x2]

</code></pre>
<pre><code class="language-py">torch.take(input, indices) → Tensor
</code></pre>
<p>在给定的索引处返回一个新的 <code>Tensor</code> ,其元素为 <code>input</code> . 输入张量被看作是一维张量.结果与索引具有相同的 shape .</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>indices (LongTensor)</code> – 进入 <code>Tensor</code> 的索引</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; src = torch.Tensor([[4, 3, 5],
...                     [6, 7, 8]])
&gt;&gt;&gt; torch.take(src, torch.LongTensor([0, 2, 5]))
 4
 5
 8
[torch.FloatTensor of size 3]

</code></pre>
<pre><code class="language-py">torch.transpose(input, dim0, dim1, out=None) → Tensor
</code></pre>
<p>返回输入矩阵 <code>input</code> 的转置.交换给定维度 <code>dim0</code> 和 <code>dim1</code> .</p>
<p><code>out</code> 张量与 <code>input</code> 张量共享内存,所以改变其中一个会导致另外一个也被修改.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>dim0 (int)</code> – 转置的第一个维度</li>
<li><code>dim1 (int)</code> – 转置的第二个维度</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(2, 3)
&gt;&gt;&gt; x

 0.5983 -0.0341  2.4918
 1.5981 -0.5265 -0.8735
[torch.FloatTensor of size 2x3]

&gt;&gt;&gt; torch.transpose(x, 0, 1)

 0.5983  1.5981
-0.0341 -0.5265
 2.4918 -0.8735
[torch.FloatTensor of size 3x2]

</code></pre>
<pre><code class="language-py">torch.unbind(tensor, dim=0)
</code></pre>
<p>移除一个张量的维度.</p>
<p>移除指定维后,返回一个元组,包含了沿着指定维切片后的各个切片 (已经没有了移除的维度).</p>
<p>参数：</p>
<ul>
<li><code>tensor (Tensor)</code> – 要执行 unbind 的张量/输入张量.</li>
<li><code>dim (int)</code> – 要移除的维度.</li>
</ul>
<pre><code class="language-py">torch.unsqueeze(input, dim, out=None)
</code></pre>
<p>返回在指定位置插入维度 size 为 1 的新张量.</p>
<p>返回张量与输入张量共享内存,所以改变其中一个的内容会改变另一个.</p>
<p>如果 <code>dim</code> 为负,则将会被转化 <img alt="dim + input.dim() + 1" src="../img/tex-722443b33cb36edca0e69759f3fa99de.gif" /> .</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>dim (int)</code> – 插入维度的索引</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.Tensor([1, 2, 3, 4])
&gt;&gt;&gt; torch.unsqueeze(x, 0)
 1  2  3  4
[torch.FloatTensor of size 1x4]
&gt;&gt;&gt; torch.unsqueeze(x, 1)
 1
 2
 3
 4
[torch.FloatTensor of size 4x1]

</code></pre>
<h2 id="random-sampling">Random sampling (随机采样)</h2>
<pre><code class="language-py">torch.manual_seed(seed)
</code></pre>
<p>设置生成随机数的种子,并返回一个 <code>torch._C.Generator</code> 对象.</p>
<p>参数：<code>seed (int 或 long)</code> – 种子.</p>
<pre><code class="language-py">torch.initial_seed()
</code></pre>
<p>返回用于生成随机数字的初始种子 (python <code>long</code>) .</p>
<pre><code class="language-py">torch.get_rng_state()
</code></pre>
<p>以ByteTensor的形式返回随机数发生器的状态.</p>
<pre><code class="language-py">torch.set_rng_state(new_state)
</code></pre>
<p>设置随机数发生器的参数.</p>
<p>参数：<code>new_state (torch.ByteTensor)</code> – 理想状态</p>
<p><code>torch.default_generator = &lt;torch._C.Generator object at 0x28bcc10&gt;</code></p>
<pre><code class="language-py">torch.bernoulli(input, out=None) → Tensor
</code></pre>
<p>从伯努利分布中抽取二进制随机数 (0 或 1).</p>
<p>The <code>input</code> 张量包含用于抽取二进制随机数的概率. 因此, <code>input</code> 中的所有值必须在这个范围内: <img alt="0 &lt;= input_i &lt;= 1" src="../img/tex-bd58cbf26356be324cc21216b3557822.gif" /></p>
<p>根据 <code>input</code> 张量第 <code>i</code> 个概率值, 输出张量的第 <code>i</code> 个元素将取值为1.</p>
<p>返回的 <code>out</code> 张量的值只有 0 或者 1 并且大小与 <code>input</code> 张量相同.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 伯努利分布的概率值</li>
<li><code>out (Tensor, 可选)</code> – 输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.Tensor(3, 3).uniform_(0, 1) # generate a uniform random matrix with range [0, 1]
&gt;&gt;&gt; a

 0.7544  0.8140  0.9842
 0.5282  0.0595  0.6445
 0.1925  0.9553  0.9732
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.bernoulli(a)

 1  1  1
 0  0  1
 0  1  1
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; a = torch.ones(3, 3) # probability of drawing &quot;1&quot; is 1
&gt;&gt;&gt; torch.bernoulli(a)

 1  1  1
 1  1  1
 1  1  1
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; a = torch.zeros(3, 3) # probability of drawing &quot;1&quot; is 0
&gt;&gt;&gt; torch.bernoulli(a)

 0  0  0
 0  0  0
 0  0  0
[torch.FloatTensor of size 3x3]

</code></pre>
<pre><code class="language-py">torch.multinomial(input, num_samples, replacement=False, out=None) → LongTensor
</code></pre>
<p>返回一个张量, 其中每一行包含在 <code>input</code> 张量对应行中多项式分布取样的 <code>num_samples</code> 索引.</p>
<p>注解：</p>
<p><code>input</code> 的每行值不需要总和为 1 (我们只使用这些值作为权重), 但必须是非负且非零和的.</p>
<p>取样时从左向右排列(第一个样本在第一列).</p>
<p>如果 <code>input</code> 是一个向量, 则 <code>out</code> 是一个大小为 <code>num_samples</code> 的向量.</p>
<p>如果 <code>input</code> 是一个 <code>m</code> 行的矩阵, 则 <code>out</code> 是一个 <code>m * n</code> 的矩阵.</p>
<p>如果参数 <code>replacement</code> 是 <code>True</code>, 则可重复取样. 否则, 样本在每行不能被重复取样.</p>
<p>参数 <code>num_samples</code> 必须小于 <code>input</code> 长度 (如果是一个矩阵, 则是 <code>input</code> 的列数).</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 包含概率值的张量</li>
<li><code>num_samples (int)</code> – 抽取的样本数</li>
<li><code>replacement (bool, 可选)</code> – 是否重复抽取样本</li>
<li><code>out (Tensor, 可选)</code> – 输出 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; weights = torch.Tensor([0, 10, 3, 0]) # create a Tensor of weights
&gt;&gt;&gt; torch.multinomial(weights, 4)

 1
 2
 0
 0
[torch.LongTensor of size 4]

&gt;&gt;&gt; torch.multinomial(weights, 4, replacement=True)

 1
 2
 1
 2
[torch.LongTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.normal()
</code></pre>
<pre><code class="language-py">torch.normal(means, std, out=None)
</code></pre>
<p>返回一个随机数张量, 随机数从给定平均值和标准差的离散正态分布中抽取.</p>
<p>参数 <code>means</code> 是一个包含每个输出元素的正态分布均值的张量.</p>
<p>参数 <code>std</code> 是一个包含每个输出元素的正态分布标准差的张量.</p>
<p>其中 <code>means</code> 和 <code>std</code> 的形状不需要匹配, 但是每个张量中的元素总数需要相同.</p>
<p>注解：</p>
<p>当形状不匹配时, <code>means</code> 的形状将作为返回输出张量的形状.</p>
<p>参数：</p>
<ul>
<li><code>means (Tensor)</code> – 均值</li>
<li><code>std (Tensor)</code> – 标准差</li>
<li><code>out (Tensor, 可选)</code> – 输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">torch.normal(means=torch.arange(1, 11), std=torch.arange(1, 0, -0.1))

 1.5104
 1.6955
 2.4895
 4.9185
 4.9895
 6.9155
 7.3683
 8.1836
 8.7164
 9.8916
[torch.FloatTensor of size 10]

</code></pre>
<pre><code class="language-py">torch.normal(mean=0.0, std, out=None)
</code></pre>
<p>功能与上面函数类似, 但所有被抽取的元素共享均值.</p>
<p>参数：</p>
<ul>
<li><code>means (float, 可选)</code> – 所有分布的均值</li>
<li><code>std (Tensor)</code> – 每个元素标准差的张量</li>
<li><code>out (Tensor, 可选)</code> – 输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.normal(mean=0.5, std=torch.arange(1, 6))

 0.5723
 0.0871
 -0.3783
 -2.5689
 10.7893
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.normal(means, std=1.0, out=None)
</code></pre>
<p>功能与上面函数类似, 但所有被抽取的元素共享标准差.</p>
<p>参数：</p>
<ul>
<li><code>means (Tensor)</code> – 每个元素均值的张量</li>
<li><code>std (float, 可选)</code> – 所有分布的标准差</li>
<li><code>out (Tensor, 可选)</code> – 输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.normal(means=torch.arange(1, 6))

 1.1681
 2.8884
 3.7718
 2.5616
 4.2500
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.rand(*sizes, out=None) → Tensor
</code></pre>
<p>在区间 ![<a href="../img/tex-b9d1ea90e68d51c01a351d857cc16e0c.gif">0, 1)</a> 中, 返回一个填充了均匀分布的随机数的张量.</p>
<p>这个张量的形状由可变参数 <code>sizes</code> 来定义.</p>
<p>参数：</p>
<ul>
<li><code>sizes (int...)</code> – 定义输出张量形状的整数集.</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.rand(4)

 0.9193
 0.3347
 0.3232
 0.7715
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.rand(2, 3)

 0.5010  0.5140  0.0719
 0.1435  0.5636  0.0538
[torch.FloatTensor of size 2x3]

</code></pre>
<pre><code class="language-py">torch.randn(*sizes, out=None) → Tensor
</code></pre>
<p>返回一个从正态分布中填充随机数的张量, 其均值为 0 , 方差为 1 .</p>
<p>这个张量的形状被可变参数 <code>sizes</code> 定义.</p>
<p>参数：</p>
<ul>
<li><code>sizes (int...)</code> – 定义输出张量形状的整数集.</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.randn(4)

-0.1145
 0.0094
-1.1717
 0.9846
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.randn(2, 3)

 1.4339  0.3351 -1.0999
 1.5458 -0.9643 -0.3558
[torch.FloatTensor of size 2x3]

</code></pre>
<pre><code class="language-py">torch.randperm(n, out=None) → LongTensor
</code></pre>
<p>返回一个从 <code>0</code> to <code>n - 1</code> 的整数的随机排列.</p>
<p>参数：<code>n (int)</code> – 上限 (唯一的)</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.randperm(4)

 2
 1
 3
 0
[torch.LongTensor of size 4]

</code></pre>
<h3 id="in-place-random-sampling">In-place random sampling (直接随机采样)</h3>
<p>在Tensors模块上还定义了许多 in-place 随机采样函数,可以点击参考它们的文档:</p>
<ul>
<li><code>torch.Tensor.bernoulli_()</code>](tensors.html#torch.Tensor.bernoulli_ "torch.Tensor.bernoulli_") - 是 [<code>torch.bernoulli()</code> 的 in-place 版本</li>
<li><a href="tensors.html#torch.Tensor.cauchy_" title="torch.Tensor.cauchy_"><code>torch.Tensor.cauchy_()</code></a> - 从柯西分布中抽取数字</li>
<li><a href="tensors.html#torch.Tensor.exponential_" title="torch.Tensor.exponential_"><code>torch.Tensor.exponential_()</code></a> - 从指数分布中抽取数字</li>
<li><a href="tensors.html#torch.Tensor.geometric_" title="torch.Tensor.geometric_"><code>torch.Tensor.geometric_()</code></a> - 从几何分布中抽取元素</li>
<li><a href="tensors.html#torch.Tensor.log_normal_" title="torch.Tensor.log_normal_"><code>torch.Tensor.log_normal_()</code></a> - 对数正态分布中的样本</li>
<li><code>torch.Tensor.normal_()</code>](tensors.html#torch.Tensor.normal_ "torch.Tensor.normal_") - 是 [<code>torch.normal()</code> 的 in-place 版本</li>
<li><a href="tensors.html#torch.Tensor.random_" title="torch.Tensor.random_"><code>torch.Tensor.random_()</code></a> - 离散均匀分布中采样的数字</li>
<li><a href="tensors.html#torch.Tensor.uniform_" title="torch.Tensor.uniform_"><code>torch.Tensor.uniform_()</code></a> - 正态分布中采样的数字</li>
</ul>
<h2 id="serialization">Serialization (序列化)</h2>
<pre><code class="language-py">torch.save(obj, f, pickle_module=&lt;module 'cPickle' from '/usr/lib64/python2.7/lib-dynload/cPickle.so'&gt;, pickle_protocol=2)
</code></pre>
<p>将一个对象保存到一个磁盘文件中.</p>
<p>另见: <a href="notes/serialization.html#recommend-saving-models">保存模型的推荐方法</a></p>
<p>参数: obj: 要保存的对象 f: 类文件对象 (必须实现返回文件描述符的 fileno 方法) 或包含文件名的字符串 pickle_module: 用于 pickling 元数据和对象的模块 pickle_protocol: 可以指定来覆盖默认协议</p>
<pre><code class="language-py">torch.load(f, map_location=None, pickle_module=&lt;module 'cPickle' from '/usr/lib64/python2.7/lib-dynload/cPickle.so'&gt;)
</code></pre>
<p>从磁盘文件中加载一个用 <code>torch.save()</code> 保存的对象.</p>
<table>
<thead>
<tr>
<th>Func:</th>
<th><code>torch.load</code> 使用 Python 的解封 (unpickling) 设施, 但特殊对待张量下的存储 (storages).</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>它们首先在 CPU 上反序列化, 然后移动到所保存的设备上. 如果这个过程失败了 (例如, 因为运行时的系统没有确定的设备), 将会抛出异常. 然而, 使用 map_location 参数, 存储可以被动态地重新映射到另一组设备上.</p>
<p>如果 map_location 是可调用对象, 则对于每个序列化存储, 它都将以两个参数调用一次: storage 和 location. 参数 storage 是驻留在 CPU 上的存储的初始反序列化. 每个序列化后的存储都有一个与之关联的位置标签, 它标识了保存它的设备, 而此标签是传递给 map_location 的第二个参数. 对于 CPU 张量, 内建的位置标签是 'cpu', 对于 CUDA 张量, 内建的位置标签是 'cuda:device_id' (例如 'cuda:2'). map_location 要么返回 None , 要么返回一个存储. 如果 map_location 返回存储, 它将用作已移动到正确设备上的, 最终反序列化的对象. 否则, 如果没有指明 map_location, 即返回 None, <code>torch.load</code> 会回落到默认的行为.</p>
<p>如果 map_location 是一个字典, 它用于将出现在文件 (键) 中的位置标签, 重新映射到另一个位置标签, 它出现在值中并指明在哪里存放存储.</p>
<p>用户扩展可以使用 register_package 来注册他们自己的位置标签, 以及标记和反序列化方法.</p>
<p>参数: f: 一个类文件对象 (必须实现返回文件描述符的 fileno, 以及 seek 方法), 或者包含文件名的字符串. map_location: 一个函数或者一个指明如何重新映射存储位置的字典 pickle_module: 用于解封 (unpickling) 元数据和对象的模块 (必须匹配用于序列化文件的 pickle_module) 示例:</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.load('tensors.pt')
# Load all tensors onto the CPU
&gt;&gt;&gt; torch.load('tensors.pt', map_location=lambda storage, loc: storage)
# Load all tensors onto GPU 1
&gt;&gt;&gt; torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))
# Map tensors from GPU 1 to GPU 0
&gt;&gt;&gt; torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})

</code></pre>
<h2 id="parallelism">Parallelism (并行化)</h2>
<pre><code class="language-py">torch.get_num_threads() → int
</code></pre>
<p>获得 OpenMP 并行化操作的线程数目</p>
<pre><code class="language-py">torch.set_num_threads(int)
</code></pre>
<p>设置 OpenMP 并行化操作的线程数目</p>
<h2 id="math-operations">Math operations (数学操作)</h2>
<h3 id="pointwise-ops">Pointwise Ops (逐点操作)</h3>
<pre><code class="language-py">torch.abs(input, out=None) → Tensor
</code></pre>
<p>计算给定 <code>input</code> 张量的元素的绝对值.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.abs(torch.FloatTensor([-1, -2, 3]))
FloatTensor([1, 2, 3])

</code></pre>
<pre><code class="language-py">torch.acos(input, out=None) → Tensor
</code></pre>
<p>用 <code>input</code> 元素的反余弦返回一个新的张量.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – the input <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – The result <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.acos(a)
 2.2608
 1.2956
 1.1075
 nan
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.add()
</code></pre>
<pre><code class="language-py">torch.add(input, value, out=None)
</code></pre>
<p>将标量值 <code>value</code> 添加到输入张量 attr:<code>input</code> 的每个元素并返回一个新的结果张量.</p>
<p><img alt="out = tensor + value" src="../img/tex-ac47755bc8dea983c6ad7c80c4581151.gif" /></p>
<p>如果输入张量 <code>input</code> 是 FloatTensor 或者 DoubleTensor 类型, 则 <code>value</code> 必须为实数, 否则为整数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>value (Number)</code> – 要添加到 <code>input</code> 每个元素的数</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 0.4050
-1.2227
 1.8688
-0.4185
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.add(a, 20)

 20.4050
 18.7773
 21.8688
 19.5815
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.add(input, value=1, other, out=None)
</code></pre>
<p>张量 <code>other</code> 的每个元素乘以标量值 <code>value</code> 并加到张量 <code>input</code> 上, 返回生成的张量 <code>out</code> .</p>
<p>张量 <code>input</code> 的形状与张量 <code>other</code> 的形状必须 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p><img alt="out = input + (other * value)" src="../img/tex-b0c1f202403038a0ada5db34d989338a.gif" /></p>
<p>如果张量 <code>other</code> 是 FloatTensor 或者 DoubleTensor 类型, 则 <code>value</code> 必须为实数, 否则为整数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 第一个输入 <code>Tensor</code></li>
<li><code>value (Number)</code> – 张量 <code>other</code> 的标量乘数</li>
<li><code>other (Tensor)</code> – 第二个输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; import torch
&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

-0.9310
 2.0330
 0.0852
-0.2941
[torch.FloatTensor of size 4]

&gt;&gt;&gt; b = torch.randn(2, 2)
&gt;&gt;&gt; b

 1.0663  0.2544
-0.1513  0.0749
[torch.FloatTensor of size 2x2]

&gt;&gt;&gt; torch.add(a, 10, b)
 9.7322
 4.5770
-1.4279
 0.4552
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None) → Tensor
</code></pre>
<p>将张量 <code>tensor1</code> 逐元素除以张量 <code>tensor2</code>, 然后乘以标量值 <code>value</code> 并加到张量 <code>tensor</code> 上.</p>
<p>张量 <code>tensor</code>, 张量 <code>tensor1</code>, 张量 <code>tensor2</code> 的形状必须 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>对于类型为 <code>FloatTensor</code> 或者 <code>DoubleTensor</code> 的张量输入, <code>value</code> 必须为实数, 否则为整数.</p>
<p>参数：</p>
<ul>
<li><code>tensor (Tensor)</code> – 张量, 对 <code>tensor1 ./ tensor2</code> 进行相加</li>
<li><code>value (Number, 可选)</code> – 标量, 对 <code>tensor1 ./ tensor2</code> 进行相乘</li>
<li><code>tensor1 (Tensor)</code> – 分子张量, 即作为被除数</li>
<li><code>tensor2 (Tensor)</code> – 分母张量, 即作为除数</li>
<li><code>out (Tensor, 可选)</code> – 输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; t = torch.randn(2, 3)
&gt;&gt;&gt; t1 = torch.randn(1, 6)
&gt;&gt;&gt; t2 = torch.randn(6, 1)
&gt;&gt;&gt; torch.addcdiv(t, 0.1, t1, t2)

 0.0122 -0.0188 -0.2354
 0.7396 -1.5721  1.2878
[torch.FloatTensor of size 2x3]

</code></pre>
<pre><code class="language-py">torch.addcmul(tensor, value=1, tensor1, tensor2, out=None) → Tensor
</code></pre>
<p>将张量 <code>tensor1</code> 逐元素与张量 <code>tensor2</code> 相乘, 然后乘以标量值 <code>value</code> 并加到张量 <code>tensor</code> 上.</p>
<p>张量 <code>tensor</code>, 张量 <code>tensor1</code>, 张量 <code>tensor2</code> 的形状必须 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>对于类型为 <code>FloatTensor</code> 或者 <code>DoubleTensor</code> 的张量输入, <code>value</code> 必须为实数, 否则为整数. :param tensor: 张量, 对 <code>tensor1 .* tensor2</code> 进行相加 :type tensor: Tensor :param value: 标量, 对 <code>tensor1 .* tensor2</code> 进行相乘 :type value: Number, 可选 :param tensor1: 张量, 作为乘子1 :type tensor1: Tensor :param tensor2: 张量, 作为乘子2 :type tensor2: Tensor :param out: 输出张量 :type out: Tensor, 可选</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; t = torch.randn(2, 3)
&gt;&gt;&gt; t1 = torch.randn(1, 6)
&gt;&gt;&gt; t2 = torch.randn(6, 1)
&gt;&gt;&gt; torch.addcmul(t, 0.1, t1, t2)

 0.0122 -0.0188 -0.2354
 0.7396 -1.5721  1.2878
[torch.FloatTensor of size 2x3]

</code></pre>
<pre><code class="language-py">torch.asin(input, out=None) → Tensor
</code></pre>
<p>返回一个新的 <code>Tensor</code> , 其元素为张量 <code>input</code> 的每个元素的反正弦.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.asin(a)
-0.6900
 0.2752
 0.4633
 nan
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.atan(input, out=None) → Tensor
</code></pre>
<p>返回一个新的 <code>Tensor</code> , 其元素为张量 <code>input</code> 的每个元素的反正切.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.atan(a)
-0.5669
 0.2653
 0.4203
 0.9196
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.atan2(input1, input2, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是输入张量 <code>input1</code> 和输入张量 <code>input2</code> 元素的反正切.</p>
<p>输入张量 <code>input1</code> 的形状和输入张量 <code>input2</code> 的形状必须可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>参数：</p>
<ul>
<li><code>input1 (Tensor)</code> – 第一个输入 <code>Tensor</code></li>
<li><code>input2 (Tensor)</code> – 第二个输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.atan2(a, torch.randn(4))
-2.4167
 2.9755
 0.9363
 1.6613
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.ceil(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 的元素向上取整(取不小于每个元素的最小整数).</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.ceil(a)

 2
 1
-0
-0
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.clamp(input, min, max, out=None) → Tensor
</code></pre>
<p>将输入张量 <code>input</code> 所有元素限制在区间 <code>[min, max]</code> 中并返回一个结果张量.</p>
<pre><code class="language-py">      | min, if x_i &lt; min
y_i = | x_i, if min &lt;= x_i &lt;= max
      | max, if x_i &gt; max

</code></pre>
<p>如果输入张量 <code>input</code> 的类型 <code>FloatTensor</code> 或者 <code>DoubleTensor</code>, 那么参数 <code>min</code> 和 <code>max</code> 必须为实数, 否则为整数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>min (Number)</code> – 限制范围下限</li>
<li><code>max (Number)</code> – 限制范围上限</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.clamp(a, min=-0.5, max=0.5)

 0.5000
 0.3912
-0.5000
-0.5000
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.clamp(input, *, min, out=None) → Tensor
</code></pre>
<p>张量 <code>input</code> 的所有元素值大于或者等于 <code>min</code>.</p>
<p>如果张量 <code>input</code> 的类型是 <code>FloatTensor</code> 或者 <code>DoubleTensor</code>, 则 <code>value</code> 必须是实数, 否则应该是整数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>value (Number)</code> – 输出中每个元素的最小值</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.clamp(a, min=0.5)

 1.3869
 0.5000
 0.5000
 0.5000
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.clamp(input, *, max, out=None) → Tensor
</code></pre>
<p>张量 <code>input</code> 的所有元素值小于或者等于 <code>max</code>.</p>
<p>如果张量 <code>input</code> 的类型是 <code>FloatTensor</code> 或者 <code>DoubleTensor</code>, 则 <code>value</code> 必须是实数, 否则应该是整数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>value (Number)</code> – 输出中每个元素的最大值</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.clamp(a, max=0.5)

 0.5000
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.cos(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 每个元素的余弦.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.cos(a)
 0.8041
 0.9633
 0.9018
 0.2557
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.cosh(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 每个元素的双曲余弦.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.cosh(a)
 1.2095
 1.0372
 1.1015
 1.9917
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.div()
</code></pre>
<pre><code class="language-py">torch.div(input, value, out=None)
</code></pre>
<p>将张量 <code>input</code> 的元素逐一除以标量值 <code>value</code> , 其结果作为一个新的张量返回.</p>
<p><img alt="out = tensor / value" src="../img/tex-4e40d7ead3c8f578a1b7b071ed53489b.gif" /></p>
<p>如果张量 <code>input</code> 的类型是 <code>FloatTensor</code> 或者 <code>DoubleTensor</code>, 则标量值 <code>value</code> 必须是实数, 否则应该是整数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>value (Number)</code> – 除数, 被张量 <code>input</code> 的元素除</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(5)
&gt;&gt;&gt; a

-0.6147
-1.1237
-0.1604
-0.6853
 0.1063
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.div(a, 0.5)

-1.2294
-2.2474
-0.3208
-1.3706
 0.2126
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.div(input, other, out=None)
</code></pre>
<p>张量 <code>input</code> 的元素与张量 <code>other</code> 的元素逐一相除. 返回一个新的结果张量 <code>out</code> . 张量 <code>input</code> 与张量 <code>other</code> 的形状必须可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p><img alt="out_i = input_i / other_i" src="../img/tex-56a7e74c24c6530b63af32b9792a1775.gif" /></p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 分子 <code>Tensor</code> (被除数)</li>
<li><code>other (Tensor)</code> – 分母 <code>Tensor</code> (除数)</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4,4)
&gt;&gt;&gt; a

-0.1810  0.4017  0.2863 -0.1013
 0.6183  2.0696  0.9012 -1.5933
 0.5679  0.4743 -0.0117 -0.1266
-0.1213  0.9629  0.2682  1.5968
[torch.FloatTensor of size 4x4]

&gt;&gt;&gt; b = torch.randn(8, 2)
&gt;&gt;&gt; b

 0.8774  0.7650
 0.8866  1.4805
-0.6490  1.1172
 1.4259 -0.8146
 1.4633 -0.1228
 0.4643 -0.6029
 0.3492  1.5270
 1.6103 -0.6291
[torch.FloatTensor of size 8x2]

&gt;&gt;&gt; torch.div(a, b)

-0.2062  0.5251  0.3229 -0.0684
-0.9528  1.8525  0.6320  1.9559
 0.3881 -3.8625 -0.0253  0.2099
-0.3473  0.6306  0.1666 -2.5381
[torch.FloatTensor of size 4x4]

</code></pre>
<pre><code class="language-py">torch.erf(tensor, out=None) → Tensor
</code></pre>
<p>计算每个元素的误差函数.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.erf(torch.Tensor([0, -1., 10.]))
torch.FloatTensor([0., -0.8427, 1.])

</code></pre>
<pre><code class="language-py">torch.erfinv(tensor, out=None) → Tensor
</code></pre>
<p>计算每个元素的反向误差函数.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.erfinv(torch.Tensor([0, 0.5., -1.]))
torch.FloatTensor([0., 0.4769, -inf])

</code></pre>
<pre><code class="language-py">torch.exp(tensor, out=None) → Tensor
</code></pre>
<p>计算每个元素的指数.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.exp(torch.Tensor([0, math.log(2)]))
torch.FloatTensor([1, 2])

</code></pre>
<pre><code class="language-py">torch.floor(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 的元素向下取整(取不大于每个元素的最大整数).</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.floor(a)

 1
 0
-1
-1
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.fmod(input, divisor, out=None) → Tensor
</code></pre>
<p>计算除法余数.</p>
<p>被除数和除数可能同时含有整数和浮点数. 这时余数的正负与被除数 <code>tensor</code> 相同.</p>
<p>当除数 <code>divisor</code> 是一个张量时r, 张量 <code>input</code> 和张量 <code>divisor</code> 的形状必须可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 被除数</li>
<li><code>divisor (Tensor 或 float)</code> – 除数. 可能是一个数或者是一个与被除数相同形状的张量.</li>
<li><code>out (Tensor, 可选)</code> – 输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.fmod(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2)
torch.FloatTensor([-1, -0, -1, 1, 0, 1])
&gt;&gt;&gt; torch.fmod(torch.Tensor([1, 2, 3, 4, 5]), 1.5)
torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])

</code></pre>
<p>See also</p>
<p><code>torch.remainder()</code>, 其计算等价于 Python's <code>%</code> 操作符的元素余数</p>
<pre><code class="language-py">torch.frac(tensor, out=None) → Tensor
</code></pre>
<p>计算张量 <code>tensor</code> 每个元素的分数部分.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.frac(torch.Tensor([1, 2.5, -3.2])
torch.FloatTensor([0, 0.5, -0.2])

</code></pre>
<pre><code class="language-py">torch.lerp(start, end, weight, out=None)
</code></pre>
<p>基于标量值 <code>weight</code>: , 在张量 <code>start</code> 与张量 <code>end</code> 之间做线性插值 并返回结果张量 <code>out</code> .</p>
<p><img alt="out_i = start_i + weight * (end_i - start_i)" src="../img/tex-ef591522596ccf5d38cdb23fb75fbab9.gif" /></p>
<p>张量 <code>start</code> 和张量 <code>end</code> 的形状必须可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>参数：</p>
<ul>
<li><code>start (Tensor)</code> – 起始点 <code>Tensor</code></li>
<li><code>end (Tensor)</code> – 终点 <code>Tensor</code></li>
<li><code>weight (float)</code> – 插值公式的权重</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; start = torch.arange(1, 5)
&gt;&gt;&gt; end = torch.Tensor(4).fill_(10)
&gt;&gt;&gt; start

 1
 2
 3
 4
[torch.FloatTensor of size 4]

&gt;&gt;&gt; end

 10
 10
 10
 10
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.lerp(start, end, 0.5)

 5.5000
 6.0000
 6.5000
 7.0000
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.log(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 所有元素的自然对数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(5)
&gt;&gt;&gt; a

-0.4183
 0.3722
-0.3091
 0.4149
 0.5857
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.log(a)

 nan
-0.9883
 nan
-0.8797
-0.5349
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.log1p(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是(1 + <code>input</code>) 的自然对数.</p>
<p><img alt="y_i = log(x_i + 1)" src="../img/tex-44ae3e6c45bdb0992887549eecbdcca1.gif" /></p>
<p>注解：</p>
<p>对于较小的张量 <code>input</code> 的值, 此函数比 <code>torch.log()</code> 更精确.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(5)
&gt;&gt;&gt; a

-0.4183
 0.3722
-0.3091
 0.4149
 0.5857
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.log1p(a)

-0.5418
 0.3164
-0.3697
 0.3471
 0.4611
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.mul()
</code></pre>
<pre><code class="language-py">torch.mul(input, value, out=None)
</code></pre>
<p>将输入张量 <code>input</code> 的每个元素与标量值 <code>value</code> 相乘并返回一个新的结果张量.</p>
<p><img alt="out = tensor * value" src="../img/tex-90772d102c1d9f559ae6fa994b1923c1.gif" /></p>
<p>如果张量 <code>input</code> 的类型为 <code>FloatTensor</code> or <code>DoubleTensor</code>, 则 <code>value</code> 应该是实数, 否则为整数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>value (Number)</code> – 与张量 <code>input</code> 每个元素相乘的数</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3)
&gt;&gt;&gt; a

-0.9374
-0.5254
-0.6069
[torch.FloatTensor of size 3]

&gt;&gt;&gt; torch.mul(a, 100)

-93.7411
-52.5374
-60.6908
[torch.FloatTensor of size 3]

</code></pre>
<pre><code class="language-py">torch.mul(input, other, out=None)
</code></pre>
<p>张量 <code>input</code> 的元素与张量 <code>other</code> 的元素逐一相乘. 其结果作为一个新的张量返回.</p>
<p>张量 <code>input</code> 和张量 <code>other</code> 的形状必须可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p><img alt="out_i = input_i * other_i" src="../img/tex-66ff7c38b998757c54474f8da6085fa7.gif" /></p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 第一个乘数 <code>Tensor</code></li>
<li><code>other (Tensor)</code> – 第二个乘数 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4,4)
&gt;&gt;&gt; a

-0.7280  0.0598 -1.4327 -0.5825
-0.1427 -0.0690  0.0821 -0.3270
-0.9241  0.5110  0.4070 -1.1188
-0.8308  0.7426 -0.6240 -1.1582
[torch.FloatTensor of size 4x4]

&gt;&gt;&gt; b = torch.randn(2, 8)
&gt;&gt;&gt; b

 0.0430 -1.0775  0.6015  1.1647 -0.6549  0.0308 -0.1670  1.0742
-1.2593  0.0292 -0.0849  0.4530  1.2404 -0.4659 -0.1840  0.5974
[torch.FloatTensor of size 2x8]

&gt;&gt;&gt; torch.mul(a, b)

-0.0313 -0.0645 -0.8618 -0.6784
 0.0934 -0.0021 -0.0137 -0.3513
 1.1638  0.0149 -0.0346 -0.5068
-1.0304 -0.3460  0.1148 -0.6919
[torch.FloatTensor of size 4x4]

</code></pre>
<pre><code class="language-py">torch.neg(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 的元素的负值.</p>
<p><img alt="out = -1 * input" src="../img/tex-12f8b36dc85a819313fa0fdebe068228.gif" /></p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(5)
&gt;&gt;&gt; a

-0.4430
 1.1690
-0.8836
-0.4565
 0.2968
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.neg(a)

 0.4430
-1.1690
 0.8836
 0.4565
-0.2968
[torch.FloatTensor of size 5]

</code></pre>
<pre><code class="language-py">torch.pow()
</code></pre>
<pre><code class="language-py">torch.pow(input, exponent, out=None)
</code></pre>
<p>对输入张量 <code>input</code> 按元素求 <code>exponent</code> 次幂值并返回结果张量(其值作为结果张量的元素).</p>
<p>幂值 <code>exponent</code> 可以是一个单一的浮点数 <code>float</code> 或者是一个与张量 <code>input</code> 有相同元素数的张量 <code>Tensor</code> .</p>
<p>当指数 <code>exponent</code> 是一个标量时, 执行操作:</p>
<p><img alt="out_i = x_i ^ {exponent}" src="../img/tex-7d5081fb4d383f1287f3abc01c783d5c.gif" /></p>
<p>当指数 <code>exponent</code> 是一个张量, 执行操作:</p>
<p><img alt="out_i = x_i ^ {exponent_i}" src="../img/tex-45f9b0f3e07ffc7cdba45900c800d5d8.gif" /></p>
<p>当幂值 <code>exponent</code> 是一个张量, 张量 <code>input</code> 和张量 <code>exponent</code> 的形状必须可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>exponent (float 或 Tensor)</code> – 指数</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

-0.5274
-0.8232
-2.1128
 1.7558
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.pow(a, 2)

 0.2781
 0.6776
 4.4640
 3.0829
[torch.FloatTensor of size 4]

&gt;&gt;&gt; exp = torch.arange(1, 5)
&gt;&gt;&gt; a = torch.arange(1, 5)
&gt;&gt;&gt; a

 1
 2
 3
 4
[torch.FloatTensor of size 4]

&gt;&gt;&gt; exp

 1
 2
 3
 4
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.pow(a, exp)

 1
 4
 27
 256
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.pow(base, input, out=None)
</code></pre>
<p><code>base</code> 是一个标量浮点值, <code>input</code> 是一个张量. 返回的张量 <code>out</code> 的形状与张量 <code>input</code> 的形状相同.</p>
<p>执行操作:</p>
<p><img alt="out_i = base ^ {input_i}" src="../img/tex-14e62bb86c53bc82b02aea5663311bbb.gif" /></p>
<p>参数：</p>
<ul>
<li><code>base (float)</code> – 幂运算的底数</li>
<li><code>input (Tensor)</code> – 指数</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; exp = torch.arange(1, 5)
&gt;&gt;&gt; base = 2
&gt;&gt;&gt; torch.pow(base, exp)

 2
 4
 8
 16
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.reciprocal(input, out=None) → Tensor
</code></pre>
<p>返回一个新的 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的倒数, i.e. <img alt="1.0 / x" src="../img/tex-e8d4c459fa54ec9efacf485b78522de6.gif" /></p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.reciprocal(a)

 0.7210
 2.5565
-1.1583
-1.8289
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.remainder(input, divisor, out=None) → Tensor
</code></pre>
<p>计算元素的除法的余数.</p>
<p>除数与被除数可能同时包含整数或浮点数. 余数与除数有相同的符号.</p>
<p>当除数 <code>divisor</code> 是一个张量, 张量 <code>input</code> 的形状和张量 <code>divisor</code> 得形状必须可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 被除数</li>
<li><code>divisor (Tensor 或 float)</code> – 除数. 可能是一个数或者可能是一个与被除数大小相同的张量</li>
<li><code>out (Tensor, 可选)</code> – 输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.remainder(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2)
torch.FloatTensor([1, 0, 1, 1, 0, 1])
&gt;&gt;&gt; torch.remainder(torch.Tensor([1, 2, 3, 4, 5]), 1.5)
torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])

</code></pre>
<p>See also</p>
<p><code>torch.fmod()</code> 同样计算除法余数, 等效于C库函数中的 <code>fmod()</code></p>
<pre><code class="language-py">torch.round(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是输入张量的元素四舍五入到最近的整数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.2290
 1.3409
-0.5662
-0.0899
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.round(a)

 1
 1
-1
-0
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.rsqrt(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的平方根的倒数.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.2290
 1.3409
-0.5662
-0.0899
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.rsqrt(a)

 0.9020
 0.8636
 nan
 nan
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.sigmoid(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的sigmoid值.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

-0.4972
 1.3512
 0.1056
-0.2650
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.sigmoid(a)

 0.3782
 0.7943
 0.5264
 0.4341
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.sign(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的符号.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.sign(a)

-1
 1
 1
 1
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.sin(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的正弦.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.sin(a)
-0.5944
 0.2684
 0.4322
 0.9667
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.sinh(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的双曲正弦.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.sinh(a)
-0.6804
 0.2751
 0.4619
 1.7225
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.sqrt(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的平方根.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.2290
 1.3409
-0.5662
-0.0899
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.sqrt(a)

 1.1086
 1.1580
 nan
 nan
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.tan(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的正切.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.tan(a)
-0.7392
 0.2786
 0.4792
 3.7801
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.tanh(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的双曲正切.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
-0.6366
 0.2718
 0.4469
 1.3122
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.tanh(a)
-0.5625
 0.2653
 0.4193
 0.8648
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.trunc(input, out=None) → Tensor
</code></pre>
<p>返回一个新的张量 <code>Tensor</code> , 其元素是张量 <code>input</code> 元素的截断整数值 (直接去除小数部分) .</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 输出 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

-0.4972
 1.3512
 0.1056
-0.2650
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.trunc(a)

-0
 1
 0
-0
[torch.FloatTensor of size 4]

</code></pre>
<h3 id="reduction-ops">Reduction Ops (归约操作)</h3>
<pre><code class="language-py">torch.cumprod(input, dim, out=None) → Tensor
</code></pre>
<p>返回元素 <code>input</code> 在给定维度 <code>dim</code> 下的累积积.</p>
<p>例如, 如果 <code>input</code> 是一个N元张量, 结果也是一个N元张量, 元素为: <img alt="y_i = x_1 * x_2 * x_3 * ... * x_i" src="../img/tex-06f4d1ef079a78930f949d6df01e2cb1.gif" /></p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>dim (int)</code> – 进行操作的维度</li>
<li><code>out (Tensor, 可选)</code> – 输出 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(10)
&gt;&gt;&gt; a

 1.1148
 1.8423
 1.4143
-0.4403
 1.2859
-1.2514
-0.4748
 1.1735
-1.6332
-0.4272
[torch.FloatTensor of size 10]

&gt;&gt;&gt; torch.cumprod(a, dim=0)

 1.1148
 2.0537
 2.9045
-1.2788
-1.6444
 2.0578
-0.9770
-1.1466
 1.8726
-0.8000
[torch.FloatTensor of size 10]

&gt;&gt;&gt; a[5] = 0.0
&gt;&gt;&gt; torch.cumprod(a, dim=0)

 1.1148
 2.0537
 2.9045
-1.2788
-1.6444
-0.0000
 0.0000
 0.0000
-0.0000
 0.0000
[torch.FloatTensor of size 10]

</code></pre>
<pre><code class="language-py">torch.cumsum(input, dim, out=None) → Tensor
</code></pre>
<p>返回元素 <code>input</code> 在给定维度 <code>dim</code> 下的累积和.</p>
<p>例如, 如果 <code>input</code> 是一个N元张量, 结果将也是一个N元张量, 元素为: <img alt="y_i = x_1 + x_2 + x_3 + ... + x_i" src="../img/tex-ee3d5bc08d5e2b0c0ad809ad0a991bd8.gif" /></p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>dim (int)</code> – 进行操作的维度</li>
<li><code>out (Tensor, 可选)</code> – 输出 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(10)
&gt;&gt;&gt; a

-0.6039
-0.2214
-0.3705
-0.0169
 1.3415
-0.1230
 0.9719
 0.6081
-0.1286
 1.0947
[torch.FloatTensor of size 10]

&gt;&gt;&gt; torch.cumsum(a, dim=0)

-0.6039
-0.8253
-1.1958
-1.2127
 0.1288
 0.0058
 0.9777
 1.5858
 1.4572
 2.5519
[torch.FloatTensor of size 10]

</code></pre>
<pre><code class="language-py">torch.dist(input, other, p=2) → float
</code></pre>
<p>返回(<code>input</code> - <code>other</code>)的p-范数 <code>input</code> 和 <code>other</code> 的形状必须满足 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>other (Tensor)</code> – 右侧输入 <code>Tensor</code></li>
<li><code>p (float, 可选)</code> – 所计算的范数.</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(4)
&gt;&gt;&gt; x

 0.2505
-0.4571
-0.3733
 0.7807
[torch.FloatTensor of size 4]

&gt;&gt;&gt; y = torch.randn(4)
&gt;&gt;&gt; y

 0.7782
-0.5185
 1.4106
-2.4063
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.dist(x, y, 3.5)
3.302832063224223
&gt;&gt;&gt; torch.dist(x, y, 3)
3.3677282206393286
&gt;&gt;&gt; torch.dist(x, y, 0)
inf
&gt;&gt;&gt; torch.dist(x, y, 1)
5.560028076171875

</code></pre>
<pre><code class="language-py">torch.mean()
</code></pre>
<pre><code class="language-py">torch.mean(input) → float
</code></pre>
<p>返回张量 <code>input</code> 所有元素的均值.</p>
<p>参数：<code>input (Tensor)</code> – 输入 <code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

-0.2946 -0.9143  2.1809
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.mean(a)
0.32398951053619385

</code></pre>
<pre><code class="language-py">torch.mean(input, dim, keepdim=False, out=None) → Tensor
</code></pre>
<p>返回张量 <code>input</code> 在给定维度 <code>dim</code> 上每行的均值.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量的大小与输入张量 <code>input</code> 相同, 除了维度 <code>dim</code> 是1. 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code> ), 导致输出张量减少一维.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool, 可选)</code> – 输出张量的维度 <code>dim</code> 保持与否</li>
<li><code>out (Tensor)</code> – 输出张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 4)
&gt;&gt;&gt; a

-1.2738 -0.3058  0.1230 -1.9615
 0.8771 -0.5430 -0.9233  0.9879
 1.4107  0.0317 -0.6823  0.2255
-1.3854  0.4953 -0.2160  0.2435
[torch.FloatTensor of size 4x4]

&gt;&gt;&gt; torch.mean(a, 1)

-0.8545
 0.0997
 0.2464
-0.2157
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.mean(a, 1, True)

-0.8545
 0.0997
 0.2464
-0.2157
[torch.FloatTensor of size 4x1]

</code></pre>
<pre><code class="language-py">torch.median()
</code></pre>
<pre><code class="language-py">torch.median(input) → float
</code></pre>
<p>返回输出张量 <code>input</code> 所有元素的中位数.</p>
<p>参数：<code>input (Tensor)</code> – the input <code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

 0.4729 -0.2266 -0.2085
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.median(a)
-0.2085

</code></pre>
<pre><code class="language-py">torch.median(input, dim=-1, keepdim=False, values=None, indices=None) -&gt; (Tensor, LongTensor)
</code></pre>
<p>返回输出张量 <code>input</code> 在给定维度 <code>dim</code> 下每行的中位数. 同时返回一个包含中位数的索引 <code>LongTensor</code>.</p>
<p><code>dim</code> 的缺省值为输入张量 <code>input</code> 的最后一维.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量与输入张量 <code>input</code> 形状相同, 除了维数 <code>dim</code> 是1. 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code> ), 导致输出张量比输入张量 <code>input</code> 少一维.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool)</code> – 输出张量的维度 <code>dim</code> 保留与否</li>
<li><code>values (Tensor, 可选)</code> – 结果张量</li>
<li><code>indices (Tensor, 可选)</code> – 结果张量索引</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a

 -0.6891 -0.6662
 0.2697  0.7412
 0.5254 -0.7402
 0.5528 -0.2399
[torch.FloatTensor of size 4x2]

&gt;&gt;&gt; a = torch.randn(4, 5)
&gt;&gt;&gt; a

 0.4056 -0.3372  1.0973 -2.4884  0.4334
 2.1336  0.3841  0.1404 -0.1821 -0.7646
-0.2403  1.3975 -2.0068  0.1298  0.0212
-1.5371 -0.7257 -0.4871 -0.2359 -1.1724
[torch.FloatTensor of size 4x5]

&gt;&gt;&gt; torch.median(a, 1)
(
 0.4056
 0.1404
 0.0212
-0.7257
[torch.FloatTensor of size 4]
,
 0
 2
 4
 1
[torch.LongTensor of size 4]
)

</code></pre>
<pre><code class="language-py">torch.mode(input, dim=-1, keepdim=False, values=None, indices=None) -&gt; (Tensor, LongTensor)
</code></pre>
<p>返回输入张量 <code>input</code> 在给定维数 <code>dim</code> 下每行元素的众数值. 同时也返回众数值的索引 <code>LongTensor</code>.</p>
<p>维度 <code>dim</code> 的缺省值是输入张量 <code>input</code> 的最后一维. .</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量的大小与输入张量 <code>input</code> 相同, 除了维度 <code>dim</code> 是1. 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code> ), 导致输出张量减少一维.</p>
<p>注解：</p>
<p>这个函数至今没有为 <code>torch.cuda.Tensor</code> 定义.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool)</code> – 输出张量的维度 <code>dim</code> 保持与否</li>
<li><code>values (Tensor, 可选)</code> – 结果张量</li>
<li><code>indices (Tensor, 可选)</code> – 结果索引张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a

 -0.6891 -0.6662
 0.2697  0.7412
 0.5254 -0.7402
 0.5528 -0.2399
[torch.FloatTensor of size 4x2]

&gt;&gt;&gt; a = torch.randn(4, 5)
&gt;&gt;&gt; a

 0.4056 -0.3372  1.0973 -2.4884  0.4334
 2.1336  0.3841  0.1404 -0.1821 -0.7646
-0.2403  1.3975 -2.0068  0.1298  0.0212
-1.5371 -0.7257 -0.4871 -0.2359 -1.1724
[torch.FloatTensor of size 4x5]

&gt;&gt;&gt; torch.mode(a, 1)
(
-2.4884
-0.7646
-2.0068
-1.5371
[torch.FloatTensor of size 4]
,
 3
 4
 2
 0
[torch.LongTensor of size 4]
)

</code></pre>
<pre><code class="language-py">torch.norm()
</code></pre>
<pre><code class="language-py">torch.norm(input, p=2) → float
</code></pre>
<p>返回输入张量 <code>input</code> 的p-范数</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>p (float, 可选)</code> – 范数计算中的幂指数值</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

-0.4376 -0.5328  0.9547
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.norm(a, 3)
1.0338925067372466

</code></pre>
<pre><code class="language-py">torch.norm(input, p, dim, keepdim=False, out=None) → Tensor
</code></pre>
<p>返回输入张量 <code>input</code> 在给定维度 <code>dim</code> 下每行元素的p-范数.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量的大小与输入张量 <code>input</code> 相同, 除非维度 <code>dim</code> 是1. 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code> ), 导致输出张量减少一维.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>p (float)</code> – 范数计算中的幂指数值</li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool)</code> – 输出张量的维度 <code>dim</code> 保持与否</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 2)
&gt;&gt;&gt; a

-0.6891 -0.6662
 0.2697  0.7412
 0.5254 -0.7402
 0.5528 -0.2399
[torch.FloatTensor of size 4x2]

&gt;&gt;&gt; torch.norm(a, 2, 1)

 0.9585
 0.7888
 0.9077
 0.6026
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.norm(a, 0, 1, True)

 2
 2
 2
 2
[torch.FloatTensor of size 4x1]

</code></pre>
<pre><code class="language-py">torch.prod()
</code></pre>
<pre><code class="language-py">torch.prod(input) → float
</code></pre>
<p>返回输入张量 <code>input</code> 所有元素的乘积.</p>
<p>参数：<code>input (Tensor)</code> – 输入张量 <code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

 0.6170  0.3546  0.0253
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.prod(a)
0.005537458061418483

</code></pre>
<pre><code class="language-py">torch.prod(input, dim, keepdim=False, out=None) → Tensor
</code></pre>
<p>返回输入张量 <code>input</code> 在给定维度 <code>dim</code> 下每行元素的积.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量的大小与输入张量 <code>input</code> 相同, 除了维度 <code>dim</code> 是1. 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code> ), 导致输出张量减少一维.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool)</code> – 输出张量的维度 <code>dim</code> 保持与否</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 2)
&gt;&gt;&gt; a

 0.1598 -0.6884
-0.1831 -0.4412
-0.9925 -0.6244
-0.2416 -0.8080
[torch.FloatTensor of size 4x2]

&gt;&gt;&gt; torch.prod(a, 1)

-0.1100
 0.0808
 0.6197
 0.1952
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.std()
</code></pre>
<pre><code class="language-py">torch.std(input, unbiased=True) → float
</code></pre>
<p>返回输入张量 <code>input</code> 所有元素的标准差.</p>
<p>如果 <code>unbiased</code> 是 <code>False</code> , 那么标准差将通过有偏估计计算.否则, Bessel's correction 将被使用.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>unbiased (bool)</code> – 是否使用无偏估计</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

-1.3063  1.4182 -0.3061
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.std(a)
1.3782334731508061

</code></pre>
<pre><code class="language-py">torch.std(input, dim, keepdim=False, unbiased=True, out=None) → Tensor
</code></pre>
<p>返回输入张量 <code>input</code> 在给定维度 <code>dim</code> 下每行元素的标准差.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量的大小与输入张量 <code>input</code> 相同, 除了维度 <code>dim</code> 是 1. 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code> ), 导致输出张量减少一维.</p>
<p>如果 <code>unbiased</code> 是 <code>False</code> , 那么标准差将通过有偏估计来计算. 否则, Bessel's correction 将被使用.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool)</code> – 输出张量的维度 <code>dim</code> 保持与否</li>
<li><code>unbiased (bool)</code> – 是否使用无偏估计</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 4)
&gt;&gt;&gt; a

 0.1889 -2.4856  0.0043  1.8169
-0.7701 -0.4682 -2.2410  0.4098
 0.1919 -1.1856 -1.0361  0.9085
 0.0173  1.0662  0.2143 -0.5576
[torch.FloatTensor of size 4x4]

&gt;&gt;&gt; torch.std(a, dim=1)

 1.7756
 1.1025
 1.0045
 0.6725
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.sum()
</code></pre>
<pre><code class="language-py">torch.sum(input) → float
</code></pre>
<p>返回输入张量 <code>input</code> 所有元素的和.</p>
<p>参数：<code>input (Tensor)</code> – 输入张量 <code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

 0.6170  0.3546  0.0253
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.sum(a)
0.9969287421554327

</code></pre>
<pre><code class="language-py">torch.sum(input, dim, keepdim=False, out=None) → Tensor
</code></pre>
<p>返回输入张量 <code>input</code> 在给定维度 <code>dim</code> 下每行元素的和.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量的大小与输入张量 <code>input</code> 相同, 除了维度 <code>dim</code> 是 1. 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code> ), 导致输出张量减少一维.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool)</code> – 输出张量的维度 <code>dim</code> 保持与否</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 4)
&gt;&gt;&gt; a

-0.4640  0.0609  0.1122  0.4784
-1.3063  1.6443  0.4714 -0.7396
-1.3561 -0.1959  1.0609 -1.9855
 2.6833  0.5746 -0.5709 -0.4430
[torch.FloatTensor of size 4x4]

&gt;&gt;&gt; torch.sum(a, 1)

 0.1874
 0.0698
-2.4767
 2.2440
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.var()
</code></pre>
<pre><code class="language-py">torch.var(input, unbiased=True) → float
</code></pre>
<p>返回输入张量 <code>input</code> 的方差.</p>
<p>如果 <code>unbiased</code> 是 <code>False</code> , 方差的计算将通过有偏估计计算. 否则, Bessel's correction 将会被使用.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>unbiased (bool)</code> – 是否使用无偏估计</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

-1.3063  1.4182 -0.3061
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.var(a)
1.899527506513334

</code></pre>
<pre><code class="language-py">torch.var(input, dim, keepdim=False, unbiased=True, out=None) → Tensor
</code></pre>
<p>返回输入张量 <code>input</code> 在给定维度 <code>dim</code> 下每行的方差.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量的大小与输入张量 <code>input</code> 相同, 除了维度 <code>dim</code> 是 1. 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code>), 导致输出张量减少一维.</p>
<p>如果 <code>unbiased</code> 是<code>False</code>, 方差的计算将通过有偏估计计算. 否则, Bessel's correction 将会被使用.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool)</code> – 输出张量的维度 <code>dim</code> 保留与否</li>
<li><code>unbiased (bool)</code> – 是否使用无偏估计</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 4)
&gt;&gt;&gt; a

-1.2738 -0.3058  0.1230 -1.9615
 0.8771 -0.5430 -0.9233  0.9879
 1.4107  0.0317 -0.6823  0.2255
-1.3854  0.4953 -0.2160  0.2435
[torch.FloatTensor of size 4x4]

&gt;&gt;&gt; torch.var(a, 1)

 0.8859
 0.9509
 0.7548
 0.6949
[torch.FloatTensor of size 4]

</code></pre>
<h3 id="comparison-ops">Comparison Ops (比较操作)</h3>
<pre><code class="language-py">torch.eq(input, other, out=None) → Tensor
</code></pre>
<p>比较元素是否相等</p>
<p>第二个元素可以是一个数字或 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 为与第一个参数形状相同的张量.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 待比较张量</li>
<li><code>other (Tensor 或 float)</code> – 比较张量或数</li>
<li><code>out (Tensor, 可选)</code> – 输出张量, 须为 ByteTensor 类型或与 input (Tensor) 同类型</li>
</ul>
<p>返回值：一个 torch.ByteTensor 张量, 待比较和要比较张量逐位置比较, 相等为 1 , 不等为 0</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.eq(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))
1  0
0  1
[torch.ByteTensor of size 2x2]

</code></pre>
<pre><code class="language-py">torch.equal(tensor1, tensor2) → bool
</code></pre>
<p>如果两个张量有相同的形状和元素值, 则返回 <code>True</code> , 否则 <code>False</code> .</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.equal(torch.Tensor([1, 2]), torch.Tensor([1, 2]))
True

</code></pre>
<pre><code class="language-py">torch.ge(input, other, out=None) → Tensor
</code></pre>
<p>逐元素比较 <code>input</code> 和 <code>other</code> , 即是否 <strong>input&gt;=other</strong> .</p>
<p>第二个参数可以为一个数或形状可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 为和第一个参数相同类型的张量.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 待对比的张量</li>
<li><code>other (Tensor 或 float)</code> – 对比的张量或 <code>float</code> 值</li>
<li><code>out (Tensor, 可选)</code> – 输出张量. 必须为 <code>ByteTensor</code> 或者与第一个参数 <code>tensor</code> 相同类型.</li>
</ul>
<p>返回值：一个 <code>torch.ByteTensor</code> 张量, 包含了每个位置的比较结果(是否 input &gt;= other ).</p>
<p>返回类型：<code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.ge(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))
 1  1
 0  1
[torch.ByteTensor of size 2x2]

</code></pre>
<pre><code class="language-py">torch.gt(input, other, out=None) → Tensor
</code></pre>
<p>逐元素比较 <code>input</code> 和 <code>other</code> , 即是否 <strong>input&gt;other</strong> 如果两个张量有相同的形状和元素值, 则返回 <code>True</code> ,否则 <code>False</code>.</p>
<p>第二个参数可以为一个数或形状可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 为和第一个参数相同类型的张量.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 待对比的张量</li>
<li><code>other (Tensor 或 float)</code> – 对比的张量或 <code>float</code> 值</li>
<li><code>out (Tensor, 可选)</code> – 输出张量. 必须为 <code>ByteTensor</code> 或者与第一个参数 <code>tensor</code> 相同类型.</li>
</ul>
<p>返回值：一个 <code>torch.ByteTensor</code> 张量, 包含了每个位置的比较结果(是否 input &gt; other ).</p>
<p>返回类型：<code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.gt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))
 0  1
 0  0
[torch.ByteTensor of size 2x2]

</code></pre>
<pre><code class="language-py">torch.kthvalue(input, k, dim=None, keepdim=False, out=None) -&gt; (Tensor, LongTensor)
</code></pre>
<p>取输入张量 <code>input</code> 指定维上第 <code>k</code> 个最小值. 如果不指定 <code>dim</code> , 则默认为 <code>input</code> 的最后一维.</p>
<p>返回一个元组 <code>(values,indices)</code> ,其中 <code>indices</code> 是原始输入张量 <code>input</code> 中沿 <code>dim</code> 维的第 <code>k</code> 个最小值下标.</p>
<p>如果 <code>keepdim</code> 为 <code>True</code> , <code>values</code> 和 <code>indices</code> 张量都和 <code>input</code> 大小相同, 除了在所有值都为1的 <code>dim</code> 维度上. 如果 <code>keepdim</code> 为 <code>False</code> , <code>dim</code> 被压缩. (参见 <code>torch.squeeze()</code> ), 使 <code>values</code> 和 <code>indices</code> 两个张量比 <code>input</code> 张量小一个的维度.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>k (int)</code> – 第 <code>k</code> 个最小值</li>
<li><code>dim (int, 可选)</code> – 沿着此维进行排序</li>
<li><code>keepdim (bool)</code> – 输出张量是否保持维度 <code>dim</code> 不变</li>
<li><code>out (tuple, 可选)</code> – 输出元组 ( Tensor, LongTensor ) 可选参数(作为输出 buffers )</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.arange(1, 6)
&gt;&gt;&gt; x

 1
 2
 3
 4
 5
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.kthvalue(x, 4)
(
 4
[torch.FloatTensor of size 1]
,
 3
[torch.LongTensor of size 1]
)

&gt;&gt;&gt; x=torch.arange(1,7).resize_(2,3)
&gt;&gt;&gt; x

1  2  3
4  5  6
[torch.FloatTensor of size 2x3]

&gt;&gt;&gt; torch.kthvalue(x,2,0,True)
(
4  5  6
[torch.FloatTensor of size 1x3]
 ,
1  1  1
[torch.LongTensor of size 1x3]
)

</code></pre>
<pre><code class="language-py">torch.le(input, other, out=None) → Tensor
</code></pre>
<p>逐元素比较 <code>input</code> 和 <code>other</code> , 即是否 <strong>input&lt;=other</strong> 如果两个张量有相同的形状和元素值, 则返回 <code>True</code> ,否则 <code>False</code> .</p>
<p>第二个参数可以为一个数或形状可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 为和第一个参数相同类型的张量.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 待对比的张量</li>
<li><code>other (Tensor 或 float)</code> – 对比的张量或 <code>float</code> 值</li>
<li><code>out (Tensor, 可选)</code> – 输出张量. 必须为 <code>ByteTensor</code> 或者与第一个参数 <code>tensor</code> 相同类型.</li>
</ul>
<p>返回值：一个 <code>torch.ByteTensor</code> 张量, 包含了每个位置的比较结果(是否 input &lt;= other ).</p>
<p>返回类型：<code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.le(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))
 1  0
 1  1
[torch.ByteTensor of size 2x2]

</code></pre>
<pre><code class="language-py">torch.lt(input, other, out=None) → Tensor
</code></pre>
<p>逐元素比较 <code>input</code> 和 <code>other</code> , 即是否 <strong>input&lt;other</strong> 如果两个张量有相同的形状和元素值, 则返回 <code>True</code> ,否则 <code>False</code> .</p>
<p>第二个参数可以为一个数或形状可 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 为和第一个参数相同类型的张量.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 待对比的张量</li>
<li><code>other (Tensor 或 float)</code> – 对比的张量或 <code>float</code> 值</li>
<li><code>out (Tensor, 可选)</code> – 输出张量. 必须为 <code>ByteTensor</code> 或者与第一个参数 <code>tensor</code> 相同类型.</li>
</ul>
<p>返回值：一个 <code>torch.ByteTensor</code> 张量, 包含了每个位置的比较结果(是否 input &lt; other ).</p>
<p>返回类型：<code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.lt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))
 0  0
 1  0
[torch.ByteTensor of size 2x2]

</code></pre>
<pre><code class="language-py">torch.max()
</code></pre>
<pre><code class="language-py">torch.max(input) → float
</code></pre>
<p>返回输入 <code>input</code> 张量所有元素的最大值.</p>
<p>参数：<code>input (Tensor)</code> – 输入 <code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

 0.4729 -0.2266 -0.2085
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.max(a)
0.4729

</code></pre>
<pre><code class="language-py">torch.max(input, dim, keepdim=False, out=None) -&gt; (Tensor, LongTensor)
</code></pre>
<p>返回输入张量 <code>input</code> 在给定维度 <code>dim</code> 上每行的最大值, 并同时返回每个最大值的位置索引.</p>
<p>如果 <code>keepdim</code> 为 <code>True</code> , <code>values</code> 和 <code>indices</code> 张量都和 <code>input</code> 尺寸相同, 除了在所有值都为 1 的 <code>dim</code> 维度上. 如果 <code>keepdim</code> 为 <code>False</code> , <code>dim</code> 被压缩. (参见 <code>torch.squeeze()</code> ), 使 <code>values</code> 和 <code>indices</code> 两个张量比 <code>input</code> 张量小一个的维度.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>k (int)</code> – 第 <code>k</code> 个最小值</li>
<li><code>dim (int, 可选)</code> – 沿着此维进行排序</li>
<li><code>keepdim (bool)</code> – 输出张量是否保持维度 <code>dim</code> 不变</li>
<li><code>out (tuple, 可选)</code> – 输出元组 (max, max_indices)</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt; a = torch.randn(4, 4)
&gt;&gt; a

0.0692  0.3142  1.2513 -0.5428
0.9288  0.8552 -0.2073  0.6409
1.0695 -0.0101 -2.4507 -1.2230
0.7426 -0.7666  0.4862 -0.6628
torch.FloatTensor of size 4x4]

&gt;&gt;&gt; torch.max(a, 1)
(
 1.2513
 0.9288
 1.0695
 0.7426
[torch.FloatTensor of size 4]
,
 2
 0
 0
 0
[torch.LongTensor of size 4]
)

</code></pre>
<pre><code class="language-py">torch.max(input, other, out=None) → Tensor
</code></pre>
<p>输入 <code>input</code> 每一个元素和对应的比较张量 <code>other</code> 进行比较, 留下较大的元素 <code>max</code>.</p>
<p>要比较的张量 <code>input</code> 与比较张量 <code>other</code> 不必大小一致, 但它们一定要能 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> .</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 要比较张量 <code>Tensor</code></li>
<li><code>other (Tensor)</code> – 比较张量 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 输出张量 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

&gt;&gt;&gt; b = torch.randn(4)
&gt;&gt;&gt; b

 1.0067
-0.8010
 0.6258
 0.3627
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.max(a, b)

 1.3869
 0.3912
 0.6258
 0.3627
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.min()
</code></pre>
<pre><code class="language-py">torch.min(input) → float
</code></pre>
<p>返回输入张量 <code>input</code> 所有元素的最小值.</p>
<p>参数：<code>input (Tensor)</code> – 输入 <code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a

 0.4729 -0.2266 -0.2085
[torch.FloatTensor of size 1x3]

&gt;&gt;&gt; torch.min(a)
-0.22663167119026184

</code></pre>
<pre><code class="language-py">torch.min(input, dim, keepdim=False, out=None) -&gt; (Tensor, LongTensor)
</code></pre>
<p>返回输入张量 <code>input</code> 在给定维度 <code>dim</code> 下每行元素的最小值. 其中第二个返回值是每个被找出的最小值的索引位置 ( argmin ) .</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 输出张量的大小与输入张量 <code>input</code> 相同, 除了维数 <code>dim</code> 是 1 . 另外, <code>dim</code> 被挤压 (参看 <code>torch.squeeze()</code> ), 导致输出张量比输入张量 <code>input</code> 少一维.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量 <code>Tensor</code></li>
<li><code>dim (int)</code> – 要减少的维度</li>
<li><code>keepdim (bool)</code> – 输出张量的维度 <code>dim</code> 保持与否</li>
<li><code>out (tuple, 可选)</code> – 两个输出张量的结果元组 (min, min_indices)</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt; a = torch.randn(4, 4)
&gt;&gt; a

0.0692  0.3142  1.2513 -0.5428
0.9288  0.8552 -0.2073  0.6409
1.0695 -0.0101 -2.4507 -1.2230
0.7426 -0.7666  0.4862 -0.6628
torch.FloatTensor of size 4x4]

&gt;&gt; torch.min(a, 1)

0.5428
0.2073
2.4507
0.7666
torch.FloatTensor of size 4]

3
2
2
1
torch.LongTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.min(input, other, out=None) → Tensor
</code></pre>
<p>输入 <code>input</code> 每一个元素和对应的比较张量 <code>other</code> 进行比较, 留下较小的元素 <code>min</code> .</p>
<p>要比较的张量 <code>input</code> 与比较张量 <code>other</code> 不必尺寸一致, 但它们一定要能广播 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> .</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 第一个张量 <code>Tensor</code></li>
<li><code>other (Tensor)</code> – 第二个张量 <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – 输出的张量 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a

 1.3869
 0.3912
-0.8634
-0.5468
[torch.FloatTensor of size 4]

&gt;&gt;&gt; b = torch.randn(4)
&gt;&gt;&gt; b

 1.0067
-0.8010
 0.6258
 0.3627
[torch.FloatTensor of size 4]

&gt;&gt;&gt; torch.min(a, b)

 1.0067
-0.8010
-0.8634
-0.5468
[torch.FloatTensor of size 4]

</code></pre>
<pre><code class="language-py">torch.ne(input, other, out=None) → Tensor
</code></pre>
<p>逐元素比较 <code>input</code> 和 <code>other</code> , 即是否 <strong>tensor != other</strong> 如果两个张量有相同的形状和元素值, 则返回 <code>True</code> , 否则 <code>False</code> .</p>
<p>第二个参数可以为一个数或形状广播 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 为和第一个参数相同类型的张量.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 待对比的张量</li>
<li><code>other (Tensor 或 float)</code> – 对比的张量或 <code>float</code> 值</li>
<li><code>out (Tensor, 可选)</code> – 输出张量. 必须为 <code>ByteTensor</code> 或者与第一个参数 <code>tensor</code> 相同类型.</li>
</ul>
<p>返回值：一个 <code>torch.ByteTensor</code> 张量, 包含了每个位置的比较结果 (是否 input != other ) .</p>
<p>返回类型：<code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.ne(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))
 0  1
 1  0
[torch.ByteTensor of size 2x2]

</code></pre>
<pre><code class="language-py">torch.sort(input, dim=None, descending=False, out=None) -&gt; (Tensor, LongTensor)
</code></pre>
<p>对输入张量 <code>input</code> 沿着指定维按升序排序.</p>
<p>如果不给定 <code>dim</code> ,则默认为输入的最后一维.</p>
<p>如果指定参数 <code>descending</code> 为 <code>True</code> , 则按降序排序.</p>
<p>返回元组 (sorted_tensor, sorted_indices) , sorted_indices 为原始输入中的下标.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 要对比的张量</li>
<li><code>dim (int, 可选)</code> – 沿着此维排序</li>
<li><code>descending (bool, 可选)</code> – 布尔值, 控制升降排序</li>
<li><code>out (tuple, 可选)</code> – 输出张量. 必须为 ByteTensor 或者与第一个参数 tensor 相同类型.</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.randn(3, 4)
&gt;&gt;&gt; sorted, indices = torch.sort(x)
&gt;&gt;&gt; sorted

-1.6747  0.0610  0.1190  1.4137
-1.4782  0.7159  1.0341  1.3678
-0.3324 -0.0782  0.3518  0.4763
[torch.FloatTensor of size 3x4]

&gt;&gt;&gt; indices

 0  1  3  2
 2  1  0  3
 3  1  0  2
[torch.LongTensor of size 3x4]

&gt;&gt;&gt; sorted, indices = torch.sort(x, 0)
&gt;&gt;&gt; sorted

-1.6747 -0.0782 -1.4782 -0.3324
 0.3518  0.0610  0.4763  0.1190
 1.0341  0.7159  1.4137  1.3678
[torch.FloatTensor of size 3x4]

&gt;&gt;&gt; indices

 0  2  1  2
 2  0  2  0
 1  1  0  1
[torch.LongTensor of size 3x4]

</code></pre>
<pre><code class="language-py">torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -&gt; (Tensor, LongTensor)
</code></pre>
<p>沿给定 dim 维度返回输入张量 <code>input</code> 中 <code>k</code> 个最大值. 如果不指定 <code>dim</code> , 则默认为 <code>input</code> 的最后一维. 如果为 <code>largest</code> 为 <code>False</code> ,则返回最小的 <code>k</code> 个值. 返回一个元组 <code>(values, indices)</code> , 其中 indices 是原始输入张量 input 中测元素下标. 如果设定布尔值 <code>sorted</code> 为 <code>True</code> , 将会确保返回的 <code>k</code> 个值被排序.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>k (int)</code> – “top-k” 中的 k</li>
<li><code>dim (int, 可选)</code> – 排序的维</li>
<li><code>largest (bool, 可选)</code> – 布尔值, 控制返回最大或最小值</li>
<li><code>sorted (bool, 可选)</code> – 布尔值, 控制返回值是否排序</li>
<li><code>out (tuple, 可选)</code> – 可选输出张量 (Tensor, LongTensor) output buffers</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.arange(1, 6)
&gt;&gt;&gt; x

 1
 2
 3
 4
 5
[torch.FloatTensor of size 5]

&gt;&gt;&gt; torch.topk(x, 3)
(
 5
 4
 3
[torch.FloatTensor of size 3]
,
 4
 3
 2
[torch.LongTensor of size 3]
)
&gt;&gt;&gt; torch.topk(x, 3, 0, largest=False)
(
 1
 2
 3
[torch.FloatTensor of size 3]
,
 0
 1
 2
[torch.LongTensor of size 3]
)

</code></pre>
<h3 id="other-operations">Other Operations (其它操作)</h3>
<pre><code class="language-py">torch.cross(input, other, dim=-1, out=None) → Tensor
</code></pre>
<p>返回沿着维度 <code>dim</code> 上, 两个张量 <code>input</code> 和 <code>other</code> 的向量积 (叉积), <code>input</code> 和 <code>other</code> 必须有相同的形状, 且指定的 <code>dim</code> 维上 <code>size</code> 必须为 3.</p>
<p>如果不指定 <code>dim</code>, 则默认为第一个尺度为 3 的维.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>other (Tensor)</code> – 第二个输入 <code>Tensor</code></li>
<li><code>dim (int, 可选)</code> – 沿着此维进行叉积操作.</li>
<li><code>out (Tensor, 可选)</code> – 结果 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(4, 3)
&gt;&gt;&gt; a

-0.6652 -1.0116 -0.6857
 0.2286  0.4446 -0.5272
 0.0476  0.2321  1.9991
 0.6199  1.1924 -0.9397
[torch.FloatTensor of size 4x3]

&gt;&gt;&gt; b = torch.randn(4, 3)
&gt;&gt;&gt; b

-0.1042 -1.1156  0.1947
 0.9947  0.1149  0.4701
-1.0108  0.8319 -0.0750
 0.9045 -1.3754  1.0976
[torch.FloatTensor of size 4x3]

&gt;&gt;&gt; torch.cross(a, b, dim=1)

-0.9619  0.2009  0.6367
 0.2696 -0.6318 -0.4160
-1.6805 -2.0171  0.2741
 0.0163 -1.5304 -1.9311
[torch.FloatTensor of size 4x3]

&gt;&gt;&gt; torch.cross(a, b)

-0.9619  0.2009  0.6367
 0.2696 -0.6318 -0.4160
-1.6805 -2.0171  0.2741
 0.0163 -1.5304 -1.9311
[torch.FloatTensor of size 4x3]

</code></pre>
<pre><code class="language-py">torch.diag(input, diagonal=0, out=None) → Tensor
</code></pre>
<ul>
<li>如果输入是一个向量( <code>1D</code> 张量), 则返回一个以 <code>input</code> 为对角线元素的 <code>2D</code> 方阵.</li>
<li>如果输入是一个矩阵( <code>2D</code> 张量), 则返回一个包含 <code>input</code> 对角线元素的1D张量.</li>
</ul>
<p>参数 <code>diagonal</code> 指定对角线:</p>
<ul>
<li><code>diagonal</code> = 0, 主对角线.</li>
<li><code>diagonal</code> &gt; 0, 主对角线之上.</li>
<li><code>diagonal</code> &lt; 0, 主对角线之下.</li>
</ul>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>diagonal (int, 可选)</code> – 指定对角线</li>
<li><code>out (Tensor, 可选)</code> – 输出 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<p>获得以 <code>input</code> 为对角线的方阵:</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3)
&gt;&gt;&gt; a

 1.0480
-2.3405
-1.1138
[torch.FloatTensor of size 3]

&gt;&gt;&gt; torch.diag(a)

 1.0480  0.0000  0.0000
 0.0000 -2.3405  0.0000
 0.0000  0.0000 -1.1138
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.diag(a, 1)

 0.0000  1.0480  0.0000  0.0000
 0.0000  0.0000 -2.3405  0.0000
 0.0000  0.0000  0.0000 -1.1138
 0.0000  0.0000  0.0000  0.0000
[torch.FloatTensor of size 4x4]

</code></pre>
<p>获得给定矩阵的第k条对角线:</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3, 3)
&gt;&gt;&gt; a

-1.5328 -1.3210 -1.5204
 0.8596  0.0471 -0.2239
-0.6617  0.0146 -1.0817
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.diag(a, 0)

-1.5328
 0.0471
-1.0817
[torch.FloatTensor of size 3]

&gt;&gt;&gt; torch.diag(a, 1)

-1.3210
-0.2239
[torch.FloatTensor of size 2]

</code></pre>
<pre><code class="language-py">torch.histc(input, bins=100, min=0, max=0, out=None) → Tensor
</code></pre>
<p>计算输入张量的直方图.</p>
<p>以 <code>min</code> 和 <code>max</code> 为 <code>range</code> 边界, 将其均分成 <code>bins</code> 个直条, 然后将排序好的数据划分到各个直条 <code>(bins)</code> 中. 如果 <code>min</code> 和 <code>max</code> 都为 0, 则利用数据中的最大最小值作为边界.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入张量</li>
<li><code>bins (int)</code> – 直方图 <code>bins</code> (直条)的个数(默认100个)</li>
<li><code>min (int)</code> – <code>range</code> 的下边界(包含)</li>
<li><code>max (int)</code> – <code>range</code> 的上边界(包含)</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>返回值：直方图</p>
<p>返回类型：<code>Tensor</code></p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.histc(torch.FloatTensor([1, 2, 1]), bins=4, min=0, max=3)
FloatTensor([0, 2, 1, 0])

</code></pre>
<pre><code class="language-py">torch.renorm(input, p, dim, maxnorm, out=None) → Tensor
</code></pre>
<p>返回一个张量, 包含规范化后的各个子张量, 使得沿着 <code>dim</code> 维划分的各子张量的 <code>p</code> 范数小于 <code>maxnorm</code></p>
<p>注解：</p>
<p>如果 p 范数的值小于 <code>maxnorm</code>, 则当前子张量不需要修改.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>p (float)</code> – 范数的 <code>p</code></li>
<li><code>dim (int)</code> – 沿着此维切片, 得到张量子集</li>
<li><code>maxnorm (float)</code> – 每个子张量的范数的最大值</li>
<li><code>out (Tensor, 可选)</code> – 结果张量</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.ones(3, 3)
&gt;&gt;&gt; x[1].fill_(2)
&gt;&gt;&gt; x[2].fill_(3)
&gt;&gt;&gt; x

 1  1  1
 2  2  2
 3  3  3
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.renorm(x, 1, 0, 5)

 1.0000  1.0000  1.0000
 1.6667  1.6667  1.6667
 1.6667  1.6667  1.6667
[torch.FloatTensor of size 3x3]

</code></pre>
<pre><code class="language-py">torch.trace(input) → float
</code></pre>
<p>返回输入 2 维矩阵对角线元素的和(迹).</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.arange(1, 10).view(3, 3)
&gt;&gt;&gt; x

 1  2  3
 4  5  6
 7  8  9
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.trace(x)
15.0

</code></pre>
<pre><code class="language-py">torch.tril(input, diagonal=0, out=None) → Tensor
</code></pre>
<p>返回一个张量, 包含输入矩阵 ( <code>2D</code> 张量)的下三角部分, 其余部分被设为 0.</p>
<p>这里所说的下三角部分为矩阵指定对角线 <code>diagonal</code> 在线里的和下面的元素.</p>
<p>参数 <code>diagonal</code> 控制对角线.</p>
<ul>
<li><code>diagonal</code> = 0, 主对角线.</li>
<li><code>diagonal</code> &gt; 0, 主对角线之上.</li>
<li><code>diagonal</code> &lt; 0, 主对角线之下.</li>
</ul>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>diagonal (int, 可选)</code> – 指定对角线</li>
<li><code>out (Tensor, 可选)</code> – 输出 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3,3)
&gt;&gt;&gt; a

 1.3225  1.7304  1.4573
-0.3052 -0.3111 -0.1809
 1.2469  0.0064 -1.6250
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.tril(a)

 1.3225  0.0000  0.0000
-0.3052 -0.3111  0.0000
 1.2469  0.0064 -1.6250
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.tril(a, diagonal=1)

 1.3225  1.7304  0.0000
-0.3052 -0.3111 -0.1809
 1.2469  0.0064 -1.6250
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.tril(a, diagonal=-1)

 0.0000  0.0000  0.0000
-0.3052  0.0000  0.0000
 1.2469  0.0064  0.0000
[torch.FloatTensor of size 3x3]

</code></pre>
<pre><code class="language-py">torch.triu(input, diagonal=0, out=None) → Tensor
</code></pre>
<p>返回一个张量, 包含输入矩阵 ( <code>2D</code> 张量)的上三角部分, 其余部分被设为 0.</p>
<p>这里所说的下三角部分为矩阵指定对角线 <code>diagonal</code> 在线里的和上面的元素.</p>
<p>参数 <code>diagonal</code> 控制对角线.</p>
<ul>
<li><code>diagonal</code> = 0, 主对角线.</li>
<li><code>diagonal</code> &gt; 0, 主对角线之上.</li>
<li><code>diagonal</code> &lt; 0, 主对角线之下.</li>
</ul>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – 输入 <code>Tensor</code></li>
<li><code>diagonal (int, 可选)</code> – 指定对角线</li>
<li><code>out (Tensor, 可选)</code> – 输出 <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3,3)
&gt;&gt;&gt; a

 1.3225  1.7304  1.4573
-0.3052 -0.3111 -0.1809
 1.2469  0.0064 -1.6250
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.triu(a)

 1.3225  1.7304  1.4573
 0.0000 -0.3111 -0.1809
 0.0000  0.0000 -1.6250
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.triu(a, diagonal=1)

 0.0000  1.7304  1.4573
 0.0000  0.0000 -0.1809
 0.0000  0.0000  0.0000
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.triu(a, diagonal=-1)

 1.3225  1.7304  1.4573
-0.3052 -0.3111 -0.1809
 0.0000  0.0064 -1.6250
[torch.FloatTensor of size 3x3]

</code></pre>
<h3 id="blas-and-lapack-operations-blaslapack">BLAS and LAPACK Operations (BLAS和LAPACK操作)</h3>
<pre><code class="language-py">torch.addbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor
</code></pre>
<p>执行保存在 <code>batch1</code> 和 <code>batch2</code> 中的矩阵的批量点乘, 伴随着一个减少的相加步骤 (所有的矩阵乘法沿第一维累加). <code>mat</code> 被相加到最终的结果中.</p>
<p><code>batch1</code> 和 <code>batch2</code> 必须是三维的张量, 且每个包含相同数量的矩阵.</p>
<p>如果 <code>batch1</code> 是一个 <code>b x n x m</code> 的张量, <code>batch2</code> 是一个 <code>b x m x p</code>的张量, 那么 <code>mat</code> 必须是 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 且是一个 <code>n x p</code> 的张量, 同时 attr:<code>out</code> 将是一个 <code>n x p</code> 的张量.</p>
<p>换句话说, <img alt="res = (beta * M) + (alpha * sum(batch1_i @ batch2_i, i = 0, b))" src="../img/tex-7ef2304a9f7469a9bd7902e33b85981c.gif" /></p>
<p>对于 <code>FloatTensor</code> 或者 <code>DoubleTensor</code> 类型的输入, 参数 <code>beta</code> 和 <code>alpha</code> 必须是实数, 否则他们应该是整数.</p>
<p>参数：</p>
<ul>
<li><code>beta (Number, 可选)</code> – 作用于 <code>mat</code> 的乘子 (系数)</li>
<li><code>mat (Tensor)</code> – 要被相加的矩阵</li>
<li><code>alpha (Number, 可选)</code> – 作用于 <code>batch1 @ batch2</code> 的乘子</li>
<li><code>batch1 (Tensor)</code> – 要相乘的第一批矩阵</li>
<li><code>batch2 (Tensor)</code> – 要相乘的第二批矩阵</li>
<li><code>out (Tensor, 可选)</code> – 输出的张量结果</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; M = torch.randn(3, 5)
&gt;&gt;&gt; batch1 = torch.randn(10, 3, 4)
&gt;&gt;&gt; batch2 = torch.randn(10, 4, 5)
&gt;&gt;&gt; torch.addbmm(M, batch1, batch2)

 -3.1162  11.0071   7.3102   0.1824  -7.6892
 1.8265   6.0739   0.4589  -0.5641  -5.4283
 -9.3387  -0.1794  -1.2318  -6.8841  -4.7239
[torch.FloatTensor of size 3x5]

</code></pre>
<pre><code class="language-py">torch.addmm(beta=1, mat, alpha=1, mat1, mat2, out=None) → Tensor
</code></pre>
<p>执行矩阵 <code>mat1</code> 和 <code>mat2</code> 的相乘. 矩阵 <code>mat</code> 将与相乘的最终计算结果相加.</p>
<p>如果 <code>mat1</code> 是一个 <code>n x m</code> 的张量, <code>mat2</code> 是一个 <code>m x p</code>的张量, 那么 <code>mat</code> 必须是 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 且是一个 <code>n x p</code> 的张量, 同时 attr:<code>out</code> 将是一个 <code>n x p</code> 的张量.</p>
<p>换句话说, <img alt="out = (beta * M) + (alpha * mat1 @ mat2)" src="../img/tex-3136ca146acddc296c21d3faf3238418.gif" /></p>
<p>对于 <code>FloatTensor</code> 或者 <code>DoubleTensor</code> 类型的输入, 参数 <code>beta</code> 和 <code>alpha</code> 必须是实数, 否则他们应该是整数.</p>
<p>参数：</p>
<ul>
<li><code>beta (Number, 可选)</code> – 作用于<code>mat</code>的乘子</li>
<li><code>mat (Tensor)</code> – 要被相加的矩阵</li>
<li><code>alpha (Number, 可选)</code> – 作用于<code>mat1 @ mat2</code>的乘子</li>
<li><code>mat1 (Tensor)</code> – 要相乘的第一个矩阵</li>
<li><code>mat2 (Tensor)</code> – 要相乘的第二个矩阵</li>
<li><code>out (Tensor, 可选)</code> – 输出结果</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; M = torch.randn(2, 3)
&gt;&gt;&gt; mat1 = torch.randn(2, 3)
&gt;&gt;&gt; mat2 = torch.randn(3, 3)
&gt;&gt;&gt; torch.addmm(M, mat1, mat2)

-0.4095 -1.9703  1.3561
 5.7674 -4.9760  2.7378
[torch.FloatTensor of size 2x3]

</code></pre>
<pre><code class="language-py">torch.addmv(beta=1, tensor, alpha=1, mat, vec, out=None) → Tensor
</code></pre>
<p>执行矩阵 <code>mat</code> 和向量 <code>vec</code> 的相乘. 矩阵 <code>tensor</code> 将与相乘的最终计算结果相加.</p>
<p>如果 <code>mat</code> 是一个 <code>n x m</code> 的张量, <code>vec</code> 是一个长度为 <code>m</code> 的一维张量, 那么 :<code>tensor</code> 必须是 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 且是一个长度为 <code>n</code> 的一维张量, 同时 attr:<code>out</code> 将是一个长度为 <code>n</code> 的一维张量.</p>
<p><code>alpha</code> 和 <code>beta</code> 分别是 <code>mat * vec</code> 和 <code>tensor</code> 的缩放因子.</p>
<p>换句话说, <img alt="out = (beta * tensor) + (alpha * (mat @ vec2))" src="../img/tex-cbf642b6dbf68ac19bcc426976b8a0d5.gif" /></p>
<p>对于 <code>FloatTensor</code> 或者 <code>DoubleTensor</code> 类型的输入, 参数 <code>beta</code> 和 <code>alpha</code> 必须是实数, 否则他们应该是整数.</p>
<p>参数：</p>
<ul>
<li><code>beta (Number, 可选)</code> – 作用于 <code>tensor</code> 的乘子</li>
<li><code>tensor (Tensor)</code> – 要被相加的向量</li>
<li><code>alpha (Number, 可选)</code> – 作用于 <code>mat @ vec</code> 的乘子</li>
<li><code>mat (Tensor)</code> – 要被相乘的矩阵</li>
<li><code>vec (Tensor)</code> – 要被要乘的向量</li>
<li><code>out (Tensor, 可选)</code> – 输出结果</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; M = torch.randn(2)
&gt;&gt;&gt; mat = torch.randn(2, 3)
&gt;&gt;&gt; vec = torch.randn(3)
&gt;&gt;&gt; torch.addmv(M, mat, vec)

-2.0939
-2.2950
[torch.FloatTensor of size 2]

</code></pre>
<pre><code class="language-py">torch.addr(beta=1, mat, alpha=1, vec1, vec2, out=None) → Tensor
</code></pre>
<p>执行向量 <code>vec1</code> 和 <code>vec2</code> 的外积, 并把外积计算结果与矩阵 <code>mat</code> 相加.</p>
<p>可选值 <code>beta</code> 和 <code>alpha</code> 是标量, 分别与 <code>mat</code> 和 <img alt="(vec1 \otimes vec2)" src="../img/tex-ab16a4d3626255c0f2ff1b18ec903b95.gif" /> 相乘.</p>
<p>换句话说, <img alt="out = (beta * mat) + (alpha * vec1 \otimes vec2)" src="../img/tex-bbe0ebf0dbe9721a25240f560ff6e3ff.gif" /></p>
<p>如果 <code>vec1</code> 是一个长度为 <code>n</code> 的向量, <code>vec2</code> 是一个长度为 <code>m</code> 的向量, 那么 <code>mat</code> 必须是 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 且是一个大小为 <code>n x m</code> 的矩阵, 同时 <code>out</code> 将是一个大小为 <code>n x m</code> 的矩阵.</p>
<p>对于 <code>FloatTensor</code> 或者 <code>DoubleTensor</code> 类型的输入, 参数 <code>beta</code> 和 <code>alpha</code> 必须是实数, 否则他们应该是整数.</p>
<p>参数：</p>
<ul>
<li><code>beta (Number, 可选)</code> – 作用于 <code>mat</code> 的乘子</li>
<li><code>mat (Tensor)</code> – 要被相加的矩阵</li>
<li><code>alpha (Number, 可选)</code> – 作用于 <code>vec1</code> 和 <code>vec2</code> 外积计算结果的乘子</li>
<li><code>vec1 (Tensor)</code> – 外积计算的第一个向量</li>
<li><code>vec2 (Tensor)</code> – 外积计算的第二个向量</li>
<li><code>out (Tensor, 可选)</code> – 输出结果</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; vec1 = torch.arange(1, 4)
&gt;&gt;&gt; vec2 = torch.arange(1, 3)
&gt;&gt;&gt; M = torch.zeros(3, 2)
&gt;&gt;&gt; torch.addr(M, vec1, vec2)
 1  2
 2  4
 3  6
[torch.FloatTensor of size 3x2]

</code></pre>
<pre><code class="language-py">torch.baddbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor
</code></pre>
<p>执行保存在 <code>batch1</code> 和 <code>batch2</code> 中的矩阵的批量点乘. <code>mat</code> 被相加到最终的结果中.</p>
<p><code>batch1</code> 和 <code>batch2</code> 必须是三维的张量, 且每个包含相同数量的矩阵.</p>
<p>如果 <code>batch1</code> 是一个 <code>b x n x m</code> 的张量, <code>batch2</code> 是一个 <code>b x m x p</code>的张量, 那么 <code>mat</code> 必须是 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> 且是一个 <code>b x n x p</code> 的张量, 同时 attr:<code>out</code> 将是一个 <code>b x n x p</code> 的张量.</p>
<p>换句话说, <img alt="res_i = (beta * M_i) + (alpha * batch1_i \times batch2_i)" src="../img/tex-4c174ea27877cea5aeef8649acf33a61.gif" /></p>
<p>对于 <code>FloatTensor</code> 或者 <code>DoubleTensor</code> 类型的输入, 参数 <code>beta</code> 和 <code>alpha</code> 必须是实数, 否则他们应该是整数.</p>
<p>参数：</p>
<ul>
<li><code>beta (Number, 可选)</code> – 作用于 <code>mat</code> 的乘子 (系数)</li>
<li><code>mat (Tensor)</code> – 要被相加的张量</li>
<li><code>alpha (Number, 可选)</code> – 作用于 <code>batch1 @ batch2</code> 的乘子</li>
<li><code>batch1 (Tensor)</code> – 要相乘的第一批矩阵</li>
<li><code>batch2 (Tensor)</code> – 要相乘的第二批矩阵</li>
<li><code>out (Tensor, 可选)</code> – 输出的张量结果</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; M = torch.randn(10, 3, 5)
&gt;&gt;&gt; batch1 = torch.randn(10, 3, 4)
&gt;&gt;&gt; batch2 = torch.randn(10, 4, 5)
&gt;&gt;&gt; torch.baddbmm(M, batch1, batch2).size()
torch.Size([10, 3, 5])

</code></pre>
<pre><code class="language-py">torch.bmm(batch1, batch2, out=None) → Tensor
</code></pre>
<p>执行保存在 <code>batch1</code> 和 <code>batch2</code> 中的矩阵的批量点乘.</p>
<p><code>batch1</code> 和 <code>batch2</code> 必须是三维的张量, 且每个包含相同数量的矩阵.</p>
<p>如果 <code>batch1</code> 是一个 <code>b x n x m</code> 的张量, <code>batch2</code> 是一个 <code>b x m x p</code> 的张量, <code>out</code> 将是一个 <code>b x n x p</code> 的张量.</p>
<p>注解：</p>
<p>这个函数不能参考 broadcast](notes/broadcasting.html#broadcasting-semantics). 对于广播矩阵相乘, 参见 [<code>torch.matmul()</code>.</p>
<p>参数：</p>
<ul>
<li><code>batch1 (Tensor)</code> – 要相乘的第一批矩阵</li>
<li><code>batch2 (Tensor)</code> – 要相乘的第二批矩阵</li>
<li><code>out (Tensor, 可选)</code> – 输出结果</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; batch1 = torch.randn(10, 3, 4)
&gt;&gt;&gt; batch2 = torch.randn(10, 4, 5)
&gt;&gt;&gt; res = torch.bmm(batch1, batch2)
&gt;&gt;&gt; res.size()
torch.Size([10, 3, 5])

</code></pre>
<pre><code class="language-py">torch.btrifact(A, info=None, pivot=True) → Tensor, IntTensor
</code></pre>
<p>批量 LU 分解.</p>
<p>返回一个包含 LU 分解和枢轴的元组. 对于每个 minibatch 示例, 如果分解成功, 可选参数 <code>info</code> 将提供分解信息. <code>info</code> 的值来自 dgetrf, 若是非零值, 则表示有错误发生. 如果 cuda 被使用的话, 具体的值来自 cublas, 否则来自 LAPACK. 如果设置了 pivot, 那么旋转操作将被执行.</p>
<p>参数：<code>A (Tensor)</code> – 要分解的张量.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; A = torch.randn(2, 3, 3)
&gt;&gt;&gt; A_LU = A.btrifact()

</code></pre>
<pre><code class="language-py">torch.btrisolve(b, LU_data, LU_pivots) → Tensor
</code></pre>
<p>批量 LU 解.</p>
<p>返回线性系统 Ax = b 的 LU 解.</p>
<p>参数：</p>
<ul>
<li><code>b (Tensor)</code> – RHS tensor.</li>
<li><code>LU_data (Tensor)</code> – Pivoted LU factorization of A from btrifact.</li>
<li><code>LU_pivots (IntTensor)</code> – Pivots of the LU factorization.</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; A = torch.randn(2, 3, 3)
&gt;&gt;&gt; b = torch.randn(2, 3)
&gt;&gt;&gt; A_LU = torch.btrifact(A)
&gt;&gt;&gt; x = b.btrisolve(*A_LU)
&gt;&gt;&gt; torch.norm(A.bmm(x.unsqueeze(2)) - b)
6.664001874625056e-08

</code></pre>
<pre><code class="language-py">torch.dot(tensor1, tensor2) → float
</code></pre>
<p>计算两个张量的点乘 (内积).</p>
<p>注解：</p>
<p>这个函数不支持 <a href="notes/broadcasting.html#broadcasting-semantics">broadcast</a>.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; torch.dot(torch.Tensor([2, 3]), torch.Tensor([2, 1]))
7.0

</code></pre>
<pre><code class="language-py">torch.eig(a, eigenvectors=False, out=None) -&gt; (Tensor, Tensor)
</code></pre>
<p>计算实数方阵的特征值和特征向量.</p>
<p>参数：</p>
<ul>
<li><code>a (Tensor)</code> – 一个要被计算特征值与特征向量的方阵</li>
<li><code>eigenvectors (bool)</code> – 若为 <code>True</code>, 表示特征值与特征向量都被计算. 否则, 仅计算特征值.</li>
<li><code>out (tuple, 可选)</code> – 输出张量</li>
</ul>
<p>返回值：包含以下的元组：</p>
<ul>
<li><code>e (Tensor)</code>: <code>a</code> 的左特征值</li>
<li><code>v (Tensor)</code>: 如果 <code>eigenvectors</code> 为 <code>True</code>, 表示 <code>a</code> 的特征向量; 否则是一个空的张量</li>
</ul>
<p>返回类型：返回一个元组, <code>(Tensor, Tensor)</code></p>
<pre><code class="language-py">torch.gels(B, A, out=None) → Tensor
</code></pre>
<p>计算秩为 <img alt="m" src="../img/tex-6f8f57715090da2632453988d9a1501b.gif" /> 的， 大小为 m x n 的矩阵 <img alt="A" src="../img/tex-7fc56270e7a70fa81a5935b72eacbe29.gif" /> 最小二乘和最小范数问题的解</p>
<p>如果 !m &gt;= n](img/tex-67ab86856a95fdd869cf2a0fff67d8be.gif), [<code>gels()</code> 求解最小二乘问题:</p>
<p><img alt="\begin{array}{ll} \mbox{minimize} &amp; |AX-B|_F. \end{array}" src="../img/tex-e616b1701f9adb598d4bc4809d5d9d13.gif" /></p>
<p>如果 !m &lt; n](img/tex-ad3a40ab7b4c9be133873408eb36bcc1.gif), [<code>gels()</code> 求解最小范数问题:</p>
<p><img alt="\begin{array}{ll} \mbox{minimize} &amp; |X|_F &amp; \mbox{subject to} &amp; AX = B. \end{array}" src="../img/tex-3f143297c60126363ebd87566cbf4d03.gif" /></p>
<p>返回的矩阵 <img alt="X" src="../img/tex-02129bb861061d1a052c592e2dc6b383.gif" /> 的头 <img alt="n" src="../img/tex-7b8b965ad4bca0e41ab51de7b31363a1.gif" /> 行包含解信息. 其余行包含剩余信息: 从第 <img alt="n" src="../img/tex-7b8b965ad4bca0e41ab51de7b31363a1.gif" /> 行开始的每列的 euclidean 范数, 是对应列的剩余.</p>
<p>参数：</p>
<ul>
<li><code>B (Tensor)</code> – The matrix <img alt="B" src="../img/tex-9d5ed678fe57bcca610140957afab571.gif" /></li>
<li><code>A (Tensor)</code> – The <img alt="m" src="../img/tex-6f8f57715090da2632453988d9a1501b.gif" /> by <img alt="n" src="../img/tex-7b8b965ad4bca0e41ab51de7b31363a1.gif" /> matrix <img alt="A" src="../img/tex-7fc56270e7a70fa81a5935b72eacbe29.gif" /></li>
<li><code>out (tuple, 可选)</code> – Optional destination tensor</li>
</ul>
<p>返回值：包含以下的元组：</p>
<ul>
<li><code>X (Tensor)</code>: 最小二乘解</li>
<li><code>qr (Tensor)</code>: QR 分解的详细信息</li>
</ul>
<p>返回类型：<code>(Tensor, Tensor)</code></p>
<p>注解：</p>
<p>不管输入矩阵的步长如何, 返回来的矩阵将总是被转置. 也就是, 他们的步长是 <code>(1, m)</code> 而不是 <code>(m, 1)</code>.</p>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; A = torch.Tensor([[1, 1, 1],
...                   [2, 3, 4],
...                   [3, 5, 2],
...                   [4, 2, 5],
...                   [5, 4, 3]])
&gt;&gt;&gt; B = torch.Tensor([[-10, -3],
 [ 12, 14],
 [ 14, 12],
 [ 16, 16],
 [ 18, 16]])
&gt;&gt;&gt; X, _ = torch.gels(B, A)
&gt;&gt;&gt; X
2.0000  1.0000
1.0000  1.0000
1.0000  2.0000
[torch.FloatTensor of size 3x2]

</code></pre>
<pre><code class="language-py">torch.geqrf(input, out=None) -&gt; (Tensor, Tensor)
</code></pre>
<p>这是直接调用 LAPACK 的低层函数.</p>
<p>通常您应该使用 <code>torch.qr()</code> 来代替之.</p>
<p>计算 <code>input</code> 的 QR 分解, 但不构造 <code>Q</code> 和 <code>R</code> 作为显示分开的矩阵.</p>
<p>然而, 这样直接调用 LAPACK 的底层函数 <code>?geqrf</code>, 会产生一连串的 'elementary reflectors'.</p>
<p>更多信息请参见 <a href="https://software.intel.com/en-us/node/521004">LAPACK documentation</a> .</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – the input matrix</li>
<li><code>out (tuple, 可选)</code> – The result tuple of (Tensor, Tensor)</li>
</ul>
<pre><code class="language-py">torch.ger(vec1, vec2, out=None) → Tensor
</code></pre>
<p>计算 <code>vec1</code> 和 <code>vec2</code> 的外积. 如果 <code>vec1</code> 是一个长度为 <code>n</code> 的向量, <code>vec2</code> 是一个长度为 <code>m</code> 的向量, 那么 <code>out</code> 必须是一个 <code>n x m</code> 的矩阵.</p>
<p>注解：</p>
<p>这个函数不支持 <a href="notes/broadcasting.html#broadcasting-semantics">broadcast</a>.</p>
<p>参数：</p>
<ul>
<li><code>vec1 (Tensor)</code> – 1D input vector</li>
<li><code>vec2 (Tensor)</code> – 1D input vector</li>
<li><code>out (Tensor, 可选)</code> – optional output matrix</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; v1 = torch.arange(1, 5)
&gt;&gt;&gt; v2 = torch.arange(1, 4)
&gt;&gt;&gt; torch.ger(v1, v2)

 1   2   3
 2   4   6
 3   6   9
 4   8  12
[torch.FloatTensor of size 4x3]

</code></pre>
<pre><code class="language-py">torch.gesv(B, A, out=None) -&gt; (Tensor, Tensor)
</code></pre>
<p><code>X, LU = torch.gesv(B, A)</code> , 该函数返回线性系统 <img alt="AX = B" src="../img/tex-87f9241ed3c96b751dca1150b5510ed0.gif" /> 的解.</p>
<p><code>LU</code> 包含 <code>A</code> 的 LU 分解因子 <code>L</code> 和 <code>U</code>.</p>
<p><code>A</code> 必须是方阵, 且是非奇异的 (2维可逆张量).</p>
<p>如果 <code>A</code> 是一个 <code>m x m</code> 矩阵, <code>B</code> 是一个 <code>m x k</code> 的矩阵, 那么结果 <code>LU</code> 的大小为 <code>m x m</code>, <code>X</code> 的大小为 <code>m x k</code> .</p>
<p>注解：</p>
<p>Irrespective of the original strides, the returned matrices <code>X</code> and <code>LU</code> will be transposed, i.e. with strides <code>(1, m)</code> instead of <code>(m, 1)</code>.</p>
<p>参数：</p>
<ul>
<li><code>B (Tensor)</code> – input matrix of <code>m x k</code> dimensions</li>
<li><code>A (Tensor)</code> – input square matrix of <code>m x m</code> dimensions</li>
<li><code>out (Tensor, 可选)</code> – optional output matrix</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; A = torch.Tensor([[6.80, -2.11,  5.66,  5.97,  8.23],
...                   [-6.05, -3.30,  5.36, -4.44,  1.08],
...                   [-0.45,  2.58, -2.70,  0.27,  9.04],
...                   [8.32,  2.71,  4.35,  -7.17,  2.14],
...                   [-9.67, -5.14, -7.26,  6.08, -6.87]]).t()
&gt;&gt;&gt; B = torch.Tensor([[4.02,  6.19, -8.22, -7.57, -3.03],
...                   [-1.56,  4.00, -8.67,  1.75,  2.86],
...                   [9.81, -4.09, -4.57, -8.61,  8.99]]).t()
&gt;&gt;&gt; X, LU = torch.gesv(B, A)
&gt;&gt;&gt; torch.dist(B, torch.mm(A, X))
9.250057093890353e-06

</code></pre>
<pre><code class="language-py">torch.inverse(input, out=None) → Tensor
</code></pre>
<p>计算方阵 <code>input</code> 的逆.</p>
<p>注解：</p>
<p>Irrespective of the original strides, the returned matrix will be transposed, i.e. with strides <code>(1, m)</code> instead of <code>(m, 1)</code></p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – the input 2D square <code>Tensor</code></li>
<li><code>out (Tensor, 可选)</code> – the optional output <code>Tensor</code></li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; x = torch.rand(10, 10)
&gt;&gt;&gt; x

 0.7800  0.2267  0.7855  0.9479  0.5914  0.7119  0.4437  0.9131  0.1289  0.1982
 0.0045  0.0425  0.2229  0.4626  0.6210  0.0207  0.6338  0.7067  0.6381  0.8196
 0.8350  0.7810  0.8526  0.9364  0.7504  0.2737  0.0694  0.5899  0.8516  0.3883
 0.6280  0.6016  0.5357  0.2936  0.7827  0.2772  0.0744  0.2627  0.6326  0.9153
 0.7897  0.0226  0.3102  0.0198  0.9415  0.9896  0.3528  0.9397  0.2074  0.6980
 0.5235  0.6119  0.6522  0.3399  0.3205  0.5555  0.8454  0.3792  0.4927  0.6086
 0.1048  0.0328  0.5734  0.6318  0.9802  0.4458  0.0979  0.3320  0.3701  0.0909
 0.2616  0.3485  0.4370  0.5620  0.5291  0.8295  0.7693  0.1807  0.0650  0.8497
 0.1655  0.2192  0.6913  0.0093  0.0178  0.3064  0.6715  0.5101  0.2561  0.3396
 0.4370  0.4695  0.8333  0.1180  0.4266  0.4161  0.0699  0.4263  0.8865  0.2578
[torch.FloatTensor of size 10x10]

&gt;&gt;&gt; x = torch.rand(10, 10)
&gt;&gt;&gt; y = torch.inverse(x)
&gt;&gt;&gt; z = torch.mm(x, y)
&gt;&gt;&gt; z

 1.0000  0.0000  0.0000 -0.0000  0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000
 0.0000  1.0000 -0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000 -0.0000 -0.0000
 0.0000  0.0000  1.0000 -0.0000 -0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000
 0.0000  0.0000  0.0000  1.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000  0.0000
 0.0000  0.0000 -0.0000 -0.0000  1.0000  0.0000  0.0000 -0.0000 -0.0000 -0.0000
 0.0000  0.0000  0.0000 -0.0000  0.0000  1.0000 -0.0000 -0.0000 -0.0000 -0.0000
 0.0000  0.0000  0.0000 -0.0000  0.0000  0.0000  1.0000  0.0000 -0.0000  0.0000
 0.0000  0.0000 -0.0000 -0.0000  0.0000  0.0000 -0.0000  1.0000 -0.0000  0.0000
-0.0000  0.0000 -0.0000 -0.0000  0.0000  0.0000 -0.0000 -0.0000  1.0000 -0.0000
-0.0000  0.0000 -0.0000 -0.0000 -0.0000  0.0000 -0.0000 -0.0000  0.0000  1.0000
[torch.FloatTensor of size 10x10]

&gt;&gt;&gt; torch.max(torch.abs(z - torch.eye(10))) # Max nonzero
5.096662789583206e-07

</code></pre>
<pre><code class="language-py">torch.matmul(tensor1, tensor2, out=None)
</code></pre>
<p>Matrix product of two tensors.</p>
<p>The behavior depends on the dimensionality of the tensors as follows:</p>
<ul>
<li>If both tensors are 1-dimensional, the dot product (scalar) is returned.</li>
<li>If both arguments are 2-dimensional, the matrix-matrix product is returned.</li>
<li>If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.</li>
<li>If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned.</li>
<li>If both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N &gt; 2), then a batched matrix multiply is returned. If the first argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the batched matrix multiply and removed after. If the second argument is 1-dimensional, a 1 is appended to its dimension for the purpose of the batched matrix multiple and removed after. The non-matrix (i.e. batch) dimensions are <a href="notes/broadcasting.html#broadcasting-semantics">broadcasted</a> (and thus must be broadcastable). For example, if <code>tensor1</code> is a <code>j x 1 x n x m</code> Tensor and <code>tensor2</code> is a <code>k x m x p</code> Tensor, <code>out</code> will be an <code>j x k x n x p</code> Tensor.</li>
</ul>
<p>注解：</p>
<p>The 1-dimensional dot product version of this function does not support an <code>out</code> parameter.</p>
<p>参数：</p>
<ul>
<li><code>tensor1 (Tensor)</code> – First tensor to be multiplied</li>
<li><code>tensor2 (Tensor)</code> – Second tensor to be multiplied</li>
<li><code>out (Tensor, 可选)</code> – Output tensor</li>
</ul>
<pre><code class="language-py">torch.mm(mat1, mat2, out=None) → Tensor
</code></pre>
<p>执行 <code>mat1</code> 和 <code>mat2</code> 的矩阵乘法.</p>
<p>如果 <code>mat1</code> 是一个 <code>n x m</code> 张量, <code>mat2</code> 是一个 <code>m x p</code> 张量, <code>out</code> 将是一个 <code>n x p</code> 张量.</p>
<p>注解：</p>
<p>这个函数不支持 broadcast](notes/broadcasting.html#broadcasting-semantics). 要使用支持广播矩阵乘法, 参见 [<code>torch.matmul()</code>.</p>
<p>参数：</p>
<ul>
<li><code>mat1 (Tensor)</code> – First matrix to be multiplied</li>
<li><code>mat2 (Tensor)</code> – Second matrix to be multiplied</li>
<li><code>out (Tensor, 可选)</code> – Output tensor</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; mat1 = torch.randn(2, 3)
&gt;&gt;&gt; mat2 = torch.randn(3, 3)
&gt;&gt;&gt; torch.mm(mat1, mat2)
 0.0519 -0.3304  1.2232
 4.3910 -5.1498  2.7571
[torch.FloatTensor of size 2x3]

</code></pre>
<pre><code class="language-py">torch.mv(mat, vec, out=None) → Tensor
</code></pre>
<p>执行矩阵 <code>mat</code> 与向量 <code>vec</code> 的乘法操作.</p>
<p>如果 <code>mat</code> 是一个 <code>n x m</code> 张量, <code>vec</code> 是一个大小为 <code>m</code> 的一维张量, <code>out</code> 将是一个大小为 <code>n</code> 的张量.</p>
<p>注解：</p>
<p>这个函数不支持 <a href="notes/broadcasting.html#broadcasting-semantics">broadcast</a>.</p>
<p>参数：</p>
<ul>
<li><code>mat (Tensor)</code> – matrix to be multiplied</li>
<li><code>vec (Tensor)</code> – vector to be multiplied</li>
<li><code>out (Tensor, 可选)</code> – Output tensor</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; mat = torch.randn(2, 3)
&gt;&gt;&gt; vec = torch.randn(3)
&gt;&gt;&gt; torch.mv(mat, vec)
-2.0939
-2.2950
[torch.FloatTensor of size 2]

</code></pre>
<pre><code class="language-py">torch.orgqr()
</code></pre>
<pre><code class="language-py">torch.ormqr()
</code></pre>
<pre><code class="language-py">torch.potrf(a, out=None)
</code></pre>
<p>potrf(a, upper, out=None)</p>
<p>计算半正定矩阵 <code>a</code>: 的 Cholesky 分解. 返回结果 <code>u</code>, 若 <code>upper</code> 设为 <code>True</code> 或未提供时, <code>u</code> 是一个上三角矩阵, 使得 <img alt="a = u^T u" src="../img/tex-a495982217ecb8f8c1c154c349699217.gif" /> 成立; 若 <code>upper</code> 设为 <code>False</code>, <code>u</code> 是一个下三角矩阵, 使得 <img alt="a = u u^T" src="../img/tex-af2a8f54be49d4fb8cc53b20d501b681.gif" /> 成立.</p>
<p>参数：</p>
<ul>
<li><code>a (Tensor)</code> – the input 2D <code>Tensor</code>, a symmetric positive semidefinite matrix</li>
<li><code>upper (bool, 可选)</code> – Return upper (default) or lower triangular matrix</li>
<li><code>out (Tensor, 可选)</code> – A Tensor for u</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3,3)
&gt;&gt;&gt; a = torch.mm(a, a.t()) # make symmetric positive definite
&gt;&gt;&gt; u = torch.potrf(a)
&gt;&gt;&gt; a

 2.3563  3.2318 -0.9406
 3.2318  4.9557 -2.1618
-0.9406 -2.1618  2.2443
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; u

 1.5350  2.1054 -0.6127
 0.0000  0.7233 -1.2053
 0.0000  0.0000  0.6451
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.mm(u.t(),u)

 2.3563  3.2318 -0.9406
 3.2318  4.9557 -2.1618
-0.9406 -2.1618  2.2443
[torch.FloatTensor of size 3x3]

</code></pre>
<pre><code class="language-py">torch.potri(u, out=None)
</code></pre>
<p>potri(u, upper, out=None)</p>
<p>给定一个半正定矩阵的 Cholesky 分解因子 <code>u</code>, 计算该半正定矩阵的逆. 返回矩阵 <code>inv</code>, 若 <code>upper</code> 设为 <code>True</code> 或为提供, <code>u</code> 是一个上三角矩阵, 使得 <img alt="inv = (u^T u)^{-1}" src="../img/tex-9c4b0a3ec8f2662acb48158c085131b6.gif" /> 成立; 若 <code>upper</code> 设为 <code>False</code>, <code>u</code> 是一个下三角矩阵, 使得 <img alt="inv = (u u^T)^{-1}" src="../img/tex-a516e9c3e09592a93fa8a11efe052352.gif" /> 成立.</p>
<p>参数：</p>
<ul>
<li><code>u (Tensor)</code> – the input 2D <code>Tensor</code>, a upper or lower triangular Cholesky factor</li>
<li><code>upper (bool, 可选)</code> – Flag if upper (default) or lower triangular matrix</li>
<li><code>out (Tensor, 可选)</code> – A Tensor for inv</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3,3)
&gt;&gt;&gt; a = torch.mm(a, a.t()) # make symmetric positive definite
&gt;&gt;&gt; u = torch.potrf(a)
&gt;&gt;&gt; a

 2.3563  3.2318 -0.9406
 3.2318  4.9557 -2.1618
-0.9406 -2.1618  2.2443
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.potri(u)

 12.5724 -10.1765  -4.5333
-10.1765   8.5852   4.0047
 -4.5333   4.0047   2.4031
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; a.inverse()

 12.5723 -10.1765  -4.5333
-10.1765   8.5852   4.0047
 -4.5333   4.0047   2.4031
[torch.FloatTensor of size 3x3]

</code></pre>
<pre><code class="language-py">torch.potrs(b, u, out=None)
</code></pre>
<p>potrs(b, u, upper, out=None)</p>
<p>Solves a linear system of equations with a positive semidefinite matrix to be inverted given its given a Cholesky factor matrix <code>u</code>: returns matrix <code>c</code> If <code>upper</code> is <code>True</code> or not provided, <code>u</code> is and upper triangular such that <img alt="c = (u^T u)^{-1} b" src="../img/tex-8adaa3f465e6b647154735a77655849a.gif" />. If <code>upper</code> is <code>False</code>, <code>u</code> is and lower triangular such that <img alt="c = (u u^T)^{-1} b" src="../img/tex-d746800a59c0e059328a7275a82f2109.gif" />.</p>
<p>注解：</p>
<p><code>b</code> is always a 2D <code>Tensor</code>, use <code>b.unsqueeze(1)</code> to convert a vector.</p>
<p>参数：</p>
<ul>
<li><code>b (Tensor)</code> – the right hand side 2D <code>Tensor</code></li>
<li><code>u (Tensor)</code> – the input 2D <code>Tensor</code>, a upper or lower triangular Cholesky factor</li>
<li><code>upper (bool, 可选)</code> – Return upper (default) or lower triangular matrix</li>
<li><code>out (Tensor, 可选)</code> – A Tensor for c</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3,3)
&gt;&gt;&gt; a = torch.mm(a, a.t()) # make symmetric positive definite
&gt;&gt;&gt; u = torch.potrf(a)
&gt;&gt;&gt; a

 2.3563  3.2318 -0.9406
 3.2318  4.9557 -2.1618
-0.9406 -2.1618  2.2443
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; b = torch.randn(3,2)
&gt;&gt;&gt; b

-0.3119 -1.8224
-0.2798  0.1789
-0.3735  1.7451
[torch.FloatTensor of size 3x2]

&gt;&gt;&gt; torch.potrs(b,u)

 0.6187 -32.6438
-0.7234  27.0703
-0.6039  13.1717
[torch.FloatTensor of size 3x2]

&gt;&gt;&gt; torch.mm(a.inverse(),b)

 0.6187 -32.6436
-0.7234  27.0702
-0.6039  13.1717
[torch.FloatTensor of size 3x2]

</code></pre>
<pre><code class="language-py">torch.pstrf(a, out=None)
</code></pre>
<p>pstrf(a, upper, out=None)</p>
<p>Computes the pivoted Cholesky decomposition of a positive semidefinite matrix <code>a</code>: returns matrices <code>u</code> and <code>piv</code>. If <code>upper</code> is <code>True</code> or not provided, <code>u</code> is and upper triangular such that <img alt="a = p^T u^T u p" src="../img/tex-a15f289c6963aee50745ebf64701af1a.gif" />, with <code>p</code> the permutation given by <code>piv</code>. If <code>upper</code> is <code>False</code>, <code>u</code> is and lower triangular such that <img alt="a = p^T u u^T p" src="../img/tex-09b54d58ebd0ed1f4092bda5c5ecb4f8.gif" />.</p>
<p>参数：</p>
<ul>
<li><code>a (Tensor)</code> – the input 2D <code>Tensor</code></li>
<li><code>upper (bool, 可选)</code> – Return upper (default) or lower triangular matrix</li>
<li><code>out (tuple, 可选)</code> – A tuple of u and piv Tensors</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.randn(3,3)
&gt;&gt;&gt; a = torch.mm(a, a.t()) # make symmetric positive definite
&gt;&gt;&gt; a

 5.4417 -2.5280  1.3643
-2.5280  2.9689 -2.1368
 1.3643 -2.1368  4.6116
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; u,piv = torch.pstrf(a)
&gt;&gt;&gt; u

 2.3328  0.5848 -1.0837
 0.0000  2.0663 -0.7274
 0.0000  0.0000  1.1249
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; piv

 0
 2
 1
[torch.IntTensor of size 3]

&gt;&gt;&gt; p = torch.eye(3).index_select(0,piv.long()).index_select(0,piv.long()).t() # make pivot permutation
&gt;&gt;&gt; torch.mm(torch.mm(p.t(),torch.mm(u.t(),u)),p) # reconstruct

 5.4417  1.3643 -2.5280
 1.3643  4.6116 -2.1368
-2.5280 -2.1368  2.9689
[torch.FloatTensor of size 3x3]

</code></pre>
<pre><code class="language-py">torch.qr(input, out=None) -&gt; (Tensor, Tensor)
</code></pre>
<p>计算矩阵 <code>input</code> 的 QR 分解. 返回矩阵 <code>q</code> 和 <code>r</code> 使得 <img alt="x = q * r" src="../img/tex-cdbaa8a802c8ac5fb33dc85e271f4b34.gif" />, 且 <code>q</code> 是一个 正交矩阵, <code>r</code> 是一个上三角矩阵.</p>
<p>This returns the thin (reduced) QR factorization.</p>
<p>注解：</p>
<p>如果矩阵 <code>input</code> 中的元素太大, 那么精度可能会丢失.</p>
<p>注解：</p>
<p>尽管该函数总是能给您一个有效的分解, 但在不同平台上结果可能不同 - 取决于该平台上 LAPACK 的实现.</p>
<p>注解：</p>
<p>Irrespective of the original strides, the returned matrix <code>q</code> will be transposed, i.e. with strides <code>(1, m)</code> instead of <code>(m, 1)</code>.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – the input 2D <code>Tensor</code></li>
<li><code>out (tuple, 可选)</code> – A tuple of Q and R Tensors</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.Tensor([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])
&gt;&gt;&gt; q, r = torch.qr(a)
&gt;&gt;&gt; q

-0.8571  0.3943  0.3314
-0.4286 -0.9029 -0.0343
 0.2857 -0.1714  0.9429
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; r

 -14.0000  -21.0000   14.0000
 0.0000 -175.0000   70.0000
 0.0000    0.0000  -35.0000
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.mm(q, r).round()

 12  -51    4
 6  167  -68
 -4   24  -41
[torch.FloatTensor of size 3x3]

&gt;&gt;&gt; torch.mm(q.t(), q).round()

 1 -0  0
-0  1  0
 0  0  1
[torch.FloatTensor of size 3x3]

</code></pre>
<pre><code class="language-py">torch.svd(input, some=True, out=None) -&gt; (Tensor, Tensor, Tensor)
</code></pre>
<p><code>U, S, V = torch.svd(A)</code> 返回大小为 <code>(n x m)</code> 的实矩阵 <code>A</code> 的奇异值分解, 使得 <img alt="A = USV'*" src="../img/tex-c887f05a8f17cc1865be06bf5709faef.gif" />.</p>
<p><code>U</code> 的大小为 <code>n x n</code></p>
<p><code>S</code> 的大小为<code>n x m</code></p>
<p><code>V</code> 的大小为 <code>m x m</code>.</p>
<p><code>some</code> 表示将被计算的奇异值的总数. 如果 <code>some=True</code>, 它将计算指定的 some 数量个奇异值, 如果 <code>some=False</code>, 则计算所有奇异值.</p>
<p>注解：</p>
<p>Irrespective of the original strides, the returned matrix <code>U</code> will be transposed, i.e. with strides <code>(1, n)</code> instead of <code>(n, 1)</code>.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – the input 2D Tensor</li>
<li><code>some (bool, 可选)</code> – controls the number of singular values to be computed</li>
<li><code>out (tuple, 可选)</code> – the result tuple</li>
</ul>
<p>示例：</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.Tensor([[8.79,  6.11, -9.15,  9.57, -3.49,  9.84],
...                   [9.93,  6.91, -7.93,  1.64,  4.02,  0.15],
...                   [9.83,  5.04,  4.86,  8.83,  9.80, -8.99],
...                   [5.45, -0.27,  4.85,  0.74, 10.00, -6.02],
...                   [3.16,  7.98,  3.01,  5.80,  4.27, -5.31]]).t()
&gt;&gt;&gt; a

 8.7900   9.9300   9.8300   5.4500   3.1600
 6.1100   6.9100   5.0400  -0.2700   7.9800
 -9.1500  -7.9300   4.8600   4.8500   3.0100
 9.5700   1.6400   8.8300   0.7400   5.8000
 -3.4900   4.0200   9.8000  10.0000   4.2700
 9.8400   0.1500  -8.9900  -6.0200  -5.3100
[torch.FloatTensor of size 6x5]

&gt;&gt;&gt; u, s, v = torch.svd(a)
&gt;&gt;&gt; u

-0.5911  0.2632  0.3554  0.3143  0.2299
-0.3976  0.2438 -0.2224 -0.7535 -0.3636
-0.0335 -0.6003 -0.4508  0.2334 -0.3055
-0.4297  0.2362 -0.6859  0.3319  0.1649
-0.4697 -0.3509  0.3874  0.1587 -0.5183
 0.2934  0.5763 -0.0209  0.3791 -0.6526
[torch.FloatTensor of size 6x5]

&gt;&gt;&gt; s

 27.4687
 22.6432
 8.5584
 5.9857
 2.0149
[torch.FloatTensor of size 5]

&gt;&gt;&gt; v

-0.2514  0.8148 -0.2606  0.3967 -0.2180
-0.3968  0.3587  0.7008 -0.4507  0.1402
-0.6922 -0.2489 -0.2208  0.2513  0.5891
-0.3662 -0.3686  0.3859  0.4342 -0.6265
-0.4076 -0.0980 -0.4932 -0.6227 -0.4396
[torch.FloatTensor of size 5x5]

&gt;&gt;&gt; torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t()))
8.934150226306685e-06

</code></pre>
<pre><code class="language-py">torch.symeig(input, eigenvectors=False, upper=True, out=None) -&gt; (Tensor, Tensor)
</code></pre>
<p><code>e, V = torch.symeig(input)</code> 返回实对称矩阵 <code>input</code> 的特征值和特征向量.</p>
<p><code>input</code> 和 <code>V</code> 是 <code>m x m</code> 矩阵, <code>e</code> 是一个 <code>m</code> 维的向量.</p>
<p>这个函数计算矩阵 <code>input</code> 的所有特征值 (和向量), 使得 <code>input = V diag(e) V'</code>.</p>
<p>布尔参数 <code>eigenvectors</code> 定义了是否计算特征向量. 如果它为 <code>False</code>, 那么只有特征值会被计算. 如果它为 <code>True</code>, 特征值和特征向量都会被计算.</p>
<p>由于输入矩阵 <code>input</code> 被假定是对称的, 因此默认地只有它的上三角部分会被使用.</p>
<p>如果 <code>upper</code> 是 <code>False</code>, 那么它的下三角部分会被使用.</p>
<p>Note: Irrespective of the original strides, the returned matrix <code>V</code> will be transposed, i.e. with strides <code>(1, m)</code> instead of <code>(m, 1)</code>.</p>
<p>参数：</p>
<ul>
<li><code>input (Tensor)</code> – the input symmetric matrix</li>
<li><code>eigenvectors (boolean, 可选)</code> – controls whether eigenvectors have to be computed</li>
<li><code>upper (boolean, 可选)</code> – controls whether to consider upper-triangular or lower-triangular region</li>
<li><code>out (tuple, 可选)</code> – The result tuple of (Tensor, Tensor)</li>
</ul>
<p>Examples:</p>
<pre><code class="language-py">&gt;&gt;&gt; a = torch.Tensor([[ 1.96,  0.00,  0.00,  0.00,  0.00],
...                   [-6.49,  3.80,  0.00,  0.00,  0.00],
...                   [-0.47, -6.39,  4.17,  0.00,  0.00],
...                   [-7.20,  1.50, -1.51,  5.70,  0.00],
...                   [-0.65, -6.34,  2.67,  1.80, -7.10]]).t()

&gt;&gt;&gt; e, v = torch.symeig(a, eigenvectors=True)
&gt;&gt;&gt; e

-11.0656
 -6.2287
 0.8640
 8.8655
 16.0948
[torch.FloatTensor of size 5]

&gt;&gt;&gt; v

-0.2981 -0.6075  0.4026 -0.3745  0.4896
-0.5078 -0.2880 -0.4066 -0.3572 -0.6053
-0.0816 -0.3843 -0.6600  0.5008  0.3991
-0.0036 -0.4467  0.4553  0.6204 -0.4564
-0.8041  0.4480  0.1725  0.3108  0.1622
[torch.FloatTensor of size 5x5]

</code></pre>
<pre><code class="language-py">torch.trtrs()
</code></pre>
<hr/>
<div align="center">
  <p><a href="https://www.apachecn.org/" target="_blank"><font face="KaiTi" size="6" color="red">我们一直在努力</font></a><p>
  <p><a href="https://github.com/apachecn/pytorch-doc-zh" target="_blank">apachecn/pytorch-doc-zh</a></p>
  <p><a target="_blank" href="https://qm.qq.com/cgi-bin/qm/qr?k=5u_aAU-YlY3fH-m8meXTJzBEo2boQIUs&jump_from=webapi&authKey=CVZcReMt/vKdTXZBQ8ly+jWncXiSzzWOlrx5hybX5pSrKu6s0fvGX54+vHHlgYNt"><img border="0" src="https://pub.idqqimg.com/wpa/images/group.png" alt="【布客】中文翻译组" title="【布客】中文翻译组"></a></p>
  <p><span id="cnzz_stat_icon_1275211409"></span></p>
  <!-- <p><a href="https://get.brightdata.com/apachecn" target="_blank"><img src="/assets/images/partnerstack.gif" /></a><p> -->
  <div class="wwads-cn wwads-horizontal" data-id="206" style="max-width:680px"></div>
  <div style="text-align:center;margin:0 0 10.5px;">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3565452474788507" crossorigin="anonymous"></script>
    <!-- ApacheCNWide -->
    <ins class="adsbygoogle"
        style="display:inline-block;width:680px;height:90px"
        data-ad-client="ca-pub-3565452474788507"
        data-ad-slot="2543897000"></ins>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
  </div>
</div>
<hr/>
<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC81ODA2NC8zNDUyNw==">
  <script type="text/javascript">
  (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];

      if (typeof LivereTower === 'function') { return; }

      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;

      e.parentNode.insertBefore(j, e);
  })(document, 'script');
  </script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->






                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../notes_serialization/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 序列化语义" rel="prev">
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                序列化语义
              </div>
            </div>
          </a>
        
        
          
          <a href="../tensors/" class="md-footer__link md-footer__link--next" aria-label="Next: torch.Tensor" rel="next">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                torch.Tensor
              </div>
            </div>
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright" style="text-align: center; width: 100%;">
  
  
    <div>
      <div style="margin:0 0 10.5px;"><script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1275211409'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s5.cnzz.com/z_stat.php%3Fid%3D1275211409%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script></div>
      <p>Copyright © 2023 学习网站 <a href="http://beian.miit.gov.cn" target="_blank">京ICP备19016010号-1</a><br/>网站由 <a href="https://apachecn.org/cooperate/">@片刻小哥哥</a> 提供支持 | 联系QQ/微信: 529815144 请注明来意！</p>
    </div>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
  
      <script src="../../assets/javascripts/bundle.b425cdc4.min.js"></script>
      
        
          <script src="../../javascripts/mathjax.js"></script>
        
      
        
          <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
    
  <script src="../../assets/javascripts/custom.a7283b5f.min.js"></script>

  </body>
</html>